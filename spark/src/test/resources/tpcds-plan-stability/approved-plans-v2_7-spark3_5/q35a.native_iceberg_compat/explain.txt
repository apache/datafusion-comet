== Physical Plan ==
* CometColumnarToRow (45)
+- CometTakeOrderedAndProject (44)
   +- RowToColumnar (43)
      +- * HashAggregate (42)
         +- * CometColumnarToRow (41)
            +- CometColumnarExchange (40)
               +- * HashAggregate (39)
                  +- * Project (38)
                     +- * BroadcastHashJoin Inner BuildRight (37)
                        :- * Project (31)
                        :  +- * BroadcastHashJoin Inner BuildRight (30)
                        :     :- * Project (24)
                        :     :  +- * BroadcastHashJoin LeftSemi BuildRight (23)
                        :     :     :- * BroadcastHashJoin LeftSemi BuildRight (10)
                        :     :     :  :- * CometColumnarToRow (3)
                        :     :     :  :  +- CometFilter (2)
                        :     :     :  :     +- CometScan [native_iceberg_compat] parquet spark_catalog.default.customer (1)
                        :     :     :  +- BroadcastExchange (9)
                        :     :     :     +- * Project (8)
                        :     :     :        +- * BroadcastHashJoin Inner BuildRight (7)
                        :     :     :           :- * CometColumnarToRow (5)
                        :     :     :           :  +- CometScan [native_iceberg_compat] parquet spark_catalog.default.store_sales (4)
                        :     :     :           +- ReusedExchange (6)
                        :     :     +- BroadcastExchange (22)
                        :     :        +- Union (21)
                        :     :           :- * Project (15)
                        :     :           :  +- * BroadcastHashJoin Inner BuildRight (14)
                        :     :           :     :- * CometColumnarToRow (12)
                        :     :           :     :  +- CometScan [native_iceberg_compat] parquet spark_catalog.default.web_sales (11)
                        :     :           :     +- ReusedExchange (13)
                        :     :           +- * Project (20)
                        :     :              +- * BroadcastHashJoin Inner BuildRight (19)
                        :     :                 :- * CometColumnarToRow (17)
                        :     :                 :  +- CometScan [native_iceberg_compat] parquet spark_catalog.default.catalog_sales (16)
                        :     :                 +- ReusedExchange (18)
                        :     +- BroadcastExchange (29)
                        :        +- * CometColumnarToRow (28)
                        :           +- CometProject (27)
                        :              +- CometFilter (26)
                        :                 +- CometScan [native_iceberg_compat] parquet spark_catalog.default.customer_address (25)
                        +- BroadcastExchange (36)
                           +- * CometColumnarToRow (35)
                              +- CometProject (34)
                                 +- CometFilter (33)
                                    +- CometScan [native_iceberg_compat] parquet spark_catalog.default.customer_demographics (32)


(1) CometScan [native_iceberg_compat] parquet spark_catalog.default.customer
Output [3]: [c_customer_sk#1, c_current_cdemo_sk#2, c_current_addr_sk#3]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_current_addr_sk), IsNotNull(c_current_cdemo_sk)]
ReadSchema: struct<c_customer_sk:int,c_current_cdemo_sk:int,c_current_addr_sk:int>

(2) CometFilter
Input [3]: [c_customer_sk#1, c_current_cdemo_sk#2, c_current_addr_sk#3]
Condition : (isnotnull(c_current_addr_sk#3) AND isnotnull(c_current_cdemo_sk#2))

(3) CometColumnarToRow [codegen id : 9]
Input [3]: [c_customer_sk#1, c_current_cdemo_sk#2, c_current_addr_sk#3]

(4) CometScan [native_iceberg_compat] parquet spark_catalog.default.store_sales
Output [2]: [ss_customer_sk#4, ss_sold_date_sk#5]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#5), dynamicpruningexpression(ss_sold_date_sk#5 IN dynamicpruning#6)]
ReadSchema: struct<ss_customer_sk:int>

(5) CometColumnarToRow [codegen id : 2]
Input [2]: [ss_customer_sk#4, ss_sold_date_sk#5]

(6) ReusedExchange [Reuses operator id: 50]
Output [1]: [d_date_sk#7]

(7) BroadcastHashJoin [codegen id : 2]
Left keys [1]: [ss_sold_date_sk#5]
Right keys [1]: [d_date_sk#7]
Join type: Inner
Join condition: None

(8) Project [codegen id : 2]
Output [1]: [ss_customer_sk#4]
Input [3]: [ss_customer_sk#4, ss_sold_date_sk#5, d_date_sk#7]

(9) BroadcastExchange
Input [1]: [ss_customer_sk#4]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(10) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [c_customer_sk#1]
Right keys [1]: [ss_customer_sk#4]
Join type: LeftSemi
Join condition: None

(11) CometScan [native_iceberg_compat] parquet spark_catalog.default.web_sales
Output [2]: [ws_bill_customer_sk#8, ws_sold_date_sk#9]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#9), dynamicpruningexpression(ws_sold_date_sk#9 IN dynamicpruning#10)]
ReadSchema: struct<ws_bill_customer_sk:int>

(12) CometColumnarToRow [codegen id : 4]
Input [2]: [ws_bill_customer_sk#8, ws_sold_date_sk#9]

(13) ReusedExchange [Reuses operator id: 50]
Output [1]: [d_date_sk#11]

(14) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ws_sold_date_sk#9]
Right keys [1]: [d_date_sk#11]
Join type: Inner
Join condition: None

(15) Project [codegen id : 4]
Output [1]: [ws_bill_customer_sk#8 AS customsk#12]
Input [3]: [ws_bill_customer_sk#8, ws_sold_date_sk#9, d_date_sk#11]

(16) CometScan [native_iceberg_compat] parquet spark_catalog.default.catalog_sales
Output [2]: [cs_ship_customer_sk#13, cs_sold_date_sk#14]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#14), dynamicpruningexpression(cs_sold_date_sk#14 IN dynamicpruning#15)]
ReadSchema: struct<cs_ship_customer_sk:int>

(17) CometColumnarToRow [codegen id : 6]
Input [2]: [cs_ship_customer_sk#13, cs_sold_date_sk#14]

(18) ReusedExchange [Reuses operator id: 50]
Output [1]: [d_date_sk#16]

(19) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [cs_sold_date_sk#14]
Right keys [1]: [d_date_sk#16]
Join type: Inner
Join condition: None

(20) Project [codegen id : 6]
Output [1]: [cs_ship_customer_sk#13 AS customsk#17]
Input [3]: [cs_ship_customer_sk#13, cs_sold_date_sk#14, d_date_sk#16]

(21) Union

(22) BroadcastExchange
Input [1]: [customsk#12]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(23) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [c_customer_sk#1]
Right keys [1]: [customsk#12]
Join type: LeftSemi
Join condition: None

(24) Project [codegen id : 9]
Output [2]: [c_current_cdemo_sk#2, c_current_addr_sk#3]
Input [3]: [c_customer_sk#1, c_current_cdemo_sk#2, c_current_addr_sk#3]

(25) CometScan [native_iceberg_compat] parquet spark_catalog.default.customer_address
Output [2]: [ca_address_sk#18, ca_state#19]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer_address]
PushedFilters: [IsNotNull(ca_address_sk)]
ReadSchema: struct<ca_address_sk:int,ca_state:string>

(26) CometFilter
Input [2]: [ca_address_sk#18, ca_state#19]
Condition : isnotnull(ca_address_sk#18)

(27) CometProject
Input [2]: [ca_address_sk#18, ca_state#19]
Arguments: [ca_address_sk#18, ca_state#20], [ca_address_sk#18, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, ca_state#19, 2, true, false, true) AS ca_state#20]

(28) CometColumnarToRow [codegen id : 7]
Input [2]: [ca_address_sk#18, ca_state#20]

(29) BroadcastExchange
Input [2]: [ca_address_sk#18, ca_state#20]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(30) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [c_current_addr_sk#3]
Right keys [1]: [ca_address_sk#18]
Join type: Inner
Join condition: None

(31) Project [codegen id : 9]
Output [2]: [c_current_cdemo_sk#2, ca_state#20]
Input [4]: [c_current_cdemo_sk#2, c_current_addr_sk#3, ca_address_sk#18, ca_state#20]

(32) CometScan [native_iceberg_compat] parquet spark_catalog.default.customer_demographics
Output [6]: [cd_demo_sk#21, cd_gender#22, cd_marital_status#23, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer_demographics]
PushedFilters: [IsNotNull(cd_demo_sk)]
ReadSchema: struct<cd_demo_sk:int,cd_gender:string,cd_marital_status:string,cd_dep_count:int,cd_dep_employed_count:int,cd_dep_college_count:int>

(33) CometFilter
Input [6]: [cd_demo_sk#21, cd_gender#22, cd_marital_status#23, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Condition : isnotnull(cd_demo_sk#21)

(34) CometProject
Input [6]: [cd_demo_sk#21, cd_gender#22, cd_marital_status#23, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Arguments: [cd_demo_sk#21, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26], [cd_demo_sk#21, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, cd_gender#22, 1, true, false, true) AS cd_gender#27, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, cd_marital_status#23, 1, true, false, true) AS cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]

(35) CometColumnarToRow [codegen id : 8]
Input [6]: [cd_demo_sk#21, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]

(36) BroadcastExchange
Input [6]: [cd_demo_sk#21, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(37) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [c_current_cdemo_sk#2]
Right keys [1]: [cd_demo_sk#21]
Join type: Inner
Join condition: None

(38) Project [codegen id : 9]
Output [6]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Input [8]: [c_current_cdemo_sk#2, ca_state#20, cd_demo_sk#21, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]

(39) HashAggregate [codegen id : 9]
Input [6]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Keys [6]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Functions [10]: [partial_count(1), partial_avg(cd_dep_count#24), partial_max(cd_dep_count#24), partial_sum(cd_dep_count#24), partial_avg(cd_dep_employed_count#25), partial_max(cd_dep_employed_count#25), partial_sum(cd_dep_employed_count#25), partial_avg(cd_dep_college_count#26), partial_max(cd_dep_college_count#26), partial_sum(cd_dep_college_count#26)]
Aggregate Attributes [13]: [count#29, sum#30, count#31, max#32, sum#33, sum#34, count#35, max#36, sum#37, sum#38, count#39, max#40, sum#41]
Results [19]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26, count#42, sum#43, count#44, max#45, sum#46, sum#47, count#48, max#49, sum#50, sum#51, count#52, max#53, sum#54]

(40) CometColumnarExchange
Input [19]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26, count#42, sum#43, count#44, max#45, sum#46, sum#47, count#48, max#49, sum#50, sum#51, count#52, max#53, sum#54]
Arguments: hashpartitioning(ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=5]

(41) CometColumnarToRow [codegen id : 10]
Input [19]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26, count#42, sum#43, count#44, max#45, sum#46, sum#47, count#48, max#49, sum#50, sum#51, count#52, max#53, sum#54]

(42) HashAggregate [codegen id : 10]
Input [19]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26, count#42, sum#43, count#44, max#45, sum#46, sum#47, count#48, max#49, sum#50, sum#51, count#52, max#53, sum#54]
Keys [6]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cd_dep_employed_count#25, cd_dep_college_count#26]
Functions [10]: [count(1), avg(cd_dep_count#24), max(cd_dep_count#24), sum(cd_dep_count#24), avg(cd_dep_employed_count#25), max(cd_dep_employed_count#25), sum(cd_dep_employed_count#25), avg(cd_dep_college_count#26), max(cd_dep_college_count#26), sum(cd_dep_college_count#26)]
Aggregate Attributes [10]: [count(1)#55, avg(cd_dep_count#24)#56, max(cd_dep_count#24)#57, sum(cd_dep_count#24)#58, avg(cd_dep_employed_count#25)#59, max(cd_dep_employed_count#25)#60, sum(cd_dep_employed_count#25)#61, avg(cd_dep_college_count#26)#62, max(cd_dep_college_count#26)#63, sum(cd_dep_college_count#26)#64]
Results [18]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, count(1)#55 AS cnt1#65, avg(cd_dep_count#24)#56 AS avg(cd_dep_count)#66, max(cd_dep_count#24)#57 AS max(cd_dep_count)#67, sum(cd_dep_count#24)#58 AS sum(cd_dep_count)#68, cd_dep_employed_count#25, count(1)#55 AS cnt2#69, avg(cd_dep_employed_count#25)#59 AS avg(cd_dep_employed_count)#70, max(cd_dep_employed_count#25)#60 AS max(cd_dep_employed_count)#71, sum(cd_dep_employed_count#25)#61 AS sum(cd_dep_employed_count)#72, cd_dep_college_count#26, count(1)#55 AS cnt3#73, avg(cd_dep_college_count#26)#62 AS avg(cd_dep_college_count)#74, max(cd_dep_college_count#26)#63 AS max(cd_dep_college_count)#75, sum(cd_dep_college_count#26)#64 AS sum(cd_dep_college_count)#76]

(43) RowToColumnar
Input [18]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cnt1#65, avg(cd_dep_count)#66, max(cd_dep_count)#67, sum(cd_dep_count)#68, cd_dep_employed_count#25, cnt2#69, avg(cd_dep_employed_count)#70, max(cd_dep_employed_count)#71, sum(cd_dep_employed_count)#72, cd_dep_college_count#26, cnt3#73, avg(cd_dep_college_count)#74, max(cd_dep_college_count)#75, sum(cd_dep_college_count)#76]

(44) CometTakeOrderedAndProject
Input [18]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cnt1#65, avg(cd_dep_count)#66, max(cd_dep_count)#67, sum(cd_dep_count)#68, cd_dep_employed_count#25, cnt2#69, avg(cd_dep_employed_count)#70, max(cd_dep_employed_count)#71, sum(cd_dep_employed_count)#72, cd_dep_college_count#26, cnt3#73, avg(cd_dep_college_count)#74, max(cd_dep_college_count)#75, sum(cd_dep_college_count)#76]
Arguments: TakeOrderedAndProject(limit=100, orderBy=[ca_state#20 ASC NULLS FIRST,cd_gender#27 ASC NULLS FIRST,cd_marital_status#28 ASC NULLS FIRST,cd_dep_count#24 ASC NULLS FIRST,cd_dep_employed_count#25 ASC NULLS FIRST,cd_dep_college_count#26 ASC NULLS FIRST], output=[ca_state#20,cd_gender#27,cd_marital_status#28,cd_dep_count#24,cnt1#65,avg(cd_dep_count)#66,max(cd_dep_count)#67,sum(cd_dep_count)#68,cd_dep_employed_count#25,cnt2#69,avg(cd_dep_employed_count)#70,max(cd_dep_employed_count)#71,sum(cd_dep_employed_count)#72,cd_dep_college_count#26,cnt3#73,avg(cd_dep_college_count)#74,max(cd_dep_college_count)#75,sum(cd_dep_college_count)#76]), [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cnt1#65, avg(cd_dep_count)#66, max(cd_dep_count)#67, sum(cd_dep_count)#68, cd_dep_employed_count#25, cnt2#69, avg(cd_dep_employed_count)#70, max(cd_dep_employed_count)#71, sum(cd_dep_employed_count)#72, cd_dep_college_count#26, cnt3#73, avg(cd_dep_college_count)#74, max(cd_dep_college_count)#75, sum(cd_dep_college_count)#76], 100, 0, [ca_state#20 ASC NULLS FIRST, cd_gender#27 ASC NULLS FIRST, cd_marital_status#28 ASC NULLS FIRST, cd_dep_count#24 ASC NULLS FIRST, cd_dep_employed_count#25 ASC NULLS FIRST, cd_dep_college_count#26 ASC NULLS FIRST], [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cnt1#65, avg(cd_dep_count)#66, max(cd_dep_count)#67, sum(cd_dep_count)#68, cd_dep_employed_count#25, cnt2#69, avg(cd_dep_employed_count)#70, max(cd_dep_employed_count)#71, sum(cd_dep_employed_count)#72, cd_dep_college_count#26, cnt3#73, avg(cd_dep_college_count)#74, max(cd_dep_college_count)#75, sum(cd_dep_college_count)#76]

(45) CometColumnarToRow [codegen id : 11]
Input [18]: [ca_state#20, cd_gender#27, cd_marital_status#28, cd_dep_count#24, cnt1#65, avg(cd_dep_count)#66, max(cd_dep_count)#67, sum(cd_dep_count)#68, cd_dep_employed_count#25, cnt2#69, avg(cd_dep_employed_count)#70, max(cd_dep_employed_count)#71, sum(cd_dep_employed_count)#72, cd_dep_college_count#26, cnt3#73, avg(cd_dep_college_count)#74, max(cd_dep_college_count)#75, sum(cd_dep_college_count)#76]

===== Subqueries =====

Subquery:1 Hosting operator id = 4 Hosting Expression = ss_sold_date_sk#5 IN dynamicpruning#6
BroadcastExchange (50)
+- * CometColumnarToRow (49)
   +- CometProject (48)
      +- CometFilter (47)
         +- CometScan [native_iceberg_compat] parquet spark_catalog.default.date_dim (46)


(46) CometScan [native_iceberg_compat] parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#7, d_year#77, d_qoy#78]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_qoy), EqualTo(d_year,1999), LessThan(d_qoy,4), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>

(47) CometFilter
Input [3]: [d_date_sk#7, d_year#77, d_qoy#78]
Condition : ((((isnotnull(d_year#77) AND isnotnull(d_qoy#78)) AND (d_year#77 = 1999)) AND (d_qoy#78 < 4)) AND isnotnull(d_date_sk#7))

(48) CometProject
Input [3]: [d_date_sk#7, d_year#77, d_qoy#78]
Arguments: [d_date_sk#7], [d_date_sk#7]

(49) CometColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#7]

(50) BroadcastExchange
Input [1]: [d_date_sk#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

Subquery:2 Hosting operator id = 11 Hosting Expression = ws_sold_date_sk#9 IN dynamicpruning#6

Subquery:3 Hosting operator id = 16 Hosting Expression = cs_sold_date_sk#14 IN dynamicpruning#6


