== Physical Plan ==
* HashAggregate (67)
+- Exchange (66)
   +- * HashAggregate (65)
      +- Union (64)
         :- * Project (46)
         :  +- * BroadcastHashJoin Inner BuildRight (45)
         :     :- * Project (43)
         :     :  +- * SortMergeJoin LeftSemi (42)
         :     :     :- * Sort (26)
         :     :     :  +- Exchange (25)
         :     :     :     +- * Project (24)
         :     :     :        +- * BroadcastHashJoin LeftSemi BuildRight (23)
         :     :     :           :- * ColumnarToRow (2)
         :     :     :           :  +- CometScan parquet spark_catalog.default.catalog_sales (1)
         :     :     :           +- BroadcastExchange (22)
         :     :     :              +- * Project (21)
         :     :     :                 +- * Filter (20)
         :     :     :                    +- * HashAggregate (19)
         :     :     :                       +- Exchange (18)
         :     :     :                          +- * ColumnarToRow (17)
         :     :     :                             +- CometHashAggregate (16)
         :     :     :                                +- CometProject (15)
         :     :     :                                   +- CometBroadcastHashJoin (14)
         :     :     :                                      :- CometProject (10)
         :     :     :                                      :  +- CometBroadcastHashJoin (9)
         :     :     :                                      :     :- CometFilter (4)
         :     :     :                                      :     :  +- CometScan parquet spark_catalog.default.store_sales (3)
         :     :     :                                      :     +- CometBroadcastExchange (8)
         :     :     :                                      :        +- CometProject (7)
         :     :     :                                      :           +- CometFilter (6)
         :     :     :                                      :              +- CometScan parquet spark_catalog.default.date_dim (5)
         :     :     :                                      +- CometBroadcastExchange (13)
         :     :     :                                         +- CometFilter (12)
         :     :     :                                            +- CometScan parquet spark_catalog.default.item (11)
         :     :     +- * Sort (41)
         :     :        +- * Project (40)
         :     :           +- * Filter (39)
         :     :              +- * HashAggregate (38)
         :     :                 +- Exchange (37)
         :     :                    +- * ColumnarToRow (36)
         :     :                       +- CometHashAggregate (35)
         :     :                          +- CometProject (34)
         :     :                             +- CometBroadcastHashJoin (33)
         :     :                                :- CometProject (29)
         :     :                                :  +- CometFilter (28)
         :     :                                :     +- CometScan parquet spark_catalog.default.store_sales (27)
         :     :                                +- CometBroadcastExchange (32)
         :     :                                   +- CometFilter (31)
         :     :                                      +- CometScan parquet spark_catalog.default.customer (30)
         :     +- ReusedExchange (44)
         +- * Project (63)
            +- * BroadcastHashJoin Inner BuildRight (62)
               :- * Project (60)
               :  +- * SortMergeJoin LeftSemi (59)
               :     :- * Sort (53)
               :     :  +- Exchange (52)
               :     :     +- * Project (51)
               :     :        +- * BroadcastHashJoin LeftSemi BuildRight (50)
               :     :           :- * ColumnarToRow (48)
               :     :           :  +- CometScan parquet spark_catalog.default.web_sales (47)
               :     :           +- ReusedExchange (49)
               :     +- * Sort (58)
               :        +- * Project (57)
               :           +- * Filter (56)
               :              +- * HashAggregate (55)
               :                 +- ReusedExchange (54)
               +- ReusedExchange (61)


(1) Scan parquet spark_catalog.default.catalog_sales
Output [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#5), dynamicpruningexpression(cs_sold_date_sk#5 IN dynamicpruning#6)]
ReadSchema: struct<cs_bill_customer_sk:int,cs_item_sk:int,cs_quantity:int,cs_list_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 3]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(3) Scan parquet spark_catalog.default.store_sales
Output [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#8), dynamicpruningexpression(ss_sold_date_sk#8 IN dynamicpruning#9)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int>

(4) CometFilter
Input [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Condition : isnotnull(ss_item_sk#7)

(5) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#10, d_date#11, d_year#12]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_year:int>

(6) CometFilter
Input [3]: [d_date_sk#10, d_date#11, d_year#12]
Condition : (d_year#12 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#10))

(7) CometProject
Input [3]: [d_date_sk#10, d_date#11, d_year#12]
Arguments: [d_date_sk#10, d_date#11], [d_date_sk#10, d_date#11]

(8) CometBroadcastExchange
Input [2]: [d_date_sk#10, d_date#11]
Arguments: [d_date_sk#10, d_date#11]

(9) CometBroadcastHashJoin
Left output [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Right output [2]: [d_date_sk#10, d_date#11]
Arguments: [ss_sold_date_sk#8], [d_date_sk#10], Inner

(10) CometProject
Input [4]: [ss_item_sk#7, ss_sold_date_sk#8, d_date_sk#10, d_date#11]
Arguments: [ss_item_sk#7, d_date#11], [ss_item_sk#7, d_date#11]

(11) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#13, i_item_desc#14]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_item_desc:string>

(12) CometFilter
Input [2]: [i_item_sk#13, i_item_desc#14]
Condition : isnotnull(i_item_sk#13)

(13) CometBroadcastExchange
Input [2]: [i_item_sk#13, i_item_desc#14]
Arguments: [i_item_sk#13, i_item_desc#14]

(14) CometBroadcastHashJoin
Left output [2]: [ss_item_sk#7, d_date#11]
Right output [2]: [i_item_sk#13, i_item_desc#14]
Arguments: [ss_item_sk#7], [i_item_sk#13], Inner

(15) CometProject
Input [4]: [ss_item_sk#7, d_date#11, i_item_sk#13, i_item_desc#14]
Arguments: [d_date#11, i_item_sk#13, _groupingexpression#15], [d_date#11, i_item_sk#13, substr(i_item_desc#14, 1, 30) AS _groupingexpression#15]

(16) CometHashAggregate
Input [3]: [d_date#11, i_item_sk#13, _groupingexpression#15]
Keys [3]: [_groupingexpression#15, i_item_sk#13, d_date#11]
Functions [1]: [partial_count(1)]

(17) ColumnarToRow [codegen id : 1]
Input [4]: [_groupingexpression#15, i_item_sk#13, d_date#11, count#16]

(18) Exchange
Input [4]: [_groupingexpression#15, i_item_sk#13, d_date#11, count#16]
Arguments: hashpartitioning(_groupingexpression#15, i_item_sk#13, d_date#11, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(19) HashAggregate [codegen id : 2]
Input [4]: [_groupingexpression#15, i_item_sk#13, d_date#11, count#16]
Keys [3]: [_groupingexpression#15, i_item_sk#13, d_date#11]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#17]
Results [2]: [i_item_sk#13 AS item_sk#18, count(1)#17 AS cnt#19]

(20) Filter [codegen id : 2]
Input [2]: [item_sk#18, cnt#19]
Condition : (cnt#19 > 4)

(21) Project [codegen id : 2]
Output [1]: [item_sk#18]
Input [2]: [item_sk#18, cnt#19]

(22) BroadcastExchange
Input [1]: [item_sk#18]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(23) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [cs_item_sk#2]
Right keys [1]: [item_sk#18]
Join type: LeftSemi
Join condition: None

(24) Project [codegen id : 3]
Output [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(25) Exchange
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: hashpartitioning(cs_bill_customer_sk#1, 5), ENSURE_REQUIREMENTS, [plan_id=3]

(26) Sort [codegen id : 4]
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: [cs_bill_customer_sk#1 ASC NULLS FIRST], false, 0

(27) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(28) CometFilter
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]
Condition : isnotnull(ss_customer_sk#20)

(29) CometProject
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]
Arguments: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22], [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22]

(30) Scan parquet spark_catalog.default.customer
Output [1]: [c_customer_sk#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int>

(31) CometFilter
Input [1]: [c_customer_sk#24]
Condition : isnotnull(c_customer_sk#24)

(32) CometBroadcastExchange
Input [1]: [c_customer_sk#24]
Arguments: [c_customer_sk#24]

(33) CometBroadcastHashJoin
Left output [3]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22]
Right output [1]: [c_customer_sk#24]
Arguments: [ss_customer_sk#20], [c_customer_sk#24], Inner

(34) CometProject
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, c_customer_sk#24]
Arguments: [ss_quantity#21, ss_sales_price#22, c_customer_sk#24], [ss_quantity#21, ss_sales_price#22, c_customer_sk#24]

(35) CometHashAggregate
Input [3]: [ss_quantity#21, ss_sales_price#22, c_customer_sk#24]
Keys [1]: [c_customer_sk#24]
Functions [1]: [partial_sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]

(36) ColumnarToRow [codegen id : 5]
Input [3]: [c_customer_sk#24, sum#25, isEmpty#26]

(37) Exchange
Input [3]: [c_customer_sk#24, sum#25, isEmpty#26]
Arguments: hashpartitioning(c_customer_sk#24, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(38) HashAggregate [codegen id : 6]
Input [3]: [c_customer_sk#24, sum#25, isEmpty#26]
Keys [1]: [c_customer_sk#24]
Functions [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#27]
Results [2]: [c_customer_sk#24, sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#27 AS ssales#28]

(39) Filter [codegen id : 6]
Input [2]: [c_customer_sk#24, ssales#28]
Condition : (isnotnull(ssales#28) AND (cast(ssales#28 as decimal(38,8)) > (0.500000 * Subquery scalar-subquery#29, [id=#30])))

(40) Project [codegen id : 6]
Output [1]: [c_customer_sk#24]
Input [2]: [c_customer_sk#24, ssales#28]

(41) Sort [codegen id : 6]
Input [1]: [c_customer_sk#24]
Arguments: [c_customer_sk#24 ASC NULLS FIRST], false, 0

(42) SortMergeJoin [codegen id : 8]
Left keys [1]: [cs_bill_customer_sk#1]
Right keys [1]: [c_customer_sk#24]
Join type: LeftSemi
Join condition: None

(43) Project [codegen id : 8]
Output [3]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(44) ReusedExchange [Reuses operator id: 72]
Output [1]: [d_date_sk#31]

(45) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [cs_sold_date_sk#5]
Right keys [1]: [d_date_sk#31]
Join type: Inner
Join condition: None

(46) Project [codegen id : 8]
Output [1]: [(cast(cs_quantity#3 as decimal(10,0)) * cs_list_price#4) AS sales#32]
Input [4]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5, d_date_sk#31]

(47) Scan parquet spark_catalog.default.web_sales
Output [5]: [ws_item_sk#33, ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#37), dynamicpruningexpression(ws_sold_date_sk#37 IN dynamicpruning#38)]
ReadSchema: struct<ws_item_sk:int,ws_bill_customer_sk:int,ws_quantity:int,ws_list_price:decimal(7,2)>

(48) ColumnarToRow [codegen id : 11]
Input [5]: [ws_item_sk#33, ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(49) ReusedExchange [Reuses operator id: 22]
Output [1]: [item_sk#18]

(50) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [ws_item_sk#33]
Right keys [1]: [item_sk#18]
Join type: LeftSemi
Join condition: None

(51) Project [codegen id : 11]
Output [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Input [5]: [ws_item_sk#33, ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(52) Exchange
Input [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Arguments: hashpartitioning(ws_bill_customer_sk#34, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(53) Sort [codegen id : 12]
Input [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Arguments: [ws_bill_customer_sk#34 ASC NULLS FIRST], false, 0

(54) ReusedExchange [Reuses operator id: 37]
Output [3]: [c_customer_sk#24, sum#25, isEmpty#26]

(55) HashAggregate [codegen id : 14]
Input [3]: [c_customer_sk#24, sum#25, isEmpty#26]
Keys [1]: [c_customer_sk#24]
Functions [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#27]
Results [2]: [c_customer_sk#24, sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#27 AS ssales#28]

(56) Filter [codegen id : 14]
Input [2]: [c_customer_sk#24, ssales#28]
Condition : (isnotnull(ssales#28) AND (cast(ssales#28 as decimal(38,8)) > (0.500000 * ReusedSubquery Subquery scalar-subquery#29, [id=#30])))

(57) Project [codegen id : 14]
Output [1]: [c_customer_sk#24]
Input [2]: [c_customer_sk#24, ssales#28]

(58) Sort [codegen id : 14]
Input [1]: [c_customer_sk#24]
Arguments: [c_customer_sk#24 ASC NULLS FIRST], false, 0

(59) SortMergeJoin [codegen id : 16]
Left keys [1]: [ws_bill_customer_sk#34]
Right keys [1]: [c_customer_sk#24]
Join type: LeftSemi
Join condition: None

(60) Project [codegen id : 16]
Output [3]: [ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]
Input [4]: [ws_bill_customer_sk#34, ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37]

(61) ReusedExchange [Reuses operator id: 72]
Output [1]: [d_date_sk#39]

(62) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [ws_sold_date_sk#37]
Right keys [1]: [d_date_sk#39]
Join type: Inner
Join condition: None

(63) Project [codegen id : 16]
Output [1]: [(cast(ws_quantity#35 as decimal(10,0)) * ws_list_price#36) AS sales#40]
Input [4]: [ws_quantity#35, ws_list_price#36, ws_sold_date_sk#37, d_date_sk#39]

(64) Union

(65) HashAggregate [codegen id : 17]
Input [1]: [sales#32]
Keys: []
Functions [1]: [partial_sum(sales#32)]
Aggregate Attributes [2]: [sum#41, isEmpty#42]
Results [2]: [sum#43, isEmpty#44]

(66) Exchange
Input [2]: [sum#43, isEmpty#44]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(67) HashAggregate [codegen id : 18]
Input [2]: [sum#43, isEmpty#44]
Keys: []
Functions [1]: [sum(sales#32)]
Aggregate Attributes [1]: [sum(sales#32)#45]
Results [1]: [sum(sales#32)#45 AS sum(sales)#46]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = cs_sold_date_sk#5 IN dynamicpruning#6
BroadcastExchange (72)
+- * ColumnarToRow (71)
   +- CometProject (70)
      +- CometFilter (69)
         +- CometScan parquet spark_catalog.default.date_dim (68)


(68) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#31, d_year#47, d_moy#48]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2000), EqualTo(d_moy,2), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(69) CometFilter
Input [3]: [d_date_sk#31, d_year#47, d_moy#48]
Condition : ((((isnotnull(d_year#47) AND isnotnull(d_moy#48)) AND (d_year#47 = 2000)) AND (d_moy#48 = 2)) AND isnotnull(d_date_sk#31))

(70) CometProject
Input [3]: [d_date_sk#31, d_year#47, d_moy#48]
Arguments: [d_date_sk#31], [d_date_sk#31]

(71) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#31]

(72) BroadcastExchange
Input [1]: [d_date_sk#31]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=7]

Subquery:2 Hosting operator id = 3 Hosting Expression = ss_sold_date_sk#8 IN dynamicpruning#9
BroadcastExchange (77)
+- * ColumnarToRow (76)
   +- CometProject (75)
      +- CometFilter (74)
         +- CometScan parquet spark_catalog.default.date_dim (73)


(73) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#10, d_date#11, d_year#12]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_year:int>

(74) CometFilter
Input [3]: [d_date_sk#10, d_date#11, d_year#12]
Condition : (d_year#12 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#10))

(75) CometProject
Input [3]: [d_date_sk#10, d_date#11, d_year#12]
Arguments: [d_date_sk#10, d_date#11], [d_date_sk#10, d_date#11]

(76) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#10, d_date#11]

(77) BroadcastExchange
Input [2]: [d_date_sk#10, d_date#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

Subquery:3 Hosting operator id = 39 Hosting Expression = Subquery scalar-subquery#29, [id=#30]
* HashAggregate (97)
+- Exchange (96)
   +- * HashAggregate (95)
      +- * HashAggregate (94)
         +- Exchange (93)
            +- * ColumnarToRow (92)
               +- CometHashAggregate (91)
                  +- CometProject (90)
                     +- CometBroadcastHashJoin (89)
                        :- CometProject (84)
                        :  +- CometBroadcastHashJoin (83)
                        :     :- CometFilter (79)
                        :     :  +- CometScan parquet spark_catalog.default.store_sales (78)
                        :     +- CometBroadcastExchange (82)
                        :        +- CometFilter (81)
                        :           +- CometScan parquet spark_catalog.default.customer (80)
                        +- CometBroadcastExchange (88)
                           +- CometProject (87)
                              +- CometFilter (86)
                                 +- CometScan parquet spark_catalog.default.date_dim (85)


(78) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#52), dynamicpruningexpression(ss_sold_date_sk#52 IN dynamicpruning#53)]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(79) CometFilter
Input [4]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52]
Condition : isnotnull(ss_customer_sk#49)

(80) Scan parquet spark_catalog.default.customer
Output [1]: [c_customer_sk#54]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int>

(81) CometFilter
Input [1]: [c_customer_sk#54]
Condition : isnotnull(c_customer_sk#54)

(82) CometBroadcastExchange
Input [1]: [c_customer_sk#54]
Arguments: [c_customer_sk#54]

(83) CometBroadcastHashJoin
Left output [4]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52]
Right output [1]: [c_customer_sk#54]
Arguments: [ss_customer_sk#49], [c_customer_sk#54], Inner

(84) CometProject
Input [5]: [ss_customer_sk#49, ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54]
Arguments: [ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54], [ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54]

(85) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#55, d_year#56]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(86) CometFilter
Input [2]: [d_date_sk#55, d_year#56]
Condition : (d_year#56 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#55))

(87) CometProject
Input [2]: [d_date_sk#55, d_year#56]
Arguments: [d_date_sk#55], [d_date_sk#55]

(88) CometBroadcastExchange
Input [1]: [d_date_sk#55]
Arguments: [d_date_sk#55]

(89) CometBroadcastHashJoin
Left output [4]: [ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54]
Right output [1]: [d_date_sk#55]
Arguments: [ss_sold_date_sk#52], [d_date_sk#55], Inner

(90) CometProject
Input [5]: [ss_quantity#50, ss_sales_price#51, ss_sold_date_sk#52, c_customer_sk#54, d_date_sk#55]
Arguments: [ss_quantity#50, ss_sales_price#51, c_customer_sk#54], [ss_quantity#50, ss_sales_price#51, c_customer_sk#54]

(91) CometHashAggregate
Input [3]: [ss_quantity#50, ss_sales_price#51, c_customer_sk#54]
Keys [1]: [c_customer_sk#54]
Functions [1]: [partial_sum((cast(ss_quantity#50 as decimal(10,0)) * ss_sales_price#51))]

(92) ColumnarToRow [codegen id : 1]
Input [3]: [c_customer_sk#54, sum#57, isEmpty#58]

(93) Exchange
Input [3]: [c_customer_sk#54, sum#57, isEmpty#58]
Arguments: hashpartitioning(c_customer_sk#54, 5), ENSURE_REQUIREMENTS, [plan_id=9]

(94) HashAggregate [codegen id : 2]
Input [3]: [c_customer_sk#54, sum#57, isEmpty#58]
Keys [1]: [c_customer_sk#54]
Functions [1]: [sum((cast(ss_quantity#50 as decimal(10,0)) * ss_sales_price#51))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#50 as decimal(10,0)) * ss_sales_price#51))#59]
Results [1]: [sum((cast(ss_quantity#50 as decimal(10,0)) * ss_sales_price#51))#59 AS csales#60]

(95) HashAggregate [codegen id : 2]
Input [1]: [csales#60]
Keys: []
Functions [1]: [partial_max(csales#60)]
Aggregate Attributes [1]: [max#61]
Results [1]: [max#62]

(96) Exchange
Input [1]: [max#62]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=10]

(97) HashAggregate [codegen id : 3]
Input [1]: [max#62]
Keys: []
Functions [1]: [max(csales#60)]
Aggregate Attributes [1]: [max(csales#60)#63]
Results [1]: [max(csales#60)#63 AS tpcds_cmax#64]

Subquery:4 Hosting operator id = 78 Hosting Expression = ss_sold_date_sk#52 IN dynamicpruning#53
BroadcastExchange (102)
+- * ColumnarToRow (101)
   +- CometProject (100)
      +- CometFilter (99)
         +- CometScan parquet spark_catalog.default.date_dim (98)


(98) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#55, d_year#56]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(99) CometFilter
Input [2]: [d_date_sk#55, d_year#56]
Condition : (d_year#56 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#55))

(100) CometProject
Input [2]: [d_date_sk#55, d_year#56]
Arguments: [d_date_sk#55], [d_date_sk#55]

(101) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#55]

(102) BroadcastExchange
Input [1]: [d_date_sk#55]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=11]

Subquery:5 Hosting operator id = 47 Hosting Expression = ws_sold_date_sk#37 IN dynamicpruning#6

Subquery:6 Hosting operator id = 56 Hosting Expression = ReusedSubquery Subquery scalar-subquery#29, [id=#30]


