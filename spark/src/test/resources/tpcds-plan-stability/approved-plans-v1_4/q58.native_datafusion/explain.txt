== Physical Plan ==
* CometColumnarToRow (51)
+- CometTakeOrderedAndProject (50)
   +- CometProject (49)
      +- CometBroadcastHashJoin (48)
         :- CometProject (33)
         :  +- CometBroadcastHashJoin (32)
         :     :- CometFilter (17)
         :     :  +- CometHashAggregate (16)
         :     :     +- CometColumnarExchange (15)
         :     :        +- * HashAggregate (14)
         :     :           +- * Project (13)
         :     :              +- * BroadcastHashJoin Inner BuildRight (12)
         :     :                 :- * Project (10)
         :     :                 :  +- * BroadcastHashJoin Inner BuildRight (9)
         :     :                 :     :- * Filter (3)
         :     :                 :     :  +- * ColumnarToRow (2)
         :     :                 :     :     +- Scan parquet spark_catalog.default.store_sales (1)
         :     :                 :     +- BroadcastExchange (8)
         :     :                 :        +- * CometColumnarToRow (7)
         :     :                 :           +- CometProject (6)
         :     :                 :              +- CometFilter (5)
         :     :                 :                 +- CometNativeScan parquet spark_catalog.default.item (4)
         :     :                 +- ReusedExchange (11)
         :     +- CometBroadcastExchange (31)
         :        +- CometFilter (30)
         :           +- CometHashAggregate (29)
         :              +- CometColumnarExchange (28)
         :                 +- * HashAggregate (27)
         :                    +- * Project (26)
         :                       +- * BroadcastHashJoin Inner BuildRight (25)
         :                          :- * Project (23)
         :                          :  +- * BroadcastHashJoin Inner BuildRight (22)
         :                          :     :- * Filter (20)
         :                          :     :  +- * ColumnarToRow (19)
         :                          :     :     +- Scan parquet spark_catalog.default.catalog_sales (18)
         :                          :     +- ReusedExchange (21)
         :                          +- ReusedExchange (24)
         +- CometBroadcastExchange (47)
            +- CometFilter (46)
               +- CometHashAggregate (45)
                  +- CometColumnarExchange (44)
                     +- * HashAggregate (43)
                        +- * Project (42)
                           +- * BroadcastHashJoin Inner BuildRight (41)
                              :- * Project (39)
                              :  +- * BroadcastHashJoin Inner BuildRight (38)
                              :     :- * Filter (36)
                              :     :  +- * ColumnarToRow (35)
                              :     :     +- Scan parquet spark_catalog.default.web_sales (34)
                              :     +- ReusedExchange (37)
                              +- ReusedExchange (40)


(1) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#3), dynamicpruningexpression(ss_sold_date_sk#3 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 3]
Input [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]

(3) Filter [codegen id : 3]
Input [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Condition : isnotnull(ss_item_sk#1)

(4) CometNativeScan parquet spark_catalog.default.item
Output [2]: [i_item_sk#5, i_item_id#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(5) CometFilter
Input [2]: [i_item_sk#5, i_item_id#6]
Condition : (isnotnull(i_item_sk#5) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_item_id#6, 16, true, false, true)))

(6) CometProject
Input [2]: [i_item_sk#5, i_item_id#6]
Arguments: [i_item_sk#5, i_item_id#7], [i_item_sk#5, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_item_id#6, 16, true, false, true) AS i_item_id#7]

(7) CometColumnarToRow [codegen id : 1]
Input [2]: [i_item_sk#5, i_item_id#7]

(8) BroadcastExchange
Input [2]: [i_item_sk#5, i_item_id#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(9) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#5]
Join type: Inner
Join condition: None

(10) Project [codegen id : 3]
Output [3]: [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#7]
Input [5]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_sk#5, i_item_id#7]

(11) ReusedExchange [Reuses operator id: 61]
Output [1]: [d_date_sk#8]

(12) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#3]
Right keys [1]: [d_date_sk#8]
Join type: Inner
Join condition: None

(13) Project [codegen id : 3]
Output [2]: [ss_ext_sales_price#2, i_item_id#7]
Input [4]: [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#7, d_date_sk#8]

(14) HashAggregate [codegen id : 3]
Input [2]: [ss_ext_sales_price#2, i_item_id#7]
Keys [1]: [i_item_id#7]
Functions [1]: [partial_sum(UnscaledValue(ss_ext_sales_price#2))]
Aggregate Attributes [1]: [sum#9]
Results [2]: [i_item_id#7, sum#10]

(15) CometColumnarExchange
Input [2]: [i_item_id#7, sum#10]
Arguments: hashpartitioning(i_item_id#7, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(16) CometHashAggregate
Input [2]: [i_item_id#7, sum#10]
Keys [1]: [i_item_id#7]
Functions [1]: [sum(UnscaledValue(ss_ext_sales_price#2))]

(17) CometFilter
Input [2]: [item_id#11, ss_item_rev#12]
Condition : isnotnull(ss_item_rev#12)

(18) Scan parquet spark_catalog.default.catalog_sales
Output [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#15), dynamicpruningexpression(cs_sold_date_sk#15 IN dynamicpruning#16)]
PushedFilters: [IsNotNull(cs_item_sk)]
ReadSchema: struct<cs_item_sk:int,cs_ext_sales_price:decimal(7,2)>

(19) ColumnarToRow [codegen id : 6]
Input [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]

(20) Filter [codegen id : 6]
Input [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]
Condition : isnotnull(cs_item_sk#13)

(21) ReusedExchange [Reuses operator id: 8]
Output [2]: [i_item_sk#17, i_item_id#18]

(22) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [cs_item_sk#13]
Right keys [1]: [i_item_sk#17]
Join type: Inner
Join condition: None

(23) Project [codegen id : 6]
Output [3]: [cs_ext_sales_price#14, cs_sold_date_sk#15, i_item_id#18]
Input [5]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15, i_item_sk#17, i_item_id#18]

(24) ReusedExchange [Reuses operator id: 75]
Output [1]: [d_date_sk#19]

(25) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [cs_sold_date_sk#15]
Right keys [1]: [d_date_sk#19]
Join type: Inner
Join condition: None

(26) Project [codegen id : 6]
Output [2]: [cs_ext_sales_price#14, i_item_id#18]
Input [4]: [cs_ext_sales_price#14, cs_sold_date_sk#15, i_item_id#18, d_date_sk#19]

(27) HashAggregate [codegen id : 6]
Input [2]: [cs_ext_sales_price#14, i_item_id#18]
Keys [1]: [i_item_id#18]
Functions [1]: [partial_sum(UnscaledValue(cs_ext_sales_price#14))]
Aggregate Attributes [1]: [sum#20]
Results [2]: [i_item_id#18, sum#21]

(28) CometColumnarExchange
Input [2]: [i_item_id#18, sum#21]
Arguments: hashpartitioning(i_item_id#18, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=3]

(29) CometHashAggregate
Input [2]: [i_item_id#18, sum#21]
Keys [1]: [i_item_id#18]
Functions [1]: [sum(UnscaledValue(cs_ext_sales_price#14))]

(30) CometFilter
Input [2]: [item_id#22, cs_item_rev#23]
Condition : isnotnull(cs_item_rev#23)

(31) CometBroadcastExchange
Input [2]: [item_id#22, cs_item_rev#23]
Arguments: [item_id#22, cs_item_rev#23]

(32) CometBroadcastHashJoin
Left output [2]: [item_id#11, ss_item_rev#12]
Right output [2]: [item_id#22, cs_item_rev#23]
Arguments: [item_id#11], [item_id#22], Inner, ((((cast(ss_item_rev#12 as decimal(19,3)) >= (0.9 * cs_item_rev#23)) AND (cast(ss_item_rev#12 as decimal(20,3)) <= (1.1 * cs_item_rev#23))) AND (cast(cs_item_rev#23 as decimal(19,3)) >= (0.9 * ss_item_rev#12))) AND (cast(cs_item_rev#23 as decimal(20,3)) <= (1.1 * ss_item_rev#12))), BuildRight

(33) CometProject
Input [4]: [item_id#11, ss_item_rev#12, item_id#22, cs_item_rev#23]
Arguments: [item_id#11, ss_item_rev#12, cs_item_rev#23], [item_id#11, ss_item_rev#12, cs_item_rev#23]

(34) Scan parquet spark_catalog.default.web_sales
Output [3]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#26), dynamicpruningexpression(ws_sold_date_sk#26 IN dynamicpruning#16)]
PushedFilters: [IsNotNull(ws_item_sk)]
ReadSchema: struct<ws_item_sk:int,ws_ext_sales_price:decimal(7,2)>

(35) ColumnarToRow [codegen id : 9]
Input [3]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26]

(36) Filter [codegen id : 9]
Input [3]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26]
Condition : isnotnull(ws_item_sk#24)

(37) ReusedExchange [Reuses operator id: 8]
Output [2]: [i_item_sk#27, i_item_id#28]

(38) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ws_item_sk#24]
Right keys [1]: [i_item_sk#27]
Join type: Inner
Join condition: None

(39) Project [codegen id : 9]
Output [3]: [ws_ext_sales_price#25, ws_sold_date_sk#26, i_item_id#28]
Input [5]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26, i_item_sk#27, i_item_id#28]

(40) ReusedExchange [Reuses operator id: 75]
Output [1]: [d_date_sk#29]

(41) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ws_sold_date_sk#26]
Right keys [1]: [d_date_sk#29]
Join type: Inner
Join condition: None

(42) Project [codegen id : 9]
Output [2]: [ws_ext_sales_price#25, i_item_id#28]
Input [4]: [ws_ext_sales_price#25, ws_sold_date_sk#26, i_item_id#28, d_date_sk#29]

(43) HashAggregate [codegen id : 9]
Input [2]: [ws_ext_sales_price#25, i_item_id#28]
Keys [1]: [i_item_id#28]
Functions [1]: [partial_sum(UnscaledValue(ws_ext_sales_price#25))]
Aggregate Attributes [1]: [sum#30]
Results [2]: [i_item_id#28, sum#31]

(44) CometColumnarExchange
Input [2]: [i_item_id#28, sum#31]
Arguments: hashpartitioning(i_item_id#28, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=4]

(45) CometHashAggregate
Input [2]: [i_item_id#28, sum#31]
Keys [1]: [i_item_id#28]
Functions [1]: [sum(UnscaledValue(ws_ext_sales_price#25))]

(46) CometFilter
Input [2]: [item_id#32, ws_item_rev#33]
Condition : isnotnull(ws_item_rev#33)

(47) CometBroadcastExchange
Input [2]: [item_id#32, ws_item_rev#33]
Arguments: [item_id#32, ws_item_rev#33]

(48) CometBroadcastHashJoin
Left output [3]: [item_id#11, ss_item_rev#12, cs_item_rev#23]
Right output [2]: [item_id#32, ws_item_rev#33]
Arguments: [item_id#11], [item_id#32], Inner, ((((((((cast(ss_item_rev#12 as decimal(19,3)) >= (0.9 * ws_item_rev#33)) AND (cast(ss_item_rev#12 as decimal(20,3)) <= (1.1 * ws_item_rev#33))) AND (cast(cs_item_rev#23 as decimal(19,3)) >= (0.9 * ws_item_rev#33))) AND (cast(cs_item_rev#23 as decimal(20,3)) <= (1.1 * ws_item_rev#33))) AND (cast(ws_item_rev#33 as decimal(19,3)) >= (0.9 * ss_item_rev#12))) AND (cast(ws_item_rev#33 as decimal(20,3)) <= (1.1 * ss_item_rev#12))) AND (cast(ws_item_rev#33 as decimal(19,3)) >= (0.9 * cs_item_rev#23))) AND (cast(ws_item_rev#33 as decimal(20,3)) <= (1.1 * cs_item_rev#23))), BuildRight

(49) CometProject
Input [5]: [item_id#11, ss_item_rev#12, cs_item_rev#23, item_id#32, ws_item_rev#33]
Arguments: [item_id#11, ss_item_rev#12, ss_dev#34, cs_item_rev#23, cs_dev#35, ws_item_rev#33, ws_dev#36, average#37], [item_id#11, ss_item_rev#12, (((ss_item_rev#12 / ((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#33)) / 3) * 100) AS ss_dev#34, cs_item_rev#23, (((cs_item_rev#23 / ((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#33)) / 3) * 100) AS cs_dev#35, ws_item_rev#33, (((ws_item_rev#33 / ((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#33)) / 3) * 100) AS ws_dev#36, (((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#33) / 3) AS average#37]

(50) CometTakeOrderedAndProject
Input [8]: [item_id#11, ss_item_rev#12, ss_dev#34, cs_item_rev#23, cs_dev#35, ws_item_rev#33, ws_dev#36, average#37]
Arguments: TakeOrderedAndProject(limit=100, orderBy=[item_id#11 ASC NULLS FIRST,ss_item_rev#12 ASC NULLS FIRST], output=[item_id#11,ss_item_rev#12,ss_dev#34,cs_item_rev#23,cs_dev#35,ws_item_rev#33,ws_dev#36,average#37]), [item_id#11, ss_item_rev#12, ss_dev#34, cs_item_rev#23, cs_dev#35, ws_item_rev#33, ws_dev#36, average#37], 100, 0, [item_id#11 ASC NULLS FIRST, ss_item_rev#12 ASC NULLS FIRST], [item_id#11, ss_item_rev#12, ss_dev#34, cs_item_rev#23, cs_dev#35, ws_item_rev#33, ws_dev#36, average#37]

(51) CometColumnarToRow [codegen id : 10]
Input [8]: [item_id#11, ss_item_rev#12, ss_dev#34, cs_item_rev#23, cs_dev#35, ws_item_rev#33, ws_dev#36, average#37]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#3 IN dynamicpruning#4
BroadcastExchange (61)
+- * CometColumnarToRow (60)
   +- CometProject (59)
      +- CometBroadcastHashJoin (58)
         :- CometFilter (53)
         :  +- CometNativeScan parquet spark_catalog.default.date_dim (52)
         +- CometBroadcastExchange (57)
            +- CometProject (56)
               +- CometFilter (55)
                  +- CometNativeScan parquet spark_catalog.default.date_dim (54)


(52) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#8, d_date#38]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(53) CometFilter
Input [2]: [d_date_sk#8, d_date#38]
Condition : isnotnull(d_date_sk#8)

(54) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date#38, d_week_seq#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_week_seq)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(55) CometFilter
Input [2]: [d_date#38, d_week_seq#39]
Condition : (isnotnull(d_week_seq#39) AND (d_week_seq#39 = Subquery scalar-subquery#40, [id=#41]))

(56) CometProject
Input [2]: [d_date#38, d_week_seq#39]
Arguments: [d_date#38#42], [d_date#38 AS d_date#38#42]

(57) CometBroadcastExchange
Input [1]: [d_date#38#42]
Arguments: [d_date#38#42]

(58) CometBroadcastHashJoin
Left output [2]: [d_date_sk#8, d_date#38]
Right output [1]: [d_date#38#42]
Arguments: [d_date#38], [d_date#38#42], LeftSemi, BuildRight

(59) CometProject
Input [2]: [d_date_sk#8, d_date#38]
Arguments: [d_date_sk#8], [d_date_sk#8]

(60) CometColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#8]

(61) BroadcastExchange
Input [1]: [d_date_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

Subquery:2 Hosting operator id = 55 Hosting Expression = Subquery scalar-subquery#40, [id=#41]
* CometColumnarToRow (65)
+- CometProject (64)
   +- CometFilter (63)
      +- CometNativeScan parquet spark_catalog.default.date_dim (62)


(62) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date#38, d_week_seq#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), EqualTo(d_date,2000-01-03)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(63) CometFilter
Input [2]: [d_date#38, d_week_seq#39]
Condition : (isnotnull(d_date#38) AND (d_date#38 = 2000-01-03))

(64) CometProject
Input [2]: [d_date#38, d_week_seq#39]
Arguments: [d_week_seq#39], [d_week_seq#39]

(65) CometColumnarToRow [codegen id : 1]
Input [1]: [d_week_seq#39]

Subquery:3 Hosting operator id = 18 Hosting Expression = cs_sold_date_sk#15 IN dynamicpruning#16
BroadcastExchange (75)
+- * CometColumnarToRow (74)
   +- CometProject (73)
      +- CometBroadcastHashJoin (72)
         :- CometFilter (67)
         :  +- CometNativeScan parquet spark_catalog.default.date_dim (66)
         +- CometBroadcastExchange (71)
            +- CometProject (70)
               +- CometFilter (69)
                  +- CometNativeScan parquet spark_catalog.default.date_dim (68)


(66) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#19, d_date#43]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(67) CometFilter
Input [2]: [d_date_sk#19, d_date#43]
Condition : isnotnull(d_date_sk#19)

(68) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date#38, d_week_seq#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_week_seq)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(69) CometFilter
Input [2]: [d_date#38, d_week_seq#39]
Condition : (isnotnull(d_week_seq#39) AND (d_week_seq#39 = ReusedSubquery Subquery scalar-subquery#40, [id=#41]))

(70) CometProject
Input [2]: [d_date#38, d_week_seq#39]
Arguments: [d_date#38], [d_date#38]

(71) CometBroadcastExchange
Input [1]: [d_date#38]
Arguments: [d_date#38]

(72) CometBroadcastHashJoin
Left output [2]: [d_date_sk#19, d_date#43]
Right output [1]: [d_date#38]
Arguments: [d_date#43], [d_date#38], LeftSemi, BuildRight

(73) CometProject
Input [2]: [d_date_sk#19, d_date#43]
Arguments: [d_date_sk#19], [d_date_sk#19]

(74) CometColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#19]

(75) BroadcastExchange
Input [1]: [d_date_sk#19]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

Subquery:4 Hosting operator id = 69 Hosting Expression = ReusedSubquery Subquery scalar-subquery#40, [id=#41]

Subquery:5 Hosting operator id = 34 Hosting Expression = ws_sold_date_sk#26 IN dynamicpruning#16


