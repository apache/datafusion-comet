== Physical Plan ==
* HashAggregate (26)
+- Exchange (25)
   +- * HashAggregate (24)
      +- * Project (23)
         +- * SortMergeJoin FullOuter (22)
            :- * Sort (12)
            :  +- * HashAggregate (11)
            :     +- Exchange (10)
            :        +- * ColumnarToRow (9)
            :           +- CometHashAggregate (8)
            :              +- CometProject (7)
            :                 +- CometBroadcastHashJoin (6)
            :                    :- CometScan parquet spark_catalog.default.store_sales (1)
            :                    +- CometBroadcastExchange (5)
            :                       +- CometProject (4)
            :                          +- CometFilter (3)
            :                             +- CometScan parquet spark_catalog.default.date_dim (2)
            +- * Sort (21)
               +- * HashAggregate (20)
                  +- Exchange (19)
                     +- * ColumnarToRow (18)
                        +- CometHashAggregate (17)
                           +- CometProject (16)
                              +- CometBroadcastHashJoin (15)
                                 :- CometScan parquet spark_catalog.default.catalog_sales (13)
                                 +- ReusedExchange (14)


(1) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_item_sk#1, ss_customer_sk#2, ss_sold_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#3), dynamicpruningexpression(ss_sold_date_sk#3 IN dynamicpruning#4)]
ReadSchema: struct<ss_item_sk:int,ss_customer_sk:int>

(2) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#5, d_month_seq#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_month_seq:int>

(3) CometFilter
Input [2]: [d_date_sk#5, d_month_seq#6]
Condition : (((isnotnull(d_month_seq#6) AND (d_month_seq#6 >= 1200)) AND (d_month_seq#6 <= 1211)) AND isnotnull(d_date_sk#5))

(4) CometProject
Input [2]: [d_date_sk#5, d_month_seq#6]
Arguments: [d_date_sk#5], [d_date_sk#5]

(5) CometBroadcastExchange
Input [1]: [d_date_sk#5]
Arguments: [d_date_sk#5]

(6) CometBroadcastHashJoin
Left output [3]: [ss_item_sk#1, ss_customer_sk#2, ss_sold_date_sk#3]
Right output [1]: [d_date_sk#5]
Arguments: [ss_sold_date_sk#3], [d_date_sk#5], Inner

(7) CometProject
Input [4]: [ss_item_sk#1, ss_customer_sk#2, ss_sold_date_sk#3, d_date_sk#5]
Arguments: [ss_item_sk#1, ss_customer_sk#2], [ss_item_sk#1, ss_customer_sk#2]

(8) CometHashAggregate
Input [2]: [ss_item_sk#1, ss_customer_sk#2]
Keys [2]: [ss_customer_sk#2, ss_item_sk#1]
Functions: []

(9) ColumnarToRow [codegen id : 1]
Input [2]: [ss_customer_sk#2, ss_item_sk#1]

(10) Exchange
Input [2]: [ss_customer_sk#2, ss_item_sk#1]
Arguments: hashpartitioning(ss_customer_sk#2, ss_item_sk#1, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(11) HashAggregate [codegen id : 2]
Input [2]: [ss_customer_sk#2, ss_item_sk#1]
Keys [2]: [ss_customer_sk#2, ss_item_sk#1]
Functions: []
Aggregate Attributes: []
Results [2]: [ss_customer_sk#2 AS customer_sk#7, ss_item_sk#1 AS item_sk#8]

(12) Sort [codegen id : 2]
Input [2]: [customer_sk#7, item_sk#8]
Arguments: [customer_sk#7 ASC NULLS FIRST, item_sk#8 ASC NULLS FIRST], false, 0

(13) Scan parquet spark_catalog.default.catalog_sales
Output [3]: [cs_bill_customer_sk#9, cs_item_sk#10, cs_sold_date_sk#11]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#11), dynamicpruningexpression(cs_sold_date_sk#11 IN dynamicpruning#12)]
ReadSchema: struct<cs_bill_customer_sk:int,cs_item_sk:int>

(14) ReusedExchange [Reuses operator id: 5]
Output [1]: [d_date_sk#13]

(15) CometBroadcastHashJoin
Left output [3]: [cs_bill_customer_sk#9, cs_item_sk#10, cs_sold_date_sk#11]
Right output [1]: [d_date_sk#13]
Arguments: [cs_sold_date_sk#11], [d_date_sk#13], Inner

(16) CometProject
Input [4]: [cs_bill_customer_sk#9, cs_item_sk#10, cs_sold_date_sk#11, d_date_sk#13]
Arguments: [cs_bill_customer_sk#9, cs_item_sk#10], [cs_bill_customer_sk#9, cs_item_sk#10]

(17) CometHashAggregate
Input [2]: [cs_bill_customer_sk#9, cs_item_sk#10]
Keys [2]: [cs_bill_customer_sk#9, cs_item_sk#10]
Functions: []

(18) ColumnarToRow [codegen id : 3]
Input [2]: [cs_bill_customer_sk#9, cs_item_sk#10]

(19) Exchange
Input [2]: [cs_bill_customer_sk#9, cs_item_sk#10]
Arguments: hashpartitioning(cs_bill_customer_sk#9, cs_item_sk#10, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(20) HashAggregate [codegen id : 4]
Input [2]: [cs_bill_customer_sk#9, cs_item_sk#10]
Keys [2]: [cs_bill_customer_sk#9, cs_item_sk#10]
Functions: []
Aggregate Attributes: []
Results [2]: [cs_bill_customer_sk#9 AS customer_sk#14, cs_item_sk#10 AS item_sk#15]

(21) Sort [codegen id : 4]
Input [2]: [customer_sk#14, item_sk#15]
Arguments: [customer_sk#14 ASC NULLS FIRST, item_sk#15 ASC NULLS FIRST], false, 0

(22) SortMergeJoin [codegen id : 5]
Left keys [2]: [customer_sk#7, item_sk#8]
Right keys [2]: [customer_sk#14, item_sk#15]
Join type: FullOuter
Join condition: None

(23) Project [codegen id : 5]
Output [2]: [customer_sk#7, customer_sk#14]
Input [4]: [customer_sk#7, item_sk#8, customer_sk#14, item_sk#15]

(24) HashAggregate [codegen id : 5]
Input [2]: [customer_sk#7, customer_sk#14]
Keys: []
Functions [3]: [partial_sum(CASE WHEN (isnotnull(customer_sk#7) AND isnull(customer_sk#14)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (isnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (isnotnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END)]
Aggregate Attributes [3]: [sum#16, sum#17, sum#18]
Results [3]: [sum#19, sum#20, sum#21]

(25) Exchange
Input [3]: [sum#19, sum#20, sum#21]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=3]

(26) HashAggregate [codegen id : 6]
Input [3]: [sum#19, sum#20, sum#21]
Keys: []
Functions [3]: [sum(CASE WHEN (isnotnull(customer_sk#7) AND isnull(customer_sk#14)) THEN 1 ELSE 0 END), sum(CASE WHEN (isnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END), sum(CASE WHEN (isnotnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END)]
Aggregate Attributes [3]: [sum(CASE WHEN (isnotnull(customer_sk#7) AND isnull(customer_sk#14)) THEN 1 ELSE 0 END)#22, sum(CASE WHEN (isnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END)#23, sum(CASE WHEN (isnotnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END)#24]
Results [3]: [sum(CASE WHEN (isnotnull(customer_sk#7) AND isnull(customer_sk#14)) THEN 1 ELSE 0 END)#22 AS store_only#25, sum(CASE WHEN (isnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END)#23 AS catalog_only#26, sum(CASE WHEN (isnotnull(customer_sk#7) AND isnotnull(customer_sk#14)) THEN 1 ELSE 0 END)#24 AS store_and_catalog#27]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#3 IN dynamicpruning#4
BroadcastExchange (31)
+- * ColumnarToRow (30)
   +- CometProject (29)
      +- CometFilter (28)
         +- CometScan parquet spark_catalog.default.date_dim (27)


(27) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#5, d_month_seq#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_month_seq:int>

(28) CometFilter
Input [2]: [d_date_sk#5, d_month_seq#6]
Condition : (((isnotnull(d_month_seq#6) AND (d_month_seq#6 >= 1200)) AND (d_month_seq#6 <= 1211)) AND isnotnull(d_date_sk#5))

(29) CometProject
Input [2]: [d_date_sk#5, d_month_seq#6]
Arguments: [d_date_sk#5], [d_date_sk#5]

(30) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#5]

(31) BroadcastExchange
Input [1]: [d_date_sk#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

Subquery:2 Hosting operator id = 13 Hosting Expression = cs_sold_date_sk#11 IN dynamicpruning#4


