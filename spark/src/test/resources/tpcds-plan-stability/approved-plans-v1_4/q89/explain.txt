== Physical Plan ==
TakeOrderedAndProject (29)
+- * Project (28)
   +- * Filter (27)
      +- Window (26)
         +- * CometColumnarToRow (25)
            +- CometSort (24)
               +- CometExchange (23)
                  +- CometHashAggregate (22)
                     +- CometExchange (21)
                        +- CometHashAggregate (20)
                           +- CometProject (19)
                              +- CometBroadcastHashJoin (18)
                                 :- CometProject (14)
                                 :  +- CometBroadcastHashJoin (13)
                                 :     :- CometProject (8)
                                 :     :  +- CometBroadcastHashJoin (7)
                                 :     :     :- CometProject (3)
                                 :     :     :  +- CometFilter (2)
                                 :     :     :     +- CometScan parquet spark_catalog.default.item (1)
                                 :     :     +- CometBroadcastExchange (6)
                                 :     :        +- CometFilter (5)
                                 :     :           +- CometScan parquet spark_catalog.default.store_sales (4)
                                 :     +- CometBroadcastExchange (12)
                                 :        +- CometProject (11)
                                 :           +- CometFilter (10)
                                 :              +- CometScan parquet spark_catalog.default.date_dim (9)
                                 +- CometBroadcastExchange (17)
                                    +- CometFilter (16)
                                       +- CometScan parquet spark_catalog.default.store (15)


(1) CometScan parquet spark_catalog.default.item
Output [4]: [i_item_sk#1, i_brand#2, i_class#3, i_category#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_brand:string,i_class:string,i_category:string>

(2) CometFilter
Input [4]: [i_item_sk#1, i_brand#2, i_class#3, i_category#4]
Condition : (((staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_category#4, 50, true, false, true) IN (Books                                             ,Electronics                                       ,Sports                                            ) AND staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_class#3, 50, true, false, true) IN (computers                                         ,stereo                                            ,football                                          )) OR (staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_category#4, 50, true, false, true) IN (Men                                               ,Jewelry                                           ,Women                                             ) AND staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_class#3, 50, true, false, true) IN (shirts                                            ,birdal                                            ,dresses                                           ))) AND isnotnull(i_item_sk#1))

(3) CometProject
Input [4]: [i_item_sk#1, i_brand#2, i_class#3, i_category#4]
Arguments: [i_item_sk#1, i_brand#5, i_class#6, i_category#7], [i_item_sk#1, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_brand#2, 50, true, false, true) AS i_brand#5, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_class#3, 50, true, false, true) AS i_class#6, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_category#4, 50, true, false, true) AS i_category#7]

(4) CometScan parquet spark_catalog.default.store_sales
Output [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#11), dynamicpruningexpression(ss_sold_date_sk#11 IN dynamicpruning#12)]
PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_item_sk:int,ss_store_sk:int,ss_sales_price:decimal(7,2)>

(5) CometFilter
Input [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Condition : (isnotnull(ss_item_sk#8) AND isnotnull(ss_store_sk#9))

(6) CometBroadcastExchange
Input [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Arguments: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]

(7) CometBroadcastHashJoin
Left output [4]: [i_item_sk#1, i_brand#5, i_class#6, i_category#7]
Right output [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Arguments: [i_item_sk#1], [ss_item_sk#8], Inner, BuildRight

(8) CometProject
Input [8]: [i_item_sk#1, i_brand#5, i_class#6, i_category#7, ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Arguments: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11], [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]

(9) CometScan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#13, d_year#14, d_moy#15]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1999), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(10) CometFilter
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Condition : ((isnotnull(d_year#14) AND (d_year#14 = 1999)) AND isnotnull(d_date_sk#13))

(11) CometProject
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Arguments: [d_date_sk#13, d_moy#15], [d_date_sk#13, d_moy#15]

(12) CometBroadcastExchange
Input [2]: [d_date_sk#13, d_moy#15]
Arguments: [d_date_sk#13, d_moy#15]

(13) CometBroadcastHashJoin
Left output [6]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Right output [2]: [d_date_sk#13, d_moy#15]
Arguments: [ss_sold_date_sk#11], [d_date_sk#13], Inner, BuildRight

(14) CometProject
Input [8]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11, d_date_sk#13, d_moy#15]
Arguments: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15], [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15]

(15) CometScan parquet spark_catalog.default.store
Output [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_name:string,s_company_name:string>

(16) CometFilter
Input [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Condition : isnotnull(s_store_sk#16)

(17) CometBroadcastExchange
Input [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Arguments: [s_store_sk#16, s_store_name#17, s_company_name#18]

(18) CometBroadcastHashJoin
Left output [6]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15]
Right output [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Arguments: [ss_store_sk#9], [s_store_sk#16], Inner, BuildRight

(19) CometProject
Input [9]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15, s_store_sk#16, s_store_name#17, s_company_name#18]
Arguments: [i_brand#5, i_class#6, i_category#7, ss_sales_price#10, d_moy#15, s_store_name#17, s_company_name#18], [i_brand#5, i_class#6, i_category#7, ss_sales_price#10, d_moy#15, s_store_name#17, s_company_name#18]

(20) CometHashAggregate
Input [7]: [i_brand#5, i_class#6, i_category#7, ss_sales_price#10, d_moy#15, s_store_name#17, s_company_name#18]
Keys [6]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15]
Functions [1]: [partial_sum(UnscaledValue(ss_sales_price#10))]

(21) CometExchange
Input [7]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum#19]
Arguments: hashpartitioning(i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, 5), ENSURE_REQUIREMENTS, CometNativeShuffle, [plan_id=1]

(22) CometHashAggregate
Input [7]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum#19]
Keys [6]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15]
Functions [1]: [sum(UnscaledValue(ss_sales_price#10))]

(23) CometExchange
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, _w0#21]
Arguments: hashpartitioning(i_category#7, i_brand#5, s_store_name#17, s_company_name#18, 5), ENSURE_REQUIREMENTS, CometNativeShuffle, [plan_id=2]

(24) CometSort
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, _w0#21]
Arguments: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, _w0#21], [i_category#7 ASC NULLS FIRST, i_brand#5 ASC NULLS FIRST, s_store_name#17 ASC NULLS FIRST, s_company_name#18 ASC NULLS FIRST]

(25) CometColumnarToRow [codegen id : 1]
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, _w0#21]

(26) Window
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, _w0#21]
Arguments: [avg(_w0#21) windowspecdefinition(i_category#7, i_brand#5, s_store_name#17, s_company_name#18, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS avg_monthly_sales#22], [i_category#7, i_brand#5, s_store_name#17, s_company_name#18]

(27) Filter [codegen id : 2]
Input [9]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, _w0#21, avg_monthly_sales#22]
Condition : CASE WHEN NOT (avg_monthly_sales#22 = 0.000000) THEN ((abs((sum_sales#20 - avg_monthly_sales#22)) / avg_monthly_sales#22) > 0.1000000000000000) END

(28) Project [codegen id : 2]
Output [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, avg_monthly_sales#22]
Input [9]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, _w0#21, avg_monthly_sales#22]

(29) TakeOrderedAndProject
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, avg_monthly_sales#22]
Arguments: 100, [(sum_sales#20 - avg_monthly_sales#22) ASC NULLS FIRST, s_store_name#17 ASC NULLS FIRST], [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#20, avg_monthly_sales#22]

===== Subqueries =====

Subquery:1 Hosting operator id = 4 Hosting Expression = ss_sold_date_sk#11 IN dynamicpruning#12
BroadcastExchange (34)
+- * CometColumnarToRow (33)
   +- CometProject (32)
      +- CometFilter (31)
         +- CometScan parquet spark_catalog.default.date_dim (30)


(30) CometScan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#13, d_year#14, d_moy#15]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1999), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(31) CometFilter
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Condition : ((isnotnull(d_year#14) AND (d_year#14 = 1999)) AND isnotnull(d_date_sk#13))

(32) CometProject
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Arguments: [d_date_sk#13, d_moy#15], [d_date_sk#13, d_moy#15]

(33) CometColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#13, d_moy#15]

(34) BroadcastExchange
Input [2]: [d_date_sk#13, d_moy#15]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]


