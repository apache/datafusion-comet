== Physical Plan ==
* CometColumnarToRow (37)
+- CometSort (36)
   +- CometExchange (35)
      +- CometHashAggregate (34)
         +- CometExchange (33)
            +- CometHashAggregate (32)
               +- CometProject (31)
                  +- CometBroadcastHashJoin (30)
                     :- CometProject (25)
                     :  +- CometBroadcastHashJoin (24)
                     :     :- CometBroadcastExchange (4)
                     :     :  +- CometProject (3)
                     :     :     +- CometFilter (2)
                     :     :        +- CometScan [native_iceberg_compat] parquet spark_catalog.default.item (1)
                     :     +- CometUnion (23)
                     :        :- CometProject (12)
                     :        :  +- CometBroadcastHashJoin (11)
                     :        :     :- CometFilter (6)
                     :        :     :  +- CometScan [native_iceberg_compat] parquet spark_catalog.default.web_sales (5)
                     :        :     +- CometBroadcastExchange (10)
                     :        :        +- CometProject (9)
                     :        :           +- CometFilter (8)
                     :        :              +- CometScan [native_iceberg_compat] parquet spark_catalog.default.date_dim (7)
                     :        :- CometProject (17)
                     :        :  +- CometBroadcastHashJoin (16)
                     :        :     :- CometFilter (14)
                     :        :     :  +- CometScan [native_iceberg_compat] parquet spark_catalog.default.catalog_sales (13)
                     :        :     +- ReusedExchange (15)
                     :        +- CometProject (22)
                     :           +- CometBroadcastHashJoin (21)
                     :              :- CometFilter (19)
                     :              :  +- CometScan [native_iceberg_compat] parquet spark_catalog.default.store_sales (18)
                     :              +- ReusedExchange (20)
                     +- CometBroadcastExchange (29)
                        +- CometProject (28)
                           +- CometFilter (27)
                              +- CometScan [native_iceberg_compat] parquet spark_catalog.default.time_dim (26)


(1) CometScan [native_iceberg_compat] parquet spark_catalog.default.item
Output [4]: [i_item_sk#1, i_brand_id#2, i_brand#3, i_manager_id#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_manager_id), EqualTo(i_manager_id,1), IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_brand:string,i_manager_id:int>

(2) CometFilter
Input [4]: [i_item_sk#1, i_brand_id#2, i_brand#3, i_manager_id#4]
Condition : ((isnotnull(i_manager_id#4) AND (i_manager_id#4 = 1)) AND isnotnull(i_item_sk#1))

(3) CometProject
Input [4]: [i_item_sk#1, i_brand_id#2, i_brand#3, i_manager_id#4]
Arguments: [i_item_sk#1, i_brand_id#2, i_brand#5], [i_item_sk#1, i_brand_id#2, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_brand#3, 50, true, false, true) AS i_brand#5]

(4) CometBroadcastExchange
Input [3]: [i_item_sk#1, i_brand_id#2, i_brand#5]
Arguments: [i_item_sk#1, i_brand_id#2, i_brand#5]

(5) CometScan [native_iceberg_compat] parquet spark_catalog.default.web_sales
Output [4]: [ws_sold_time_sk#6, ws_item_sk#7, ws_ext_sales_price#8, ws_sold_date_sk#9]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#9), dynamicpruningexpression(ws_sold_date_sk#9 IN dynamicpruning#10)]
PushedFilters: [IsNotNull(ws_item_sk), IsNotNull(ws_sold_time_sk)]
ReadSchema: struct<ws_sold_time_sk:int,ws_item_sk:int,ws_ext_sales_price:decimal(7,2)>

(6) CometFilter
Input [4]: [ws_sold_time_sk#6, ws_item_sk#7, ws_ext_sales_price#8, ws_sold_date_sk#9]
Condition : (isnotnull(ws_item_sk#7) AND isnotnull(ws_sold_time_sk#6))

(7) CometScan [native_iceberg_compat] parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#11, d_year#12, d_moy#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_moy), IsNotNull(d_year), EqualTo(d_moy,11), EqualTo(d_year,1999), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(8) CometFilter
Input [3]: [d_date_sk#11, d_year#12, d_moy#13]
Condition : ((((isnotnull(d_moy#13) AND isnotnull(d_year#12)) AND (d_moy#13 = 11)) AND (d_year#12 = 1999)) AND isnotnull(d_date_sk#11))

(9) CometProject
Input [3]: [d_date_sk#11, d_year#12, d_moy#13]
Arguments: [d_date_sk#11], [d_date_sk#11]

(10) CometBroadcastExchange
Input [1]: [d_date_sk#11]
Arguments: [d_date_sk#11]

(11) CometBroadcastHashJoin
Left output [4]: [ws_sold_time_sk#6, ws_item_sk#7, ws_ext_sales_price#8, ws_sold_date_sk#9]
Right output [1]: [d_date_sk#11]
Arguments: [ws_sold_date_sk#9], [d_date_sk#11], Inner, BuildRight

(12) CometProject
Input [5]: [ws_sold_time_sk#6, ws_item_sk#7, ws_ext_sales_price#8, ws_sold_date_sk#9, d_date_sk#11]
Arguments: [ext_price#14, sold_item_sk#15, time_sk#16], [ws_ext_sales_price#8 AS ext_price#14, ws_item_sk#7 AS sold_item_sk#15, ws_sold_time_sk#6 AS time_sk#16]

(13) CometScan [native_iceberg_compat] parquet spark_catalog.default.catalog_sales
Output [4]: [cs_sold_time_sk#17, cs_item_sk#18, cs_ext_sales_price#19, cs_sold_date_sk#20]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#20), dynamicpruningexpression(cs_sold_date_sk#20 IN dynamicpruning#21)]
PushedFilters: [IsNotNull(cs_item_sk), IsNotNull(cs_sold_time_sk)]
ReadSchema: struct<cs_sold_time_sk:int,cs_item_sk:int,cs_ext_sales_price:decimal(7,2)>

(14) CometFilter
Input [4]: [cs_sold_time_sk#17, cs_item_sk#18, cs_ext_sales_price#19, cs_sold_date_sk#20]
Condition : (isnotnull(cs_item_sk#18) AND isnotnull(cs_sold_time_sk#17))

(15) ReusedExchange [Reuses operator id: 10]
Output [1]: [d_date_sk#22]

(16) CometBroadcastHashJoin
Left output [4]: [cs_sold_time_sk#17, cs_item_sk#18, cs_ext_sales_price#19, cs_sold_date_sk#20]
Right output [1]: [d_date_sk#22]
Arguments: [cs_sold_date_sk#20], [d_date_sk#22], Inner, BuildRight

(17) CometProject
Input [5]: [cs_sold_time_sk#17, cs_item_sk#18, cs_ext_sales_price#19, cs_sold_date_sk#20, d_date_sk#22]
Arguments: [ext_price#23, sold_item_sk#24, time_sk#25], [cs_ext_sales_price#19 AS ext_price#23, cs_item_sk#18 AS sold_item_sk#24, cs_sold_time_sk#17 AS time_sk#25]

(18) CometScan [native_iceberg_compat] parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#26, ss_item_sk#27, ss_ext_sales_price#28, ss_sold_date_sk#29]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#29), dynamicpruningexpression(ss_sold_date_sk#29 IN dynamicpruning#30)]
PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_time_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>

(19) CometFilter
Input [4]: [ss_sold_time_sk#26, ss_item_sk#27, ss_ext_sales_price#28, ss_sold_date_sk#29]
Condition : (isnotnull(ss_item_sk#27) AND isnotnull(ss_sold_time_sk#26))

(20) ReusedExchange [Reuses operator id: 10]
Output [1]: [d_date_sk#31]

(21) CometBroadcastHashJoin
Left output [4]: [ss_sold_time_sk#26, ss_item_sk#27, ss_ext_sales_price#28, ss_sold_date_sk#29]
Right output [1]: [d_date_sk#31]
Arguments: [ss_sold_date_sk#29], [d_date_sk#31], Inner, BuildRight

(22) CometProject
Input [5]: [ss_sold_time_sk#26, ss_item_sk#27, ss_ext_sales_price#28, ss_sold_date_sk#29, d_date_sk#31]
Arguments: [ext_price#32, sold_item_sk#33, time_sk#34], [ss_ext_sales_price#28 AS ext_price#32, ss_item_sk#27 AS sold_item_sk#33, ss_sold_time_sk#26 AS time_sk#34]

(23) CometUnion
Child 0 Input [3]: [ext_price#14, sold_item_sk#15, time_sk#16]
Child 1 Input [3]: [ext_price#23, sold_item_sk#24, time_sk#25]
Child 2 Input [3]: [ext_price#32, sold_item_sk#33, time_sk#34]

(24) CometBroadcastHashJoin
Left output [3]: [i_item_sk#1, i_brand_id#2, i_brand#5]
Right output [3]: [ext_price#14, sold_item_sk#15, time_sk#16]
Arguments: [i_item_sk#1], [sold_item_sk#15], Inner, BuildLeft

(25) CometProject
Input [6]: [i_item_sk#1, i_brand_id#2, i_brand#5, ext_price#14, sold_item_sk#15, time_sk#16]
Arguments: [i_brand_id#2, i_brand#5, ext_price#14, time_sk#16], [i_brand_id#2, i_brand#5, ext_price#14, time_sk#16]

(26) CometScan [native_iceberg_compat] parquet spark_catalog.default.time_dim
Output [4]: [t_time_sk#35, t_hour#36, t_minute#37, t_meal_time#38]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int,t_meal_time:string>

(27) CometFilter
Input [4]: [t_time_sk#35, t_hour#36, t_minute#37, t_meal_time#38]
Condition : (((staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, t_meal_time#38, 20, true, false, true) = breakfast           ) OR (staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, t_meal_time#38, 20, true, false, true) = dinner              )) AND isnotnull(t_time_sk#35))

(28) CometProject
Input [4]: [t_time_sk#35, t_hour#36, t_minute#37, t_meal_time#38]
Arguments: [t_time_sk#35, t_hour#36, t_minute#37], [t_time_sk#35, t_hour#36, t_minute#37]

(29) CometBroadcastExchange
Input [3]: [t_time_sk#35, t_hour#36, t_minute#37]
Arguments: [t_time_sk#35, t_hour#36, t_minute#37]

(30) CometBroadcastHashJoin
Left output [4]: [i_brand_id#2, i_brand#5, ext_price#14, time_sk#16]
Right output [3]: [t_time_sk#35, t_hour#36, t_minute#37]
Arguments: [time_sk#16], [t_time_sk#35], Inner, BuildRight

(31) CometProject
Input [7]: [i_brand_id#2, i_brand#5, ext_price#14, time_sk#16, t_time_sk#35, t_hour#36, t_minute#37]
Arguments: [i_brand_id#2, i_brand#5, ext_price#14, t_hour#36, t_minute#37], [i_brand_id#2, i_brand#5, ext_price#14, t_hour#36, t_minute#37]

(32) CometHashAggregate
Input [5]: [i_brand_id#2, i_brand#5, ext_price#14, t_hour#36, t_minute#37]
Keys [4]: [i_brand#5, i_brand_id#2, t_hour#36, t_minute#37]
Functions [1]: [partial_sum(UnscaledValue(ext_price#14))]

(33) CometExchange
Input [5]: [i_brand#5, i_brand_id#2, t_hour#36, t_minute#37, sum#39]
Arguments: hashpartitioning(i_brand#5, i_brand_id#2, t_hour#36, t_minute#37, 5), ENSURE_REQUIREMENTS, CometNativeShuffle, [plan_id=1]

(34) CometHashAggregate
Input [5]: [i_brand#5, i_brand_id#2, t_hour#36, t_minute#37, sum#39]
Keys [4]: [i_brand#5, i_brand_id#2, t_hour#36, t_minute#37]
Functions [1]: [sum(UnscaledValue(ext_price#14))]

(35) CometExchange
Input [5]: [brand_id#40, brand#41, t_hour#36, t_minute#37, ext_price#42]
Arguments: rangepartitioning(ext_price#42 DESC NULLS LAST, brand_id#40 ASC NULLS FIRST, 5), ENSURE_REQUIREMENTS, CometNativeShuffle, [plan_id=2]

(36) CometSort
Input [5]: [brand_id#40, brand#41, t_hour#36, t_minute#37, ext_price#42]
Arguments: [brand_id#40, brand#41, t_hour#36, t_minute#37, ext_price#42], [ext_price#42 DESC NULLS LAST, brand_id#40 ASC NULLS FIRST]

(37) CometColumnarToRow [codegen id : 1]
Input [5]: [brand_id#40, brand#41, t_hour#36, t_minute#37, ext_price#42]

===== Subqueries =====

Subquery:1 Hosting operator id = 5 Hosting Expression = ws_sold_date_sk#9 IN dynamicpruning#10
BroadcastExchange (42)
+- * CometColumnarToRow (41)
   +- CometProject (40)
      +- CometFilter (39)
         +- CometScan [native_iceberg_compat] parquet spark_catalog.default.date_dim (38)


(38) CometScan [native_iceberg_compat] parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#11, d_year#12, d_moy#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_moy), IsNotNull(d_year), EqualTo(d_moy,11), EqualTo(d_year,1999), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(39) CometFilter
Input [3]: [d_date_sk#11, d_year#12, d_moy#13]
Condition : ((((isnotnull(d_moy#13) AND isnotnull(d_year#12)) AND (d_moy#13 = 11)) AND (d_year#12 = 1999)) AND isnotnull(d_date_sk#11))

(40) CometProject
Input [3]: [d_date_sk#11, d_year#12, d_moy#13]
Arguments: [d_date_sk#11], [d_date_sk#11]

(41) CometColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#11]

(42) BroadcastExchange
Input [1]: [d_date_sk#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

Subquery:2 Hosting operator id = 13 Hosting Expression = cs_sold_date_sk#20 IN dynamicpruning#10

Subquery:3 Hosting operator id = 18 Hosting Expression = ss_sold_date_sk#29 IN dynamicpruning#10


