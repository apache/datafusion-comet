== Physical Plan ==
TakeOrderedAndProject (61)
+- * Project (60)
   +- * BroadcastHashJoin Inner BuildRight (59)
      :- * Project (45)
      :  +- * BroadcastHashJoin Inner BuildRight (44)
      :     :- * HashAggregate (30)
      :     :  +- Exchange (29)
      :     :     +- * HashAggregate (28)
      :     :        +- * Project (27)
      :     :           +- * BroadcastHashJoin Inner BuildRight (26)
      :     :              :- * Project (9)
      :     :              :  +- * BroadcastHashJoin Inner BuildRight (8)
      :     :              :     :- * Filter (3)
      :     :              :     :  +- * ColumnarToRow (2)
      :     :              :     :     +- Scan parquet spark_catalog.default.store_returns (1)
      :     :              :     +- BroadcastExchange (7)
      :     :              :        +- * Filter (6)
      :     :              :           +- * ColumnarToRow (5)
      :     :              :              +- Scan parquet spark_catalog.default.item (4)
      :     :              +- BroadcastExchange (25)
      :     :                 +- * Project (24)
      :     :                    +- * BroadcastHashJoin LeftSemi BuildRight (23)
      :     :                       :- * Filter (12)
      :     :                       :  +- * ColumnarToRow (11)
      :     :                       :     +- Scan parquet spark_catalog.default.date_dim (10)
      :     :                       +- BroadcastExchange (22)
      :     :                          +- * Project (21)
      :     :                             +- * BroadcastHashJoin LeftSemi BuildRight (20)
      :     :                                :- * ColumnarToRow (14)
      :     :                                :  +- Scan parquet spark_catalog.default.date_dim (13)
      :     :                                +- BroadcastExchange (19)
      :     :                                   +- * Project (18)
      :     :                                      +- * Filter (17)
      :     :                                         +- * ColumnarToRow (16)
      :     :                                            +- Scan parquet spark_catalog.default.date_dim (15)
      :     +- BroadcastExchange (43)
      :        +- * HashAggregate (42)
      :           +- Exchange (41)
      :              +- * HashAggregate (40)
      :                 +- * Project (39)
      :                    +- * BroadcastHashJoin Inner BuildRight (38)
      :                       :- * Project (36)
      :                       :  +- * BroadcastHashJoin Inner BuildRight (35)
      :                       :     :- * Filter (33)
      :                       :     :  +- * ColumnarToRow (32)
      :                       :     :     +- Scan parquet spark_catalog.default.catalog_returns (31)
      :                       :     +- ReusedExchange (34)
      :                       +- ReusedExchange (37)
      +- BroadcastExchange (58)
         +- * HashAggregate (57)
            +- Exchange (56)
               +- * HashAggregate (55)
                  +- * Project (54)
                     +- * BroadcastHashJoin Inner BuildRight (53)
                        :- * Project (51)
                        :  +- * BroadcastHashJoin Inner BuildRight (50)
                        :     :- * Filter (48)
                        :     :  +- * ColumnarToRow (47)
                        :     :     +- Scan parquet spark_catalog.default.web_returns (46)
                        :     +- ReusedExchange (49)
                        +- ReusedExchange (52)


(1) Scan parquet spark_catalog.default.store_returns
Output [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(sr_returned_date_sk#3)]
PushedFilters: [IsNotNull(sr_item_sk)]
ReadSchema: struct<sr_item_sk:int,sr_return_quantity:int>

(2) ColumnarToRow [codegen id : 5]
Input [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]

(3) Filter [codegen id : 5]
Input [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Condition : isnotnull(sr_item_sk#1)

(4) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#4, i_item_id#5]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_item_id)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(5) ColumnarToRow [codegen id : 1]
Input [2]: [i_item_sk#4, i_item_id#5]

(6) Filter [codegen id : 1]
Input [2]: [i_item_sk#4, i_item_id#5]
Condition : (isnotnull(i_item_sk#4) AND isnotnull(i_item_id#5))

(7) BroadcastExchange
Input [2]: [i_item_sk#4, i_item_id#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(8) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [sr_item_sk#1]
Right keys [1]: [i_item_sk#4]
Join type: Inner
Join condition: None

(9) Project [codegen id : 5]
Output [3]: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#5]
Input [5]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3, i_item_sk#4, i_item_id#5]

(10) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#6, d_date#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(11) ColumnarToRow [codegen id : 4]
Input [2]: [d_date_sk#6, d_date#7]

(12) Filter [codegen id : 4]
Input [2]: [d_date_sk#6, d_date#7]
Condition : isnotnull(d_date_sk#6)

(13) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#8, d_week_seq#9]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(14) ColumnarToRow [codegen id : 3]
Input [2]: [d_date#8, d_week_seq#9]

(15) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#10, d_week_seq#11]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(16) ColumnarToRow [codegen id : 2]
Input [2]: [d_date#10, d_week_seq#11]

(17) Filter [codegen id : 2]
Input [2]: [d_date#10, d_week_seq#11]
Condition : cast(d_date#10 as string) IN (2000-06-30,2000-09-27,2000-11-17)

(18) Project [codegen id : 2]
Output [1]: [d_week_seq#11]
Input [2]: [d_date#10, d_week_seq#11]

(19) BroadcastExchange
Input [1]: [d_week_seq#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(20) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [d_week_seq#9]
Right keys [1]: [d_week_seq#11]
Join type: LeftSemi
Join condition: None

(21) Project [codegen id : 3]
Output [1]: [d_date#8]
Input [2]: [d_date#8, d_week_seq#9]

(22) BroadcastExchange
Input [1]: [d_date#8]
Arguments: HashedRelationBroadcastMode(List(input[0, date, true]),false), [plan_id=3]

(23) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [d_date#7]
Right keys [1]: [d_date#8]
Join type: LeftSemi
Join condition: None

(24) Project [codegen id : 4]
Output [1]: [d_date_sk#6]
Input [2]: [d_date_sk#6, d_date#7]

(25) BroadcastExchange
Input [1]: [d_date_sk#6]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(26) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [sr_returned_date_sk#3]
Right keys [1]: [d_date_sk#6]
Join type: Inner
Join condition: None

(27) Project [codegen id : 5]
Output [2]: [sr_return_quantity#2, i_item_id#5]
Input [4]: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#5, d_date_sk#6]

(28) HashAggregate [codegen id : 5]
Input [2]: [sr_return_quantity#2, i_item_id#5]
Keys [1]: [i_item_id#5]
Functions [1]: [partial_sum(sr_return_quantity#2)]
Aggregate Attributes [1]: [sum#12]
Results [2]: [i_item_id#5, sum#13]

(29) Exchange
Input [2]: [i_item_id#5, sum#13]
Arguments: hashpartitioning(i_item_id#5, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(30) HashAggregate [codegen id : 18]
Input [2]: [i_item_id#5, sum#13]
Keys [1]: [i_item_id#5]
Functions [1]: [sum(sr_return_quantity#2)]
Aggregate Attributes [1]: [sum(sr_return_quantity#2)#14]
Results [2]: [i_item_id#5 AS item_id#15, sum(sr_return_quantity#2)#14 AS sr_item_qty#16]

(31) Scan parquet spark_catalog.default.catalog_returns
Output [3]: [cr_item_sk#17, cr_return_quantity#18, cr_returned_date_sk#19]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cr_returned_date_sk#19)]
PushedFilters: [IsNotNull(cr_item_sk)]
ReadSchema: struct<cr_item_sk:int,cr_return_quantity:int>

(32) ColumnarToRow [codegen id : 10]
Input [3]: [cr_item_sk#17, cr_return_quantity#18, cr_returned_date_sk#19]

(33) Filter [codegen id : 10]
Input [3]: [cr_item_sk#17, cr_return_quantity#18, cr_returned_date_sk#19]
Condition : isnotnull(cr_item_sk#17)

(34) ReusedExchange [Reuses operator id: 7]
Output [2]: [i_item_sk#20, i_item_id#21]

(35) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [cr_item_sk#17]
Right keys [1]: [i_item_sk#20]
Join type: Inner
Join condition: None

(36) Project [codegen id : 10]
Output [3]: [cr_return_quantity#18, cr_returned_date_sk#19, i_item_id#21]
Input [5]: [cr_item_sk#17, cr_return_quantity#18, cr_returned_date_sk#19, i_item_sk#20, i_item_id#21]

(37) ReusedExchange [Reuses operator id: 25]
Output [1]: [d_date_sk#22]

(38) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [cr_returned_date_sk#19]
Right keys [1]: [d_date_sk#22]
Join type: Inner
Join condition: None

(39) Project [codegen id : 10]
Output [2]: [cr_return_quantity#18, i_item_id#21]
Input [4]: [cr_return_quantity#18, cr_returned_date_sk#19, i_item_id#21, d_date_sk#22]

(40) HashAggregate [codegen id : 10]
Input [2]: [cr_return_quantity#18, i_item_id#21]
Keys [1]: [i_item_id#21]
Functions [1]: [partial_sum(cr_return_quantity#18)]
Aggregate Attributes [1]: [sum#23]
Results [2]: [i_item_id#21, sum#24]

(41) Exchange
Input [2]: [i_item_id#21, sum#24]
Arguments: hashpartitioning(i_item_id#21, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(42) HashAggregate [codegen id : 11]
Input [2]: [i_item_id#21, sum#24]
Keys [1]: [i_item_id#21]
Functions [1]: [sum(cr_return_quantity#18)]
Aggregate Attributes [1]: [sum(cr_return_quantity#18)#25]
Results [2]: [i_item_id#21 AS item_id#26, sum(cr_return_quantity#18)#25 AS cr_item_qty#27]

(43) BroadcastExchange
Input [2]: [item_id#26, cr_item_qty#27]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=7]

(44) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [item_id#15]
Right keys [1]: [item_id#26]
Join type: Inner
Join condition: None

(45) Project [codegen id : 18]
Output [3]: [item_id#15, sr_item_qty#16, cr_item_qty#27]
Input [4]: [item_id#15, sr_item_qty#16, item_id#26, cr_item_qty#27]

(46) Scan parquet spark_catalog.default.web_returns
Output [3]: [wr_item_sk#28, wr_return_quantity#29, wr_returned_date_sk#30]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(wr_returned_date_sk#30)]
PushedFilters: [IsNotNull(wr_item_sk)]
ReadSchema: struct<wr_item_sk:int,wr_return_quantity:int>

(47) ColumnarToRow [codegen id : 16]
Input [3]: [wr_item_sk#28, wr_return_quantity#29, wr_returned_date_sk#30]

(48) Filter [codegen id : 16]
Input [3]: [wr_item_sk#28, wr_return_quantity#29, wr_returned_date_sk#30]
Condition : isnotnull(wr_item_sk#28)

(49) ReusedExchange [Reuses operator id: 7]
Output [2]: [i_item_sk#31, i_item_id#32]

(50) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [wr_item_sk#28]
Right keys [1]: [i_item_sk#31]
Join type: Inner
Join condition: None

(51) Project [codegen id : 16]
Output [3]: [wr_return_quantity#29, wr_returned_date_sk#30, i_item_id#32]
Input [5]: [wr_item_sk#28, wr_return_quantity#29, wr_returned_date_sk#30, i_item_sk#31, i_item_id#32]

(52) ReusedExchange [Reuses operator id: 25]
Output [1]: [d_date_sk#33]

(53) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [wr_returned_date_sk#30]
Right keys [1]: [d_date_sk#33]
Join type: Inner
Join condition: None

(54) Project [codegen id : 16]
Output [2]: [wr_return_quantity#29, i_item_id#32]
Input [4]: [wr_return_quantity#29, wr_returned_date_sk#30, i_item_id#32, d_date_sk#33]

(55) HashAggregate [codegen id : 16]
Input [2]: [wr_return_quantity#29, i_item_id#32]
Keys [1]: [i_item_id#32]
Functions [1]: [partial_sum(wr_return_quantity#29)]
Aggregate Attributes [1]: [sum#34]
Results [2]: [i_item_id#32, sum#35]

(56) Exchange
Input [2]: [i_item_id#32, sum#35]
Arguments: hashpartitioning(i_item_id#32, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(57) HashAggregate [codegen id : 17]
Input [2]: [i_item_id#32, sum#35]
Keys [1]: [i_item_id#32]
Functions [1]: [sum(wr_return_quantity#29)]
Aggregate Attributes [1]: [sum(wr_return_quantity#29)#36]
Results [2]: [i_item_id#32 AS item_id#37, sum(wr_return_quantity#29)#36 AS wr_item_qty#38]

(58) BroadcastExchange
Input [2]: [item_id#37, wr_item_qty#38]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=9]

(59) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [item_id#15]
Right keys [1]: [item_id#37]
Join type: Inner
Join condition: None

(60) Project [codegen id : 18]
Output [8]: [item_id#15, sr_item_qty#16, (((cast(sr_item_qty#16 as double) / cast(((sr_item_qty#16 + cr_item_qty#27) + wr_item_qty#38) as double)) / 3.0) * 100.0) AS sr_dev#39, cr_item_qty#27, (((cast(cr_item_qty#27 as double) / cast(((sr_item_qty#16 + cr_item_qty#27) + wr_item_qty#38) as double)) / 3.0) * 100.0) AS cr_dev#40, wr_item_qty#38, (((cast(wr_item_qty#38 as double) / cast(((sr_item_qty#16 + cr_item_qty#27) + wr_item_qty#38) as double)) / 3.0) * 100.0) AS wr_dev#41, (cast(((sr_item_qty#16 + cr_item_qty#27) + wr_item_qty#38) as decimal(20,0)) / 3.0) AS average#42]
Input [5]: [item_id#15, sr_item_qty#16, cr_item_qty#27, item_id#37, wr_item_qty#38]

(61) TakeOrderedAndProject
Input [8]: [item_id#15, sr_item_qty#16, sr_dev#39, cr_item_qty#27, cr_dev#40, wr_item_qty#38, wr_dev#41, average#42]
Arguments: 100, [item_id#15 ASC NULLS FIRST, sr_item_qty#16 ASC NULLS FIRST], [item_id#15, sr_item_qty#16, sr_dev#39, cr_item_qty#27, cr_dev#40, wr_item_qty#38, wr_dev#41, average#42]

