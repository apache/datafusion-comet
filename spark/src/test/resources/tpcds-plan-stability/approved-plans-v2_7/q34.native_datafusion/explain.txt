== Physical Plan ==
* Sort (36)
+- Exchange (35)
   +- * Project (34)
      +- * BroadcastHashJoin Inner BuildRight (33)
         :- * Filter (28)
         :  +- * HashAggregate (27)
         :     +- Exchange (26)
         :        +- * HashAggregate (25)
         :           +- * Project (24)
         :              +- * BroadcastHashJoin Inner BuildRight (23)
         :                 :- * Project (17)
         :                 :  +- * BroadcastHashJoin Inner BuildRight (16)
         :                 :     :- * Project (10)
         :                 :     :  +- * BroadcastHashJoin Inner BuildRight (9)
         :                 :     :     :- * Filter (3)
         :                 :     :     :  +- * ColumnarToRow (2)
         :                 :     :     :     +- Scan parquet spark_catalog.default.store_sales (1)
         :                 :     :     +- BroadcastExchange (8)
         :                 :     :        +- * Project (7)
         :                 :     :           +- * Filter (6)
         :                 :     :              +- * ColumnarToRow (5)
         :                 :     :                 +- Scan parquet spark_catalog.default.date_dim (4)
         :                 :     +- BroadcastExchange (15)
         :                 :        +- * Project (14)
         :                 :           +- * Filter (13)
         :                 :              +- * ColumnarToRow (12)
         :                 :                 +- Scan parquet spark_catalog.default.store (11)
         :                 +- BroadcastExchange (22)
         :                    +- * Project (21)
         :                       +- * Filter (20)
         :                          +- * ColumnarToRow (19)
         :                             +- Scan parquet spark_catalog.default.household_demographics (18)
         +- BroadcastExchange (32)
            +- * Filter (31)
               +- * ColumnarToRow (30)
                  +- Scan parquet spark_catalog.default.customer (29)


(1) Scan parquet spark_catalog.default.store_sales
Output [5]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_sold_date_sk#5]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#5)]
PushedFilters: [IsNotNull(ss_store_sk), IsNotNull(ss_hdemo_sk), IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_hdemo_sk:int,ss_store_sk:int,ss_ticket_number:int>

(2) ColumnarToRow [codegen id : 4]
Input [5]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_sold_date_sk#5]

(3) Filter [codegen id : 4]
Input [5]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_sold_date_sk#5]
Condition : ((isnotnull(ss_store_sk#3) AND isnotnull(ss_hdemo_sk#2)) AND isnotnull(ss_customer_sk#1))

(4) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#6, d_year#7, d_dom#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [Or(And(GreaterThanOrEqual(d_dom,1),LessThanOrEqual(d_dom,3)),And(GreaterThanOrEqual(d_dom,25),LessThanOrEqual(d_dom,28))), In(d_year, [1999,2000,2001]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_dom:int>

(5) ColumnarToRow [codegen id : 1]
Input [3]: [d_date_sk#6, d_year#7, d_dom#8]

(6) Filter [codegen id : 1]
Input [3]: [d_date_sk#6, d_year#7, d_dom#8]
Condition : (((((d_dom#8 >= 1) AND (d_dom#8 <= 3)) OR ((d_dom#8 >= 25) AND (d_dom#8 <= 28))) AND d_year#7 IN (1999,2000,2001)) AND isnotnull(d_date_sk#6))

(7) Project [codegen id : 1]
Output [1]: [d_date_sk#6]
Input [3]: [d_date_sk#6, d_year#7, d_dom#8]

(8) BroadcastExchange
Input [1]: [d_date_sk#6]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(9) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_sold_date_sk#5]
Right keys [1]: [d_date_sk#6]
Join type: Inner
Join condition: None

(10) Project [codegen id : 4]
Output [4]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_ticket_number#4]
Input [6]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_ticket_number#4, ss_sold_date_sk#5, d_date_sk#6]

(11) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#9, s_county#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_county), EqualTo(s_county,Williamson County), IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_county:string>

(12) ColumnarToRow [codegen id : 2]
Input [2]: [s_store_sk#9, s_county#10]

(13) Filter [codegen id : 2]
Input [2]: [s_store_sk#9, s_county#10]
Condition : ((isnotnull(s_county#10) AND (s_county#10 = Williamson County)) AND isnotnull(s_store_sk#9))

(14) Project [codegen id : 2]
Output [1]: [s_store_sk#9]
Input [2]: [s_store_sk#9, s_county#10]

(15) BroadcastExchange
Input [1]: [s_store_sk#9]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(16) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#9]
Join type: Inner
Join condition: None

(17) Project [codegen id : 4]
Output [3]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_ticket_number#4]
Input [5]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_ticket_number#4, s_store_sk#9]

(18) Scan parquet spark_catalog.default.household_demographics
Output [4]: [hd_demo_sk#11, hd_buy_potential#12, hd_dep_count#13, hd_vehicle_count#14]
Batched: true
Location [not included in comparison]/{warehouse_dir}/household_demographics]
PushedFilters: [IsNotNull(hd_vehicle_count), Or(EqualTo(hd_buy_potential,>10000         ),EqualTo(hd_buy_potential,unknown        )), GreaterThan(hd_vehicle_count,0), IsNotNull(hd_demo_sk)]
ReadSchema: struct<hd_demo_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_count:int>

(19) ColumnarToRow [codegen id : 3]
Input [4]: [hd_demo_sk#11, hd_buy_potential#12, hd_dep_count#13, hd_vehicle_count#14]

(20) Filter [codegen id : 3]
Input [4]: [hd_demo_sk#11, hd_buy_potential#12, hd_dep_count#13, hd_vehicle_count#14]
Condition : ((((isnotnull(hd_vehicle_count#14) AND ((hd_buy_potential#12 = >10000         ) OR (hd_buy_potential#12 = unknown        ))) AND (hd_vehicle_count#14 > 0)) AND CASE WHEN (hd_vehicle_count#14 > 0) THEN ((cast(hd_dep_count#13 as double) / cast(hd_vehicle_count#14 as double)) > 1.2) END) AND isnotnull(hd_demo_sk#11))

(21) Project [codegen id : 3]
Output [1]: [hd_demo_sk#11]
Input [4]: [hd_demo_sk#11, hd_buy_potential#12, hd_dep_count#13, hd_vehicle_count#14]

(22) BroadcastExchange
Input [1]: [hd_demo_sk#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(23) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#11]
Join type: Inner
Join condition: None

(24) Project [codegen id : 4]
Output [2]: [ss_customer_sk#1, ss_ticket_number#4]
Input [4]: [ss_customer_sk#1, ss_hdemo_sk#2, ss_ticket_number#4, hd_demo_sk#11]

(25) HashAggregate [codegen id : 4]
Input [2]: [ss_customer_sk#1, ss_ticket_number#4]
Keys [2]: [ss_ticket_number#4, ss_customer_sk#1]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#15]
Results [3]: [ss_ticket_number#4, ss_customer_sk#1, count#16]

(26) Exchange
Input [3]: [ss_ticket_number#4, ss_customer_sk#1, count#16]
Arguments: hashpartitioning(ss_ticket_number#4, ss_customer_sk#1, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(27) HashAggregate [codegen id : 6]
Input [3]: [ss_ticket_number#4, ss_customer_sk#1, count#16]
Keys [2]: [ss_ticket_number#4, ss_customer_sk#1]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#17]
Results [3]: [ss_ticket_number#4, ss_customer_sk#1, count(1)#17 AS cnt#18]

(28) Filter [codegen id : 6]
Input [3]: [ss_ticket_number#4, ss_customer_sk#1, cnt#18]
Condition : ((cnt#18 >= 15) AND (cnt#18 <= 20))

(29) Scan parquet spark_catalog.default.customer
Output [5]: [c_customer_sk#19, c_salutation#20, c_first_name#21, c_last_name#22, c_preferred_cust_flag#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_salutation:string,c_first_name:string,c_last_name:string,c_preferred_cust_flag:string>

(30) ColumnarToRow [codegen id : 5]
Input [5]: [c_customer_sk#19, c_salutation#20, c_first_name#21, c_last_name#22, c_preferred_cust_flag#23]

(31) Filter [codegen id : 5]
Input [5]: [c_customer_sk#19, c_salutation#20, c_first_name#21, c_last_name#22, c_preferred_cust_flag#23]
Condition : isnotnull(c_customer_sk#19)

(32) BroadcastExchange
Input [5]: [c_customer_sk#19, c_salutation#20, c_first_name#21, c_last_name#22, c_preferred_cust_flag#23]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(33) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_customer_sk#1]
Right keys [1]: [c_customer_sk#19]
Join type: Inner
Join condition: None

(34) Project [codegen id : 6]
Output [6]: [c_last_name#22, c_first_name#21, c_salutation#20, c_preferred_cust_flag#23, ss_ticket_number#4, cnt#18]
Input [8]: [ss_ticket_number#4, ss_customer_sk#1, cnt#18, c_customer_sk#19, c_salutation#20, c_first_name#21, c_last_name#22, c_preferred_cust_flag#23]

(35) Exchange
Input [6]: [c_last_name#22, c_first_name#21, c_salutation#20, c_preferred_cust_flag#23, ss_ticket_number#4, cnt#18]
Arguments: rangepartitioning(c_last_name#22 ASC NULLS FIRST, c_first_name#21 ASC NULLS FIRST, c_salutation#20 ASC NULLS FIRST, c_preferred_cust_flag#23 DESC NULLS LAST, ss_ticket_number#4 ASC NULLS FIRST, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(36) Sort [codegen id : 7]
Input [6]: [c_last_name#22, c_first_name#21, c_salutation#20, c_preferred_cust_flag#23, ss_ticket_number#4, cnt#18]
Arguments: [c_last_name#22 ASC NULLS FIRST, c_first_name#21 ASC NULLS FIRST, c_salutation#20 ASC NULLS FIRST, c_preferred_cust_flag#23 DESC NULLS LAST, ss_ticket_number#4 ASC NULLS FIRST], true, 0

