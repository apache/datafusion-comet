== Physical Plan ==
TakeOrderedAndProject (53)
+- * Project (52)
   +- * BroadcastHashJoin Inner BuildRight (51)
      :- * Project (36)
      :  +- * BroadcastHashJoin Inner BuildRight (35)
      :     :- * Filter (20)
      :     :  +- * HashAggregate (19)
      :     :     +- Exchange (18)
      :     :        +- * ColumnarToRow (17)
      :     :           +- CometHashAggregate (16)
      :     :              +- CometProject (15)
      :     :                 +- CometBroadcastHashJoin (14)
      :     :                    :- CometProject (7)
      :     :                    :  +- CometBroadcastHashJoin (6)
      :     :                    :     :- CometFilter (2)
      :     :                    :     :  +- CometScan parquet spark_catalog.default.store_sales (1)
      :     :                    :     +- CometBroadcastExchange (5)
      :     :                    :        +- CometFilter (4)
      :     :                    :           +- CometScan parquet spark_catalog.default.item (3)
      :     :                    +- CometBroadcastExchange (13)
      :     :                       +- CometProject (12)
      :     :                          +- CometBroadcastHashJoin (11)
      :     :                             :- CometFilter (9)
      :     :                             :  +- CometScan parquet spark_catalog.default.date_dim (8)
      :     :                             +- ReusedExchange (10)
      :     +- BroadcastExchange (34)
      :        +- * Filter (33)
      :           +- * HashAggregate (32)
      :              +- Exchange (31)
      :                 +- * ColumnarToRow (30)
      :                    +- CometHashAggregate (29)
      :                       +- CometProject (28)
      :                          +- CometBroadcastHashJoin (27)
      :                             :- CometProject (25)
      :                             :  +- CometBroadcastHashJoin (24)
      :                             :     :- CometFilter (22)
      :                             :     :  +- CometScan parquet spark_catalog.default.catalog_sales (21)
      :                             :     +- ReusedExchange (23)
      :                             +- ReusedExchange (26)
      +- BroadcastExchange (50)
         +- * Filter (49)
            +- * HashAggregate (48)
               +- Exchange (47)
                  +- * ColumnarToRow (46)
                     +- CometHashAggregate (45)
                        +- CometProject (44)
                           +- CometBroadcastHashJoin (43)
                              :- CometProject (41)
                              :  +- CometBroadcastHashJoin (40)
                              :     :- CometFilter (38)
                              :     :  +- CometScan parquet spark_catalog.default.web_sales (37)
                              :     +- ReusedExchange (39)
                              +- ReusedExchange (42)


(1) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#3), dynamicpruningexpression(ss_sold_date_sk#3 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>

(2) CometFilter
Input [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Condition : isnotnull(ss_item_sk#1)

(3) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#5, i_item_id#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_item_id)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(4) CometFilter
Input [2]: [i_item_sk#5, i_item_id#6]
Condition : (isnotnull(i_item_sk#5) AND isnotnull(i_item_id#6))

(5) CometBroadcastExchange
Input [2]: [i_item_sk#5, i_item_id#6]
Arguments: [i_item_sk#5, i_item_id#6]

(6) CometBroadcastHashJoin
Left output [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Right output [2]: [i_item_sk#5, i_item_id#6]
Arguments: [ss_item_sk#1], [i_item_sk#5], Inner, BuildRight

(7) CometProject
Input [5]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_sk#5, i_item_id#6]
Arguments: [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#6], [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#6]

(8) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#7, d_date#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(9) CometFilter
Input [2]: [d_date_sk#7, d_date#8]
Condition : isnotnull(d_date_sk#7)

(10) ReusedExchange [Reuses operator id: 59]
Output [1]: [d_date#9]

(11) CometBroadcastHashJoin
Left output [2]: [d_date_sk#7, d_date#8]
Right output [1]: [d_date#9]
Arguments: [d_date#8], [d_date#9], LeftSemi, BuildRight

(12) CometProject
Input [2]: [d_date_sk#7, d_date#8]
Arguments: [d_date_sk#7], [d_date_sk#7]

(13) CometBroadcastExchange
Input [1]: [d_date_sk#7]
Arguments: [d_date_sk#7]

(14) CometBroadcastHashJoin
Left output [3]: [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#6]
Right output [1]: [d_date_sk#7]
Arguments: [ss_sold_date_sk#3], [d_date_sk#7], Inner, BuildRight

(15) CometProject
Input [4]: [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#6, d_date_sk#7]
Arguments: [ss_ext_sales_price#2, i_item_id#6], [ss_ext_sales_price#2, i_item_id#6]

(16) CometHashAggregate
Input [2]: [ss_ext_sales_price#2, i_item_id#6]
Keys [1]: [i_item_id#6]
Functions [1]: [partial_sum(UnscaledValue(ss_ext_sales_price#2))]

(17) ColumnarToRow [codegen id : 1]
Input [2]: [i_item_id#6, sum#10]

(18) Exchange
Input [2]: [i_item_id#6, sum#10]
Arguments: hashpartitioning(i_item_id#6, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(19) HashAggregate [codegen id : 6]
Input [2]: [i_item_id#6, sum#10]
Keys [1]: [i_item_id#6]
Functions [1]: [sum(UnscaledValue(ss_ext_sales_price#2))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_ext_sales_price#2))#11]
Results [2]: [i_item_id#6 AS item_id#12, MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#2))#11,17,2) AS ss_item_rev#13]

(20) Filter [codegen id : 6]
Input [2]: [item_id#12, ss_item_rev#13]
Condition : isnotnull(ss_item_rev#13)

(21) Scan parquet spark_catalog.default.catalog_sales
Output [3]: [cs_item_sk#14, cs_ext_sales_price#15, cs_sold_date_sk#16]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#16), dynamicpruningexpression(cs_sold_date_sk#16 IN dynamicpruning#17)]
PushedFilters: [IsNotNull(cs_item_sk)]
ReadSchema: struct<cs_item_sk:int,cs_ext_sales_price:decimal(7,2)>

(22) CometFilter
Input [3]: [cs_item_sk#14, cs_ext_sales_price#15, cs_sold_date_sk#16]
Condition : isnotnull(cs_item_sk#14)

(23) ReusedExchange [Reuses operator id: 5]
Output [2]: [i_item_sk#18, i_item_id#19]

(24) CometBroadcastHashJoin
Left output [3]: [cs_item_sk#14, cs_ext_sales_price#15, cs_sold_date_sk#16]
Right output [2]: [i_item_sk#18, i_item_id#19]
Arguments: [cs_item_sk#14], [i_item_sk#18], Inner, BuildRight

(25) CometProject
Input [5]: [cs_item_sk#14, cs_ext_sales_price#15, cs_sold_date_sk#16, i_item_sk#18, i_item_id#19]
Arguments: [cs_ext_sales_price#15, cs_sold_date_sk#16, i_item_id#19], [cs_ext_sales_price#15, cs_sold_date_sk#16, i_item_id#19]

(26) ReusedExchange [Reuses operator id: 13]
Output [1]: [d_date_sk#20]

(27) CometBroadcastHashJoin
Left output [3]: [cs_ext_sales_price#15, cs_sold_date_sk#16, i_item_id#19]
Right output [1]: [d_date_sk#20]
Arguments: [cs_sold_date_sk#16], [d_date_sk#20], Inner, BuildRight

(28) CometProject
Input [4]: [cs_ext_sales_price#15, cs_sold_date_sk#16, i_item_id#19, d_date_sk#20]
Arguments: [cs_ext_sales_price#15, i_item_id#19], [cs_ext_sales_price#15, i_item_id#19]

(29) CometHashAggregate
Input [2]: [cs_ext_sales_price#15, i_item_id#19]
Keys [1]: [i_item_id#19]
Functions [1]: [partial_sum(UnscaledValue(cs_ext_sales_price#15))]

(30) ColumnarToRow [codegen id : 2]
Input [2]: [i_item_id#19, sum#21]

(31) Exchange
Input [2]: [i_item_id#19, sum#21]
Arguments: hashpartitioning(i_item_id#19, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(32) HashAggregate [codegen id : 3]
Input [2]: [i_item_id#19, sum#21]
Keys [1]: [i_item_id#19]
Functions [1]: [sum(UnscaledValue(cs_ext_sales_price#15))]
Aggregate Attributes [1]: [sum(UnscaledValue(cs_ext_sales_price#15))#22]
Results [2]: [i_item_id#19 AS item_id#23, MakeDecimal(sum(UnscaledValue(cs_ext_sales_price#15))#22,17,2) AS cs_item_rev#24]

(33) Filter [codegen id : 3]
Input [2]: [item_id#23, cs_item_rev#24]
Condition : isnotnull(cs_item_rev#24)

(34) BroadcastExchange
Input [2]: [item_id#23, cs_item_rev#24]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=3]

(35) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [item_id#12]
Right keys [1]: [item_id#23]
Join type: Inner
Join condition: ((((cast(ss_item_rev#13 as decimal(19,3)) >= (0.9 * cs_item_rev#24)) AND (cast(ss_item_rev#13 as decimal(20,3)) <= (1.1 * cs_item_rev#24))) AND (cast(cs_item_rev#24 as decimal(19,3)) >= (0.9 * ss_item_rev#13))) AND (cast(cs_item_rev#24 as decimal(20,3)) <= (1.1 * ss_item_rev#13)))

(36) Project [codegen id : 6]
Output [3]: [item_id#12, ss_item_rev#13, cs_item_rev#24]
Input [4]: [item_id#12, ss_item_rev#13, item_id#23, cs_item_rev#24]

(37) Scan parquet spark_catalog.default.web_sales
Output [3]: [ws_item_sk#25, ws_ext_sales_price#26, ws_sold_date_sk#27]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#27), dynamicpruningexpression(ws_sold_date_sk#27 IN dynamicpruning#28)]
PushedFilters: [IsNotNull(ws_item_sk)]
ReadSchema: struct<ws_item_sk:int,ws_ext_sales_price:decimal(7,2)>

(38) CometFilter
Input [3]: [ws_item_sk#25, ws_ext_sales_price#26, ws_sold_date_sk#27]
Condition : isnotnull(ws_item_sk#25)

(39) ReusedExchange [Reuses operator id: 5]
Output [2]: [i_item_sk#29, i_item_id#30]

(40) CometBroadcastHashJoin
Left output [3]: [ws_item_sk#25, ws_ext_sales_price#26, ws_sold_date_sk#27]
Right output [2]: [i_item_sk#29, i_item_id#30]
Arguments: [ws_item_sk#25], [i_item_sk#29], Inner, BuildRight

(41) CometProject
Input [5]: [ws_item_sk#25, ws_ext_sales_price#26, ws_sold_date_sk#27, i_item_sk#29, i_item_id#30]
Arguments: [ws_ext_sales_price#26, ws_sold_date_sk#27, i_item_id#30], [ws_ext_sales_price#26, ws_sold_date_sk#27, i_item_id#30]

(42) ReusedExchange [Reuses operator id: 13]
Output [1]: [d_date_sk#31]

(43) CometBroadcastHashJoin
Left output [3]: [ws_ext_sales_price#26, ws_sold_date_sk#27, i_item_id#30]
Right output [1]: [d_date_sk#31]
Arguments: [ws_sold_date_sk#27], [d_date_sk#31], Inner, BuildRight

(44) CometProject
Input [4]: [ws_ext_sales_price#26, ws_sold_date_sk#27, i_item_id#30, d_date_sk#31]
Arguments: [ws_ext_sales_price#26, i_item_id#30], [ws_ext_sales_price#26, i_item_id#30]

(45) CometHashAggregate
Input [2]: [ws_ext_sales_price#26, i_item_id#30]
Keys [1]: [i_item_id#30]
Functions [1]: [partial_sum(UnscaledValue(ws_ext_sales_price#26))]

(46) ColumnarToRow [codegen id : 4]
Input [2]: [i_item_id#30, sum#32]

(47) Exchange
Input [2]: [i_item_id#30, sum#32]
Arguments: hashpartitioning(i_item_id#30, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(48) HashAggregate [codegen id : 5]
Input [2]: [i_item_id#30, sum#32]
Keys [1]: [i_item_id#30]
Functions [1]: [sum(UnscaledValue(ws_ext_sales_price#26))]
Aggregate Attributes [1]: [sum(UnscaledValue(ws_ext_sales_price#26))#33]
Results [2]: [i_item_id#30 AS item_id#34, MakeDecimal(sum(UnscaledValue(ws_ext_sales_price#26))#33,17,2) AS ws_item_rev#35]

(49) Filter [codegen id : 5]
Input [2]: [item_id#34, ws_item_rev#35]
Condition : isnotnull(ws_item_rev#35)

(50) BroadcastExchange
Input [2]: [item_id#34, ws_item_rev#35]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=5]

(51) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [item_id#12]
Right keys [1]: [item_id#34]
Join type: Inner
Join condition: ((((((((cast(ss_item_rev#13 as decimal(19,3)) >= (0.9 * ws_item_rev#35)) AND (cast(ss_item_rev#13 as decimal(20,3)) <= (1.1 * ws_item_rev#35))) AND (cast(cs_item_rev#24 as decimal(19,3)) >= (0.9 * ws_item_rev#35))) AND (cast(cs_item_rev#24 as decimal(20,3)) <= (1.1 * ws_item_rev#35))) AND (cast(ws_item_rev#35 as decimal(19,3)) >= (0.9 * ss_item_rev#13))) AND (cast(ws_item_rev#35 as decimal(20,3)) <= (1.1 * ss_item_rev#13))) AND (cast(ws_item_rev#35 as decimal(19,3)) >= (0.9 * cs_item_rev#24))) AND (cast(ws_item_rev#35 as decimal(20,3)) <= (1.1 * cs_item_rev#24)))

(52) Project [codegen id : 6]
Output [8]: [item_id#12, ss_item_rev#13, (((ss_item_rev#13 / ((ss_item_rev#13 + cs_item_rev#24) + ws_item_rev#35)) / 3) * 100) AS ss_dev#36, cs_item_rev#24, (((cs_item_rev#24 / ((ss_item_rev#13 + cs_item_rev#24) + ws_item_rev#35)) / 3) * 100) AS cs_dev#37, ws_item_rev#35, (((ws_item_rev#35 / ((ss_item_rev#13 + cs_item_rev#24) + ws_item_rev#35)) / 3) * 100) AS ws_dev#38, (((ss_item_rev#13 + cs_item_rev#24) + ws_item_rev#35) / 3) AS average#39]
Input [5]: [item_id#12, ss_item_rev#13, cs_item_rev#24, item_id#34, ws_item_rev#35]

(53) TakeOrderedAndProject
Input [8]: [item_id#12, ss_item_rev#13, ss_dev#36, cs_item_rev#24, cs_dev#37, ws_item_rev#35, ws_dev#38, average#39]
Arguments: 100, [item_id#12 ASC NULLS FIRST, ss_item_rev#13 ASC NULLS FIRST], [item_id#12, ss_item_rev#13, ss_dev#36, cs_item_rev#24, cs_dev#37, ws_item_rev#35, ws_dev#38, average#39]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#3 IN dynamicpruning#4
BroadcastExchange (63)
+- * ColumnarToRow (62)
   +- CometProject (61)
      +- CometBroadcastHashJoin (60)
         :- CometFilter (55)
         :  +- CometScan parquet spark_catalog.default.date_dim (54)
         +- CometBroadcastExchange (59)
            +- CometProject (58)
               +- CometFilter (57)
                  +- CometScan parquet spark_catalog.default.date_dim (56)


(54) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#7, d_date#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(55) CometFilter
Input [2]: [d_date_sk#7, d_date#8]
Condition : isnotnull(d_date_sk#7)

(56) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#9, d_week_seq#40]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_week_seq)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(57) CometFilter
Input [2]: [d_date#9, d_week_seq#40]
Condition : (isnotnull(d_week_seq#40) AND (d_week_seq#40 = Subquery scalar-subquery#41, [id=#42]))

(58) CometProject
Input [2]: [d_date#9, d_week_seq#40]
Arguments: [d_date#9], [d_date#9]

(59) CometBroadcastExchange
Input [1]: [d_date#9]
Arguments: [d_date#9]

(60) CometBroadcastHashJoin
Left output [2]: [d_date_sk#7, d_date#8]
Right output [1]: [d_date#9]
Arguments: [d_date#8], [d_date#9], LeftSemi, BuildRight

(61) CometProject
Input [2]: [d_date_sk#7, d_date#8]
Arguments: [d_date_sk#7], [d_date_sk#7]

(62) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#7]

(63) BroadcastExchange
Input [1]: [d_date_sk#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

Subquery:2 Hosting operator id = 57 Hosting Expression = Subquery scalar-subquery#41, [id=#42]
* ColumnarToRow (67)
+- CometProject (66)
   +- CometFilter (65)
      +- CometScan parquet spark_catalog.default.date_dim (64)


(64) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#43, d_week_seq#44]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), EqualTo(d_date,2000-01-03)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(65) CometFilter
Input [2]: [d_date#43, d_week_seq#44]
Condition : (isnotnull(d_date#43) AND (d_date#43 = 2000-01-03))

(66) CometProject
Input [2]: [d_date#43, d_week_seq#44]
Arguments: [d_week_seq#44], [d_week_seq#44]

(67) ColumnarToRow [codegen id : 1]
Input [1]: [d_week_seq#44]

Subquery:3 Hosting operator id = 21 Hosting Expression = cs_sold_date_sk#16 IN dynamicpruning#4

Subquery:4 Hosting operator id = 37 Hosting Expression = ws_sold_date_sk#27 IN dynamicpruning#4


