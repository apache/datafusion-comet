== Physical Plan ==
* CometColumnarToRow (78)
+- CometTakeOrderedAndProject (77)
   +- CometHashAggregate (76)
      +- CometExchange (75)
         +- CometHashAggregate (74)
            +- CometExpand (73)
               +- CometUnion (72)
                  :- CometHashAggregate (22)
                  :  +- CometColumnarExchange (21)
                  :     +- * HashAggregate (20)
                  :        +- * Project (19)
                  :           +- * BroadcastHashJoin Inner BuildRight (18)
                  :              :- * Project (12)
                  :              :  +- * BroadcastHashJoin Inner BuildRight (11)
                  :              :     :- Union (9)
                  :              :     :  :- * Project (4)
                  :              :     :  :  +- * Filter (3)
                  :              :     :  :     +- * ColumnarToRow (2)
                  :              :     :  :        +- Scan parquet spark_catalog.default.store_sales (1)
                  :              :     :  +- * Project (8)
                  :              :     :     +- * Filter (7)
                  :              :     :        +- * ColumnarToRow (6)
                  :              :     :           +- Scan parquet spark_catalog.default.store_returns (5)
                  :              :     +- ReusedExchange (10)
                  :              +- BroadcastExchange (17)
                  :                 +- * CometColumnarToRow (16)
                  :                    +- CometProject (15)
                  :                       +- CometFilter (14)
                  :                          +- CometNativeScan parquet spark_catalog.default.store (13)
                  :- CometHashAggregate (44)
                  :  +- CometColumnarExchange (43)
                  :     +- * HashAggregate (42)
                  :        +- * Project (41)
                  :           +- * BroadcastHashJoin Inner BuildRight (40)
                  :              :- * Project (34)
                  :              :  +- * BroadcastHashJoin Inner BuildRight (33)
                  :              :     :- Union (31)
                  :              :     :  :- * Project (26)
                  :              :     :  :  +- * Filter (25)
                  :              :     :  :     +- * ColumnarToRow (24)
                  :              :     :  :        +- Scan parquet spark_catalog.default.catalog_sales (23)
                  :              :     :  +- * Project (30)
                  :              :     :     +- * Filter (29)
                  :              :     :        +- * ColumnarToRow (28)
                  :              :     :           +- Scan parquet spark_catalog.default.catalog_returns (27)
                  :              :     +- ReusedExchange (32)
                  :              +- BroadcastExchange (39)
                  :                 +- * CometColumnarToRow (38)
                  :                    +- CometProject (37)
                  :                       +- CometFilter (36)
                  :                          +- CometNativeScan parquet spark_catalog.default.catalog_page (35)
                  +- CometHashAggregate (71)
                     +- CometColumnarExchange (70)
                        +- * HashAggregate (69)
                           +- * Project (68)
                              +- * BroadcastHashJoin Inner BuildRight (67)
                                 :- * Project (61)
                                 :  +- * BroadcastHashJoin Inner BuildRight (60)
                                 :     :- Union (58)
                                 :     :  :- * Project (48)
                                 :     :  :  +- * Filter (47)
                                 :     :  :     +- * ColumnarToRow (46)
                                 :     :  :        +- Scan parquet spark_catalog.default.web_sales (45)
                                 :     :  +- * Project (57)
                                 :     :     +- * BroadcastHashJoin Inner BuildLeft (56)
                                 :     :        :- BroadcastExchange (51)
                                 :     :        :  +- * ColumnarToRow (50)
                                 :     :        :     +- Scan parquet spark_catalog.default.web_returns (49)
                                 :     :        +- * CometColumnarToRow (55)
                                 :     :           +- CometProject (54)
                                 :     :              +- CometFilter (53)
                                 :     :                 +- CometNativeScan parquet spark_catalog.default.web_sales (52)
                                 :     +- ReusedExchange (59)
                                 +- BroadcastExchange (66)
                                    +- * CometColumnarToRow (65)
                                       +- CometProject (64)
                                          +- CometFilter (63)
                                             +- CometNativeScan parquet spark_catalog.default.web_site (62)


(1) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#4), dynamicpruningexpression(ss_sold_date_sk#4 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_store_sk:int,ss_ext_sales_price:decimal(7,2),ss_net_profit:decimal(7,2)>

(2) ColumnarToRow [codegen id : 1]
Input [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]

(3) Filter [codegen id : 1]
Input [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]
Condition : isnotnull(ss_store_sk#1)

(4) Project [codegen id : 1]
Output [6]: [ss_store_sk#1 AS store_sk#6, ss_sold_date_sk#4 AS date_sk#7, ss_ext_sales_price#2 AS sales_price#8, ss_net_profit#3 AS profit#9, 0.00 AS return_amt#10, 0.00 AS net_loss#11]
Input [4]: [ss_store_sk#1, ss_ext_sales_price#2, ss_net_profit#3, ss_sold_date_sk#4]

(5) Scan parquet spark_catalog.default.store_returns
Output [4]: [sr_store_sk#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(sr_returned_date_sk#15), dynamicpruningexpression(sr_returned_date_sk#15 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(sr_store_sk)]
ReadSchema: struct<sr_store_sk:int,sr_return_amt:decimal(7,2),sr_net_loss:decimal(7,2)>

(6) ColumnarToRow [codegen id : 2]
Input [4]: [sr_store_sk#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]

(7) Filter [codegen id : 2]
Input [4]: [sr_store_sk#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]
Condition : isnotnull(sr_store_sk#12)

(8) Project [codegen id : 2]
Output [6]: [sr_store_sk#12 AS store_sk#16, sr_returned_date_sk#15 AS date_sk#17, 0.00 AS sales_price#18, 0.00 AS profit#19, sr_return_amt#13 AS return_amt#20, sr_net_loss#14 AS net_loss#21]
Input [4]: [sr_store_sk#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]

(9) Union

(10) ReusedExchange [Reuses operator id: 83]
Output [1]: [d_date_sk#22]

(11) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [date_sk#7]
Right keys [1]: [d_date_sk#22]
Join type: Inner
Join condition: None

(12) Project [codegen id : 5]
Output [5]: [store_sk#6, sales_price#8, profit#9, return_amt#10, net_loss#11]
Input [7]: [store_sk#6, date_sk#7, sales_price#8, profit#9, return_amt#10, net_loss#11, d_date_sk#22]

(13) CometNativeScan parquet spark_catalog.default.store
Output [2]: [s_store_sk#23, s_store_id#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_id:string>

(14) CometFilter
Input [2]: [s_store_sk#23, s_store_id#24]
Condition : isnotnull(s_store_sk#23)

(15) CometProject
Input [2]: [s_store_sk#23, s_store_id#24]
Arguments: [s_store_sk#23, s_store_id#25], [s_store_sk#23, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, s_store_id#24, 16, true, false, true) AS s_store_id#25]

(16) CometColumnarToRow [codegen id : 4]
Input [2]: [s_store_sk#23, s_store_id#25]

(17) BroadcastExchange
Input [2]: [s_store_sk#23, s_store_id#25]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(18) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [store_sk#6]
Right keys [1]: [s_store_sk#23]
Join type: Inner
Join condition: None

(19) Project [codegen id : 5]
Output [5]: [sales_price#8, profit#9, return_amt#10, net_loss#11, s_store_id#25]
Input [7]: [store_sk#6, sales_price#8, profit#9, return_amt#10, net_loss#11, s_store_sk#23, s_store_id#25]

(20) HashAggregate [codegen id : 5]
Input [5]: [sales_price#8, profit#9, return_amt#10, net_loss#11, s_store_id#25]
Keys [1]: [s_store_id#25]
Functions [4]: [partial_sum(UnscaledValue(sales_price#8)), partial_sum(UnscaledValue(return_amt#10)), partial_sum(UnscaledValue(profit#9)), partial_sum(UnscaledValue(net_loss#11))]
Aggregate Attributes [4]: [sum#26, sum#27, sum#28, sum#29]
Results [5]: [s_store_id#25, sum#30, sum#31, sum#32, sum#33]

(21) CometColumnarExchange
Input [5]: [s_store_id#25, sum#30, sum#31, sum#32, sum#33]
Arguments: hashpartitioning(s_store_id#25, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(22) CometHashAggregate
Input [5]: [s_store_id#25, sum#30, sum#31, sum#32, sum#33]
Keys [1]: [s_store_id#25]
Functions [4]: [sum(UnscaledValue(sales_price#8)), sum(UnscaledValue(return_amt#10)), sum(UnscaledValue(profit#9)), sum(UnscaledValue(net_loss#11))]

(23) Scan parquet spark_catalog.default.catalog_sales
Output [4]: [cs_catalog_page_sk#34, cs_ext_sales_price#35, cs_net_profit#36, cs_sold_date_sk#37]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#37), dynamicpruningexpression(cs_sold_date_sk#37 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(cs_catalog_page_sk)]
ReadSchema: struct<cs_catalog_page_sk:int,cs_ext_sales_price:decimal(7,2),cs_net_profit:decimal(7,2)>

(24) ColumnarToRow [codegen id : 6]
Input [4]: [cs_catalog_page_sk#34, cs_ext_sales_price#35, cs_net_profit#36, cs_sold_date_sk#37]

(25) Filter [codegen id : 6]
Input [4]: [cs_catalog_page_sk#34, cs_ext_sales_price#35, cs_net_profit#36, cs_sold_date_sk#37]
Condition : isnotnull(cs_catalog_page_sk#34)

(26) Project [codegen id : 6]
Output [6]: [cs_catalog_page_sk#34 AS page_sk#38, cs_sold_date_sk#37 AS date_sk#39, cs_ext_sales_price#35 AS sales_price#40, cs_net_profit#36 AS profit#41, 0.00 AS return_amt#42, 0.00 AS net_loss#43]
Input [4]: [cs_catalog_page_sk#34, cs_ext_sales_price#35, cs_net_profit#36, cs_sold_date_sk#37]

(27) Scan parquet spark_catalog.default.catalog_returns
Output [4]: [cr_catalog_page_sk#44, cr_return_amount#45, cr_net_loss#46, cr_returned_date_sk#47]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cr_returned_date_sk#47), dynamicpruningexpression(cr_returned_date_sk#47 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(cr_catalog_page_sk)]
ReadSchema: struct<cr_catalog_page_sk:int,cr_return_amount:decimal(7,2),cr_net_loss:decimal(7,2)>

(28) ColumnarToRow [codegen id : 7]
Input [4]: [cr_catalog_page_sk#44, cr_return_amount#45, cr_net_loss#46, cr_returned_date_sk#47]

(29) Filter [codegen id : 7]
Input [4]: [cr_catalog_page_sk#44, cr_return_amount#45, cr_net_loss#46, cr_returned_date_sk#47]
Condition : isnotnull(cr_catalog_page_sk#44)

(30) Project [codegen id : 7]
Output [6]: [cr_catalog_page_sk#44 AS page_sk#48, cr_returned_date_sk#47 AS date_sk#49, 0.00 AS sales_price#50, 0.00 AS profit#51, cr_return_amount#45 AS return_amt#52, cr_net_loss#46 AS net_loss#53]
Input [4]: [cr_catalog_page_sk#44, cr_return_amount#45, cr_net_loss#46, cr_returned_date_sk#47]

(31) Union

(32) ReusedExchange [Reuses operator id: 83]
Output [1]: [d_date_sk#54]

(33) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [date_sk#39]
Right keys [1]: [d_date_sk#54]
Join type: Inner
Join condition: None

(34) Project [codegen id : 10]
Output [5]: [page_sk#38, sales_price#40, profit#41, return_amt#42, net_loss#43]
Input [7]: [page_sk#38, date_sk#39, sales_price#40, profit#41, return_amt#42, net_loss#43, d_date_sk#54]

(35) CometNativeScan parquet spark_catalog.default.catalog_page
Output [2]: [cp_catalog_page_sk#55, cp_catalog_page_id#56]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_page]
PushedFilters: [IsNotNull(cp_catalog_page_sk)]
ReadSchema: struct<cp_catalog_page_sk:int,cp_catalog_page_id:string>

(36) CometFilter
Input [2]: [cp_catalog_page_sk#55, cp_catalog_page_id#56]
Condition : isnotnull(cp_catalog_page_sk#55)

(37) CometProject
Input [2]: [cp_catalog_page_sk#55, cp_catalog_page_id#56]
Arguments: [cp_catalog_page_sk#55, cp_catalog_page_id#57], [cp_catalog_page_sk#55, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, cp_catalog_page_id#56, 16, true, false, true) AS cp_catalog_page_id#57]

(38) CometColumnarToRow [codegen id : 9]
Input [2]: [cp_catalog_page_sk#55, cp_catalog_page_id#57]

(39) BroadcastExchange
Input [2]: [cp_catalog_page_sk#55, cp_catalog_page_id#57]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(40) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [page_sk#38]
Right keys [1]: [cp_catalog_page_sk#55]
Join type: Inner
Join condition: None

(41) Project [codegen id : 10]
Output [5]: [sales_price#40, profit#41, return_amt#42, net_loss#43, cp_catalog_page_id#57]
Input [7]: [page_sk#38, sales_price#40, profit#41, return_amt#42, net_loss#43, cp_catalog_page_sk#55, cp_catalog_page_id#57]

(42) HashAggregate [codegen id : 10]
Input [5]: [sales_price#40, profit#41, return_amt#42, net_loss#43, cp_catalog_page_id#57]
Keys [1]: [cp_catalog_page_id#57]
Functions [4]: [partial_sum(UnscaledValue(sales_price#40)), partial_sum(UnscaledValue(return_amt#42)), partial_sum(UnscaledValue(profit#41)), partial_sum(UnscaledValue(net_loss#43))]
Aggregate Attributes [4]: [sum#58, sum#59, sum#60, sum#61]
Results [5]: [cp_catalog_page_id#57, sum#62, sum#63, sum#64, sum#65]

(43) CometColumnarExchange
Input [5]: [cp_catalog_page_id#57, sum#62, sum#63, sum#64, sum#65]
Arguments: hashpartitioning(cp_catalog_page_id#57, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=4]

(44) CometHashAggregate
Input [5]: [cp_catalog_page_id#57, sum#62, sum#63, sum#64, sum#65]
Keys [1]: [cp_catalog_page_id#57]
Functions [4]: [sum(UnscaledValue(sales_price#40)), sum(UnscaledValue(return_amt#42)), sum(UnscaledValue(profit#41)), sum(UnscaledValue(net_loss#43))]

(45) Scan parquet spark_catalog.default.web_sales
Output [4]: [ws_web_site_sk#66, ws_ext_sales_price#67, ws_net_profit#68, ws_sold_date_sk#69]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#69), dynamicpruningexpression(ws_sold_date_sk#69 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(ws_web_site_sk)]
ReadSchema: struct<ws_web_site_sk:int,ws_ext_sales_price:decimal(7,2),ws_net_profit:decimal(7,2)>

(46) ColumnarToRow [codegen id : 11]
Input [4]: [ws_web_site_sk#66, ws_ext_sales_price#67, ws_net_profit#68, ws_sold_date_sk#69]

(47) Filter [codegen id : 11]
Input [4]: [ws_web_site_sk#66, ws_ext_sales_price#67, ws_net_profit#68, ws_sold_date_sk#69]
Condition : isnotnull(ws_web_site_sk#66)

(48) Project [codegen id : 11]
Output [6]: [ws_web_site_sk#66 AS wsr_web_site_sk#70, ws_sold_date_sk#69 AS date_sk#71, ws_ext_sales_price#67 AS sales_price#72, ws_net_profit#68 AS profit#73, 0.00 AS return_amt#74, 0.00 AS net_loss#75]
Input [4]: [ws_web_site_sk#66, ws_ext_sales_price#67, ws_net_profit#68, ws_sold_date_sk#69]

(49) Scan parquet spark_catalog.default.web_returns
Output [5]: [wr_item_sk#76, wr_order_number#77, wr_return_amt#78, wr_net_loss#79, wr_returned_date_sk#80]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(wr_returned_date_sk#80), dynamicpruningexpression(wr_returned_date_sk#80 IN dynamicpruning#5)]
ReadSchema: struct<wr_item_sk:int,wr_order_number:int,wr_return_amt:decimal(7,2),wr_net_loss:decimal(7,2)>

(50) ColumnarToRow [codegen id : 12]
Input [5]: [wr_item_sk#76, wr_order_number#77, wr_return_amt#78, wr_net_loss#79, wr_returned_date_sk#80]

(51) BroadcastExchange
Input [5]: [wr_item_sk#76, wr_order_number#77, wr_return_amt#78, wr_net_loss#79, wr_returned_date_sk#80]
Arguments: HashedRelationBroadcastMode(List((shiftleft(cast(input[0, int, true] as bigint), 32) | (cast(input[1, int, true] as bigint) & 4294967295))),false), [plan_id=5]

(52) CometNativeScan parquet spark_catalog.default.web_sales
Output [4]: [ws_item_sk#81, ws_web_site_sk#82, ws_order_number#83, ws_sold_date_sk#84]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_sales]
PushedFilters: [IsNotNull(ws_item_sk), IsNotNull(ws_order_number), IsNotNull(ws_web_site_sk)]
ReadSchema: struct<ws_item_sk:int,ws_web_site_sk:int,ws_order_number:int>

(53) CometFilter
Input [4]: [ws_item_sk#81, ws_web_site_sk#82, ws_order_number#83, ws_sold_date_sk#84]
Condition : ((isnotnull(ws_item_sk#81) AND isnotnull(ws_order_number#83)) AND isnotnull(ws_web_site_sk#82))

(54) CometProject
Input [4]: [ws_item_sk#81, ws_web_site_sk#82, ws_order_number#83, ws_sold_date_sk#84]
Arguments: [ws_item_sk#81, ws_web_site_sk#82, ws_order_number#83], [ws_item_sk#81, ws_web_site_sk#82, ws_order_number#83]

(55) CometColumnarToRow
Input [3]: [ws_item_sk#81, ws_web_site_sk#82, ws_order_number#83]

(56) BroadcastHashJoin [codegen id : 13]
Left keys [2]: [wr_item_sk#76, wr_order_number#77]
Right keys [2]: [ws_item_sk#81, ws_order_number#83]
Join type: Inner
Join condition: None

(57) Project [codegen id : 13]
Output [6]: [ws_web_site_sk#82 AS wsr_web_site_sk#85, wr_returned_date_sk#80 AS date_sk#86, 0.00 AS sales_price#87, 0.00 AS profit#88, wr_return_amt#78 AS return_amt#89, wr_net_loss#79 AS net_loss#90]
Input [8]: [wr_item_sk#76, wr_order_number#77, wr_return_amt#78, wr_net_loss#79, wr_returned_date_sk#80, ws_item_sk#81, ws_web_site_sk#82, ws_order_number#83]

(58) Union

(59) ReusedExchange [Reuses operator id: 83]
Output [1]: [d_date_sk#91]

(60) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [date_sk#71]
Right keys [1]: [d_date_sk#91]
Join type: Inner
Join condition: None

(61) Project [codegen id : 16]
Output [5]: [wsr_web_site_sk#70, sales_price#72, profit#73, return_amt#74, net_loss#75]
Input [7]: [wsr_web_site_sk#70, date_sk#71, sales_price#72, profit#73, return_amt#74, net_loss#75, d_date_sk#91]

(62) CometNativeScan parquet spark_catalog.default.web_site
Output [2]: [web_site_sk#92, web_site_id#93]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_site]
PushedFilters: [IsNotNull(web_site_sk)]
ReadSchema: struct<web_site_sk:int,web_site_id:string>

(63) CometFilter
Input [2]: [web_site_sk#92, web_site_id#93]
Condition : isnotnull(web_site_sk#92)

(64) CometProject
Input [2]: [web_site_sk#92, web_site_id#93]
Arguments: [web_site_sk#92, web_site_id#94], [web_site_sk#92, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, web_site_id#93, 16, true, false, true) AS web_site_id#94]

(65) CometColumnarToRow [codegen id : 15]
Input [2]: [web_site_sk#92, web_site_id#94]

(66) BroadcastExchange
Input [2]: [web_site_sk#92, web_site_id#94]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

(67) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [wsr_web_site_sk#70]
Right keys [1]: [web_site_sk#92]
Join type: Inner
Join condition: None

(68) Project [codegen id : 16]
Output [5]: [sales_price#72, profit#73, return_amt#74, net_loss#75, web_site_id#94]
Input [7]: [wsr_web_site_sk#70, sales_price#72, profit#73, return_amt#74, net_loss#75, web_site_sk#92, web_site_id#94]

(69) HashAggregate [codegen id : 16]
Input [5]: [sales_price#72, profit#73, return_amt#74, net_loss#75, web_site_id#94]
Keys [1]: [web_site_id#94]
Functions [4]: [partial_sum(UnscaledValue(sales_price#72)), partial_sum(UnscaledValue(return_amt#74)), partial_sum(UnscaledValue(profit#73)), partial_sum(UnscaledValue(net_loss#75))]
Aggregate Attributes [4]: [sum#95, sum#96, sum#97, sum#98]
Results [5]: [web_site_id#94, sum#99, sum#100, sum#101, sum#102]

(70) CometColumnarExchange
Input [5]: [web_site_id#94, sum#99, sum#100, sum#101, sum#102]
Arguments: hashpartitioning(web_site_id#94, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=7]

(71) CometHashAggregate
Input [5]: [web_site_id#94, sum#99, sum#100, sum#101, sum#102]
Keys [1]: [web_site_id#94]
Functions [4]: [sum(UnscaledValue(sales_price#72)), sum(UnscaledValue(return_amt#74)), sum(UnscaledValue(profit#73)), sum(UnscaledValue(net_loss#75))]

(72) CometUnion
Child 0 Input [5]: [sales#103, returns#104, profit#105, channel#106, id#107]
Child 1 Input [5]: [sales#108, returns#109, profit#110, channel#111, id#112]
Child 2 Input [5]: [sales#113, returns#114, profit#115, channel#116, id#117]

(73) CometExpand
Input [5]: [sales#103, returns#104, profit#105, channel#106, id#107]
Arguments: [[sales#103, returns#104, profit#105, channel#106, id#107, 0], [sales#103, returns#104, profit#105, channel#106, null, 1], [sales#103, returns#104, profit#105, null, null, 3]], [sales#103, returns#104, profit#105, channel#118, id#119, spark_grouping_id#120]

(74) CometHashAggregate
Input [6]: [sales#103, returns#104, profit#105, channel#118, id#119, spark_grouping_id#120]
Keys [3]: [channel#118, id#119, spark_grouping_id#120]
Functions [3]: [partial_sum(sales#103), partial_sum(returns#104), partial_sum(profit#105)]

(75) CometExchange
Input [9]: [channel#118, id#119, spark_grouping_id#120, sum#121, isEmpty#122, sum#123, isEmpty#124, sum#125, isEmpty#126]
Arguments: hashpartitioning(channel#118, id#119, spark_grouping_id#120, 5), ENSURE_REQUIREMENTS, CometNativeShuffle, [plan_id=8]

(76) CometHashAggregate
Input [9]: [channel#118, id#119, spark_grouping_id#120, sum#121, isEmpty#122, sum#123, isEmpty#124, sum#125, isEmpty#126]
Keys [3]: [channel#118, id#119, spark_grouping_id#120]
Functions [3]: [sum(sales#103), sum(returns#104), sum(profit#105)]

(77) CometTakeOrderedAndProject
Input [5]: [channel#118, id#119, sales#127, returns#128, profit#129]
Arguments: TakeOrderedAndProject(limit=100, orderBy=[channel#118 ASC NULLS FIRST,id#119 ASC NULLS FIRST], output=[channel#118,id#119,sales#127,returns#128,profit#129]), [channel#118, id#119, sales#127, returns#128, profit#129], 100, 0, [channel#118 ASC NULLS FIRST, id#119 ASC NULLS FIRST], [channel#118, id#119, sales#127, returns#128, profit#129]

(78) CometColumnarToRow [codegen id : 17]
Input [5]: [channel#118, id#119, sales#127, returns#128, profit#129]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#4 IN dynamicpruning#5
BroadcastExchange (83)
+- * CometColumnarToRow (82)
   +- CometProject (81)
      +- CometFilter (80)
         +- CometNativeScan parquet spark_catalog.default.date_dim (79)


(79) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#22, d_date#130]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-23), LessThanOrEqual(d_date,2000-09-06), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(80) CometFilter
Input [2]: [d_date_sk#22, d_date#130]
Condition : (((isnotnull(d_date#130) AND (d_date#130 >= 2000-08-23)) AND (d_date#130 <= 2000-09-06)) AND isnotnull(d_date_sk#22))

(81) CometProject
Input [2]: [d_date_sk#22, d_date#130]
Arguments: [d_date_sk#22], [d_date_sk#22]

(82) CometColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#22]

(83) BroadcastExchange
Input [1]: [d_date_sk#22]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=9]

Subquery:2 Hosting operator id = 5 Hosting Expression = sr_returned_date_sk#15 IN dynamicpruning#5

Subquery:3 Hosting operator id = 23 Hosting Expression = cs_sold_date_sk#37 IN dynamicpruning#5

Subquery:4 Hosting operator id = 27 Hosting Expression = cr_returned_date_sk#47 IN dynamicpruning#5

Subquery:5 Hosting operator id = 45 Hosting Expression = ws_sold_date_sk#69 IN dynamicpruning#5

Subquery:6 Hosting operator id = 49 Hosting Expression = wr_returned_date_sk#80 IN dynamicpruning#5


