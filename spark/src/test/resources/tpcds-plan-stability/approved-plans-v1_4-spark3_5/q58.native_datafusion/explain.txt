== Physical Plan ==
* CometColumnarToRow (51)
+- CometTakeOrderedAndProject (50)
   +- CometProject (49)
      +- CometBroadcastHashJoin (48)
         :- CometProject (33)
         :  +- CometBroadcastHashJoin (32)
         :     :- CometFilter (17)
         :     :  +- CometHashAggregate (16)
         :     :     +- CometColumnarExchange (15)
         :     :        +- * HashAggregate (14)
         :     :           +- * Project (13)
         :     :              +- * BroadcastHashJoin Inner BuildRight (12)
         :     :                 :- * Project (10)
         :     :                 :  +- * BroadcastHashJoin Inner BuildRight (9)
         :     :                 :     :- * Filter (3)
         :     :                 :     :  +- * ColumnarToRow (2)
         :     :                 :     :     +- Scan parquet spark_catalog.default.store_sales (1)
         :     :                 :     +- BroadcastExchange (8)
         :     :                 :        +- * CometColumnarToRow (7)
         :     :                 :           +- CometProject (6)
         :     :                 :              +- CometFilter (5)
         :     :                 :                 +- CometNativeScan parquet spark_catalog.default.item (4)
         :     :                 +- ReusedExchange (11)
         :     +- CometBroadcastExchange (31)
         :        +- CometFilter (30)
         :           +- CometHashAggregate (29)
         :              +- CometColumnarExchange (28)
         :                 +- * HashAggregate (27)
         :                    +- * Project (26)
         :                       +- * BroadcastHashJoin Inner BuildRight (25)
         :                          :- * Project (23)
         :                          :  +- * BroadcastHashJoin Inner BuildRight (22)
         :                          :     :- * Filter (20)
         :                          :     :  +- * ColumnarToRow (19)
         :                          :     :     +- Scan parquet spark_catalog.default.catalog_sales (18)
         :                          :     +- ReusedExchange (21)
         :                          +- ReusedExchange (24)
         +- CometBroadcastExchange (47)
            +- CometFilter (46)
               +- CometHashAggregate (45)
                  +- CometColumnarExchange (44)
                     +- * HashAggregate (43)
                        +- * Project (42)
                           +- * BroadcastHashJoin Inner BuildRight (41)
                              :- * Project (39)
                              :  +- * BroadcastHashJoin Inner BuildRight (38)
                              :     :- * Filter (36)
                              :     :  +- * ColumnarToRow (35)
                              :     :     +- Scan parquet spark_catalog.default.web_sales (34)
                              :     +- ReusedExchange (37)
                              +- ReusedExchange (40)


(1) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#3), dynamicpruningexpression(ss_sold_date_sk#3 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 3]
Input [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]

(3) Filter [codegen id : 3]
Input [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Condition : isnotnull(ss_item_sk#1)

(4) CometNativeScan parquet spark_catalog.default.item
Output [2]: [i_item_sk#5, i_item_id#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(5) CometFilter
Input [2]: [i_item_sk#5, i_item_id#6]
Condition : (isnotnull(i_item_sk#5) AND isnotnull(staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_item_id#6, 16, true, false, true)))

(6) CometProject
Input [2]: [i_item_sk#5, i_item_id#6]
Arguments: [i_item_sk#5, i_item_id#7], [i_item_sk#5, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_item_id#6, 16, true, false, true) AS i_item_id#7]

(7) CometColumnarToRow [codegen id : 1]
Input [2]: [i_item_sk#5, i_item_id#7]

(8) BroadcastExchange
Input [2]: [i_item_sk#5, i_item_id#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(9) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#5]
Join type: Inner
Join condition: None

(10) Project [codegen id : 3]
Output [3]: [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#7]
Input [5]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_sk#5, i_item_id#7]

(11) ReusedExchange [Reuses operator id: 61]
Output [1]: [d_date_sk#8]

(12) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#3]
Right keys [1]: [d_date_sk#8]
Join type: Inner
Join condition: None

(13) Project [codegen id : 3]
Output [2]: [ss_ext_sales_price#2, i_item_id#7]
Input [4]: [ss_ext_sales_price#2, ss_sold_date_sk#3, i_item_id#7, d_date_sk#8]

(14) HashAggregate [codegen id : 3]
Input [2]: [ss_ext_sales_price#2, i_item_id#7]
Keys [1]: [i_item_id#7]
Functions [1]: [partial_sum(UnscaledValue(ss_ext_sales_price#2))]
Aggregate Attributes [1]: [sum#9]
Results [2]: [i_item_id#7, sum#10]

(15) CometColumnarExchange
Input [2]: [i_item_id#7, sum#10]
Arguments: hashpartitioning(i_item_id#7, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(16) CometHashAggregate
Input [2]: [i_item_id#7, sum#10]
Keys [1]: [i_item_id#7]
Functions [1]: [sum(UnscaledValue(ss_ext_sales_price#2))]

(17) CometFilter
Input [2]: [item_id#11, ss_item_rev#12]
Condition : isnotnull(ss_item_rev#12)

(18) Scan parquet spark_catalog.default.catalog_sales
Output [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#15), dynamicpruningexpression(cs_sold_date_sk#15 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(cs_item_sk)]
ReadSchema: struct<cs_item_sk:int,cs_ext_sales_price:decimal(7,2)>

(19) ColumnarToRow [codegen id : 6]
Input [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]

(20) Filter [codegen id : 6]
Input [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]
Condition : isnotnull(cs_item_sk#13)

(21) ReusedExchange [Reuses operator id: 8]
Output [2]: [i_item_sk#16, i_item_id#17]

(22) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [cs_item_sk#13]
Right keys [1]: [i_item_sk#16]
Join type: Inner
Join condition: None

(23) Project [codegen id : 6]
Output [3]: [cs_ext_sales_price#14, cs_sold_date_sk#15, i_item_id#17]
Input [5]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15, i_item_sk#16, i_item_id#17]

(24) ReusedExchange [Reuses operator id: 61]
Output [1]: [d_date_sk#18]

(25) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [cs_sold_date_sk#15]
Right keys [1]: [d_date_sk#18]
Join type: Inner
Join condition: None

(26) Project [codegen id : 6]
Output [2]: [cs_ext_sales_price#14, i_item_id#17]
Input [4]: [cs_ext_sales_price#14, cs_sold_date_sk#15, i_item_id#17, d_date_sk#18]

(27) HashAggregate [codegen id : 6]
Input [2]: [cs_ext_sales_price#14, i_item_id#17]
Keys [1]: [i_item_id#17]
Functions [1]: [partial_sum(UnscaledValue(cs_ext_sales_price#14))]
Aggregate Attributes [1]: [sum#19]
Results [2]: [i_item_id#17, sum#20]

(28) CometColumnarExchange
Input [2]: [i_item_id#17, sum#20]
Arguments: hashpartitioning(i_item_id#17, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=3]

(29) CometHashAggregate
Input [2]: [i_item_id#17, sum#20]
Keys [1]: [i_item_id#17]
Functions [1]: [sum(UnscaledValue(cs_ext_sales_price#14))]

(30) CometFilter
Input [2]: [item_id#21, cs_item_rev#22]
Condition : isnotnull(cs_item_rev#22)

(31) CometBroadcastExchange
Input [2]: [item_id#21, cs_item_rev#22]
Arguments: [item_id#21, cs_item_rev#22]

(32) CometBroadcastHashJoin
Left output [2]: [item_id#11, ss_item_rev#12]
Right output [2]: [item_id#21, cs_item_rev#22]
Arguments: [item_id#11], [item_id#21], Inner, ((((cast(ss_item_rev#12 as decimal(19,3)) >= (0.9 * cs_item_rev#22)) AND (cast(ss_item_rev#12 as decimal(20,3)) <= (1.1 * cs_item_rev#22))) AND (cast(cs_item_rev#22 as decimal(19,3)) >= (0.9 * ss_item_rev#12))) AND (cast(cs_item_rev#22 as decimal(20,3)) <= (1.1 * ss_item_rev#12))), BuildRight

(33) CometProject
Input [4]: [item_id#11, ss_item_rev#12, item_id#21, cs_item_rev#22]
Arguments: [item_id#11, ss_item_rev#12, cs_item_rev#22], [item_id#11, ss_item_rev#12, cs_item_rev#22]

(34) Scan parquet spark_catalog.default.web_sales
Output [3]: [ws_item_sk#23, ws_ext_sales_price#24, ws_sold_date_sk#25]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#25), dynamicpruningexpression(ws_sold_date_sk#25 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(ws_item_sk)]
ReadSchema: struct<ws_item_sk:int,ws_ext_sales_price:decimal(7,2)>

(35) ColumnarToRow [codegen id : 9]
Input [3]: [ws_item_sk#23, ws_ext_sales_price#24, ws_sold_date_sk#25]

(36) Filter [codegen id : 9]
Input [3]: [ws_item_sk#23, ws_ext_sales_price#24, ws_sold_date_sk#25]
Condition : isnotnull(ws_item_sk#23)

(37) ReusedExchange [Reuses operator id: 8]
Output [2]: [i_item_sk#26, i_item_id#27]

(38) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ws_item_sk#23]
Right keys [1]: [i_item_sk#26]
Join type: Inner
Join condition: None

(39) Project [codegen id : 9]
Output [3]: [ws_ext_sales_price#24, ws_sold_date_sk#25, i_item_id#27]
Input [5]: [ws_item_sk#23, ws_ext_sales_price#24, ws_sold_date_sk#25, i_item_sk#26, i_item_id#27]

(40) ReusedExchange [Reuses operator id: 61]
Output [1]: [d_date_sk#28]

(41) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ws_sold_date_sk#25]
Right keys [1]: [d_date_sk#28]
Join type: Inner
Join condition: None

(42) Project [codegen id : 9]
Output [2]: [ws_ext_sales_price#24, i_item_id#27]
Input [4]: [ws_ext_sales_price#24, ws_sold_date_sk#25, i_item_id#27, d_date_sk#28]

(43) HashAggregate [codegen id : 9]
Input [2]: [ws_ext_sales_price#24, i_item_id#27]
Keys [1]: [i_item_id#27]
Functions [1]: [partial_sum(UnscaledValue(ws_ext_sales_price#24))]
Aggregate Attributes [1]: [sum#29]
Results [2]: [i_item_id#27, sum#30]

(44) CometColumnarExchange
Input [2]: [i_item_id#27, sum#30]
Arguments: hashpartitioning(i_item_id#27, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=4]

(45) CometHashAggregate
Input [2]: [i_item_id#27, sum#30]
Keys [1]: [i_item_id#27]
Functions [1]: [sum(UnscaledValue(ws_ext_sales_price#24))]

(46) CometFilter
Input [2]: [item_id#31, ws_item_rev#32]
Condition : isnotnull(ws_item_rev#32)

(47) CometBroadcastExchange
Input [2]: [item_id#31, ws_item_rev#32]
Arguments: [item_id#31, ws_item_rev#32]

(48) CometBroadcastHashJoin
Left output [3]: [item_id#11, ss_item_rev#12, cs_item_rev#22]
Right output [2]: [item_id#31, ws_item_rev#32]
Arguments: [item_id#11], [item_id#31], Inner, ((((((((cast(ss_item_rev#12 as decimal(19,3)) >= (0.9 * ws_item_rev#32)) AND (cast(ss_item_rev#12 as decimal(20,3)) <= (1.1 * ws_item_rev#32))) AND (cast(cs_item_rev#22 as decimal(19,3)) >= (0.9 * ws_item_rev#32))) AND (cast(cs_item_rev#22 as decimal(20,3)) <= (1.1 * ws_item_rev#32))) AND (cast(ws_item_rev#32 as decimal(19,3)) >= (0.9 * ss_item_rev#12))) AND (cast(ws_item_rev#32 as decimal(20,3)) <= (1.1 * ss_item_rev#12))) AND (cast(ws_item_rev#32 as decimal(19,3)) >= (0.9 * cs_item_rev#22))) AND (cast(ws_item_rev#32 as decimal(20,3)) <= (1.1 * cs_item_rev#22))), BuildRight

(49) CometProject
Input [5]: [item_id#11, ss_item_rev#12, cs_item_rev#22, item_id#31, ws_item_rev#32]
Arguments: [item_id#11, ss_item_rev#12, ss_dev#33, cs_item_rev#22, cs_dev#34, ws_item_rev#32, ws_dev#35, average#36], [item_id#11, ss_item_rev#12, (((ss_item_rev#12 / ((ss_item_rev#12 + cs_item_rev#22) + ws_item_rev#32)) / 3) * 100) AS ss_dev#33, cs_item_rev#22, (((cs_item_rev#22 / ((ss_item_rev#12 + cs_item_rev#22) + ws_item_rev#32)) / 3) * 100) AS cs_dev#34, ws_item_rev#32, (((ws_item_rev#32 / ((ss_item_rev#12 + cs_item_rev#22) + ws_item_rev#32)) / 3) * 100) AS ws_dev#35, (((ss_item_rev#12 + cs_item_rev#22) + ws_item_rev#32) / 3) AS average#36]

(50) CometTakeOrderedAndProject
Input [8]: [item_id#11, ss_item_rev#12, ss_dev#33, cs_item_rev#22, cs_dev#34, ws_item_rev#32, ws_dev#35, average#36]
Arguments: TakeOrderedAndProject(limit=100, orderBy=[item_id#11 ASC NULLS FIRST,ss_item_rev#12 ASC NULLS FIRST], output=[item_id#11,ss_item_rev#12,ss_dev#33,cs_item_rev#22,cs_dev#34,ws_item_rev#32,ws_dev#35,average#36]), [item_id#11, ss_item_rev#12, ss_dev#33, cs_item_rev#22, cs_dev#34, ws_item_rev#32, ws_dev#35, average#36], 100, 0, [item_id#11 ASC NULLS FIRST, ss_item_rev#12 ASC NULLS FIRST], [item_id#11, ss_item_rev#12, ss_dev#33, cs_item_rev#22, cs_dev#34, ws_item_rev#32, ws_dev#35, average#36]

(51) CometColumnarToRow [codegen id : 10]
Input [8]: [item_id#11, ss_item_rev#12, ss_dev#33, cs_item_rev#22, cs_dev#34, ws_item_rev#32, ws_dev#35, average#36]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#3 IN dynamicpruning#4
BroadcastExchange (61)
+- * CometColumnarToRow (60)
   +- CometProject (59)
      +- CometBroadcastHashJoin (58)
         :- CometFilter (53)
         :  +- CometNativeScan parquet spark_catalog.default.date_dim (52)
         +- CometBroadcastExchange (57)
            +- CometProject (56)
               +- CometFilter (55)
                  +- CometNativeScan parquet spark_catalog.default.date_dim (54)


(52) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#8, d_date#37]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(53) CometFilter
Input [2]: [d_date_sk#8, d_date#37]
Condition : isnotnull(d_date_sk#8)

(54) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date#38, d_week_seq#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_week_seq)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(55) CometFilter
Input [2]: [d_date#38, d_week_seq#39]
Condition : (isnotnull(d_week_seq#39) AND (d_week_seq#39 = Subquery scalar-subquery#40, [id=#41]))

(56) CometProject
Input [2]: [d_date#38, d_week_seq#39]
Arguments: [d_date#38], [d_date#38]

(57) CometBroadcastExchange
Input [1]: [d_date#38]
Arguments: [d_date#38]

(58) CometBroadcastHashJoin
Left output [2]: [d_date_sk#8, d_date#37]
Right output [1]: [d_date#38]
Arguments: [d_date#37], [d_date#38], LeftSemi, BuildRight

(59) CometProject
Input [2]: [d_date_sk#8, d_date#37]
Arguments: [d_date_sk#8], [d_date_sk#8]

(60) CometColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#8]

(61) BroadcastExchange
Input [1]: [d_date_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

Subquery:2 Hosting operator id = 55 Hosting Expression = Subquery scalar-subquery#40, [id=#41]
* CometColumnarToRow (65)
+- CometProject (64)
   +- CometFilter (63)
      +- CometNativeScan parquet spark_catalog.default.date_dim (62)


(62) CometNativeScan parquet spark_catalog.default.date_dim
Output [2]: [d_date#42, d_week_seq#43]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), EqualTo(d_date,2000-01-03)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(63) CometFilter
Input [2]: [d_date#42, d_week_seq#43]
Condition : (isnotnull(d_date#42) AND (d_date#42 = 2000-01-03))

(64) CometProject
Input [2]: [d_date#42, d_week_seq#43]
Arguments: [d_week_seq#43], [d_week_seq#43]

(65) CometColumnarToRow [codegen id : 1]
Input [1]: [d_week_seq#43]

Subquery:3 Hosting operator id = 18 Hosting Expression = cs_sold_date_sk#15 IN dynamicpruning#4

Subquery:4 Hosting operator id = 34 Hosting Expression = ws_sold_date_sk#25 IN dynamicpruning#4


