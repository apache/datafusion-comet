== Physical Plan ==
TakeOrderedAndProject (31)
+- * Project (30)
   +- * Filter (29)
      +- Window (28)
         +- * CometColumnarToRow (27)
            +- CometSort (26)
               +- CometColumnarExchange (25)
                  +- * HashAggregate (24)
                     +- * CometColumnarToRow (23)
                        +- CometColumnarExchange (22)
                           +- * HashAggregate (21)
                              +- * CometColumnarToRow (20)
                                 +- CometProject (19)
                                    +- CometBroadcastHashJoin (18)
                                       :- CometProject (14)
                                       :  +- CometBroadcastHashJoin (13)
                                       :     :- CometProject (8)
                                       :     :  +- CometBroadcastHashJoin (7)
                                       :     :     :- CometProject (3)
                                       :     :     :  +- CometFilter (2)
                                       :     :     :     +- CometScan parquet spark_catalog.default.item (1)
                                       :     :     +- CometBroadcastExchange (6)
                                       :     :        +- CometFilter (5)
                                       :     :           +- CometScan parquet spark_catalog.default.store_sales (4)
                                       :     +- CometBroadcastExchange (12)
                                       :        +- CometProject (11)
                                       :           +- CometFilter (10)
                                       :              +- CometScan parquet spark_catalog.default.date_dim (9)
                                       +- CometBroadcastExchange (17)
                                          +- CometFilter (16)
                                             +- CometScan parquet spark_catalog.default.store (15)


(1) CometScan parquet spark_catalog.default.item
Output [4]: [i_item_sk#1, i_brand#2, i_class#3, i_category#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_brand:string,i_class:string,i_category:string>

(2) CometFilter
Input [4]: [i_item_sk#1, i_brand#2, i_class#3, i_category#4]
Condition : (((staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_category#4, 50, true, false, true) IN (Books                                             ,Electronics                                       ,Sports                                            ) AND staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_class#3, 50, true, false, true) IN (computers                                         ,stereo                                            ,football                                          )) OR (staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_category#4, 50, true, false, true) IN (Men                                               ,Jewelry                                           ,Women                                             ) AND staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_class#3, 50, true, false, true) IN (shirts                                            ,birdal                                            ,dresses                                           ))) AND isnotnull(i_item_sk#1))

(3) CometProject
Input [4]: [i_item_sk#1, i_brand#2, i_class#3, i_category#4]
Arguments: [i_item_sk#1, i_brand#5, i_class#6, i_category#7], [i_item_sk#1, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_brand#2, 50, true, false, true) AS i_brand#5, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_class#3, 50, true, false, true) AS i_class#6, staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, i_category#4, 50, true, false, true) AS i_category#7]

(4) CometScan parquet spark_catalog.default.store_sales
Output [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#11), dynamicpruningexpression(ss_sold_date_sk#11 IN dynamicpruning#12)]
PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_item_sk:int,ss_store_sk:int,ss_sales_price:decimal(7,2)>

(5) CometFilter
Input [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Condition : (isnotnull(ss_item_sk#8) AND isnotnull(ss_store_sk#9))

(6) CometBroadcastExchange
Input [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Arguments: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]

(7) CometBroadcastHashJoin
Left output [4]: [i_item_sk#1, i_brand#5, i_class#6, i_category#7]
Right output [4]: [ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Arguments: [i_item_sk#1], [ss_item_sk#8], Inner, BuildRight

(8) CometProject
Input [8]: [i_item_sk#1, i_brand#5, i_class#6, i_category#7, ss_item_sk#8, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Arguments: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11], [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]

(9) CometScan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#13, d_year#14, d_moy#15]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1999), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(10) CometFilter
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Condition : ((isnotnull(d_year#14) AND (d_year#14 = 1999)) AND isnotnull(d_date_sk#13))

(11) CometProject
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Arguments: [d_date_sk#13, d_moy#15], [d_date_sk#13, d_moy#15]

(12) CometBroadcastExchange
Input [2]: [d_date_sk#13, d_moy#15]
Arguments: [d_date_sk#13, d_moy#15]

(13) CometBroadcastHashJoin
Left output [6]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11]
Right output [2]: [d_date_sk#13, d_moy#15]
Arguments: [ss_sold_date_sk#11], [d_date_sk#13], Inner, BuildRight

(14) CometProject
Input [8]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, ss_sold_date_sk#11, d_date_sk#13, d_moy#15]
Arguments: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15], [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15]

(15) CometScan parquet spark_catalog.default.store
Output [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_name:string,s_company_name:string>

(16) CometFilter
Input [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Condition : isnotnull(s_store_sk#16)

(17) CometBroadcastExchange
Input [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Arguments: [s_store_sk#16, s_store_name#17, s_company_name#18]

(18) CometBroadcastHashJoin
Left output [6]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15]
Right output [3]: [s_store_sk#16, s_store_name#17, s_company_name#18]
Arguments: [ss_store_sk#9], [s_store_sk#16], Inner, BuildRight

(19) CometProject
Input [9]: [i_brand#5, i_class#6, i_category#7, ss_store_sk#9, ss_sales_price#10, d_moy#15, s_store_sk#16, s_store_name#17, s_company_name#18]
Arguments: [i_brand#5, i_class#6, i_category#7, ss_sales_price#10, d_moy#15, s_store_name#17, s_company_name#18], [i_brand#5, i_class#6, i_category#7, ss_sales_price#10, d_moy#15, s_store_name#17, s_company_name#18]

(20) CometColumnarToRow [codegen id : 1]
Input [7]: [i_brand#5, i_class#6, i_category#7, ss_sales_price#10, d_moy#15, s_store_name#17, s_company_name#18]

(21) HashAggregate [codegen id : 1]
Input [7]: [i_brand#5, i_class#6, i_category#7, ss_sales_price#10, d_moy#15, s_store_name#17, s_company_name#18]
Keys [6]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15]
Functions [1]: [partial_sum(UnscaledValue(ss_sales_price#10))]
Aggregate Attributes [1]: [sum#19]
Results [7]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum#20]

(22) CometColumnarExchange
Input [7]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum#20]
Arguments: hashpartitioning(i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=1]

(23) CometColumnarToRow [codegen id : 2]
Input [7]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum#20]

(24) HashAggregate [codegen id : 2]
Input [7]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum#20]
Keys [6]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15]
Functions [1]: [sum(UnscaledValue(ss_sales_price#10))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_sales_price#10))#21]
Results [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, MakeDecimal(sum(UnscaledValue(ss_sales_price#10))#21,17,2) AS sum_sales#22, MakeDecimal(sum(UnscaledValue(ss_sales_price#10))#21,17,2) AS _w0#23]

(25) CometColumnarExchange
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, _w0#23]
Arguments: hashpartitioning(i_category#7, i_brand#5, s_store_name#17, s_company_name#18, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(26) CometSort
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, _w0#23]
Arguments: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, _w0#23], [i_category#7 ASC NULLS FIRST, i_brand#5 ASC NULLS FIRST, s_store_name#17 ASC NULLS FIRST, s_company_name#18 ASC NULLS FIRST]

(27) CometColumnarToRow [codegen id : 3]
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, _w0#23]

(28) Window
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, _w0#23]
Arguments: [avg(_w0#23) windowspecdefinition(i_category#7, i_brand#5, s_store_name#17, s_company_name#18, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS avg_monthly_sales#24], [i_category#7, i_brand#5, s_store_name#17, s_company_name#18]

(29) Filter [codegen id : 4]
Input [9]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, _w0#23, avg_monthly_sales#24]
Condition : CASE WHEN NOT (avg_monthly_sales#24 = 0.000000) THEN ((abs((sum_sales#22 - avg_monthly_sales#24)) / avg_monthly_sales#24) > 0.1000000000000000) END

(30) Project [codegen id : 4]
Output [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, avg_monthly_sales#24]
Input [9]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, _w0#23, avg_monthly_sales#24]

(31) TakeOrderedAndProject
Input [8]: [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, avg_monthly_sales#24]
Arguments: 100, [(sum_sales#22 - avg_monthly_sales#24) ASC NULLS FIRST, s_store_name#17 ASC NULLS FIRST], [i_category#7, i_class#6, i_brand#5, s_store_name#17, s_company_name#18, d_moy#15, sum_sales#22, avg_monthly_sales#24]

===== Subqueries =====

Subquery:1 Hosting operator id = 4 Hosting Expression = ss_sold_date_sk#11 IN dynamicpruning#12
BroadcastExchange (36)
+- * CometColumnarToRow (35)
   +- CometProject (34)
      +- CometFilter (33)
         +- CometScan parquet spark_catalog.default.date_dim (32)


(32) CometScan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#13, d_year#14, d_moy#15]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1999), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(33) CometFilter
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Condition : ((isnotnull(d_year#14) AND (d_year#14 = 1999)) AND isnotnull(d_date_sk#13))

(34) CometProject
Input [3]: [d_date_sk#13, d_year#14, d_moy#15]
Arguments: [d_date_sk#13, d_moy#15], [d_date_sk#13, d_moy#15]

(35) CometColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#13, d_moy#15]

(36) BroadcastExchange
Input [2]: [d_date_sk#13, d_moy#15]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]


