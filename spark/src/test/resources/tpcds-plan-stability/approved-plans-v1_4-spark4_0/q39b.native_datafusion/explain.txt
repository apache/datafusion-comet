== Physical Plan ==
* CometColumnarToRow (45)
+- CometSort (44)
   +- CometExchange (43)
      +- CometBroadcastHashJoin (42)
         :- CometProject (23)
         :  +- CometFilter (22)
         :     +- CometHashAggregate (21)
         :        +- CometColumnarExchange (20)
         :           +- * HashAggregate (19)
         :              +- * Project (18)
         :                 +- * BroadcastHashJoin Inner BuildRight (17)
         :                    :- * Project (15)
         :                    :  +- * BroadcastHashJoin Inner BuildRight (14)
         :                    :     :- * Project (9)
         :                    :     :  +- * BroadcastHashJoin Inner BuildRight (8)
         :                    :     :     :- * Filter (3)
         :                    :     :     :  +- * ColumnarToRow (2)
         :                    :     :     :     +- Scan parquet spark_catalog.default.inventory (1)
         :                    :     :     +- BroadcastExchange (7)
         :                    :     :        +- * CometColumnarToRow (6)
         :                    :     :           +- CometFilter (5)
         :                    :     :              +- CometNativeScan parquet spark_catalog.default.item (4)
         :                    :     +- BroadcastExchange (13)
         :                    :        +- * CometColumnarToRow (12)
         :                    :           +- CometFilter (11)
         :                    :              +- CometNativeScan parquet spark_catalog.default.warehouse (10)
         :                    +- ReusedExchange (16)
         +- CometBroadcastExchange (41)
            +- CometProject (40)
               +- CometFilter (39)
                  +- CometHashAggregate (38)
                     +- CometColumnarExchange (37)
                        +- * HashAggregate (36)
                           +- * Project (35)
                              +- * BroadcastHashJoin Inner BuildRight (34)
                                 :- * Project (32)
                                 :  +- * BroadcastHashJoin Inner BuildRight (31)
                                 :     :- * Project (29)
                                 :     :  +- * BroadcastHashJoin Inner BuildRight (28)
                                 :     :     :- * Filter (26)
                                 :     :     :  +- * ColumnarToRow (25)
                                 :     :     :     +- Scan parquet spark_catalog.default.inventory (24)
                                 :     :     +- ReusedExchange (27)
                                 :     +- ReusedExchange (30)
                                 +- ReusedExchange (33)


(1) Scan parquet spark_catalog.default.inventory
Output [4]: [inv_item_sk#1, inv_warehouse_sk#2, inv_quantity_on_hand#3, inv_date_sk#4]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(inv_date_sk#4), dynamicpruningexpression(inv_date_sk#4 IN dynamicpruning#5)]
PushedFilters: [IsNotNull(inv_item_sk), IsNotNull(inv_warehouse_sk)]
ReadSchema: struct<inv_item_sk:int,inv_warehouse_sk:int,inv_quantity_on_hand:int>

(2) ColumnarToRow [codegen id : 4]
Input [4]: [inv_item_sk#1, inv_warehouse_sk#2, inv_quantity_on_hand#3, inv_date_sk#4]

(3) Filter [codegen id : 4]
Input [4]: [inv_item_sk#1, inv_warehouse_sk#2, inv_quantity_on_hand#3, inv_date_sk#4]
Condition : (isnotnull(inv_item_sk#1) AND isnotnull(inv_warehouse_sk#2))

(4) CometNativeScan parquet spark_catalog.default.item
Output [1]: [i_item_sk#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int>

(5) CometFilter
Input [1]: [i_item_sk#6]
Condition : isnotnull(i_item_sk#6)

(6) CometColumnarToRow [codegen id : 1]
Input [1]: [i_item_sk#6]

(7) BroadcastExchange
Input [1]: [i_item_sk#6]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(8) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [inv_item_sk#1]
Right keys [1]: [i_item_sk#6]
Join type: Inner
Join condition: None

(9) Project [codegen id : 4]
Output [4]: [inv_warehouse_sk#2, inv_quantity_on_hand#3, inv_date_sk#4, i_item_sk#6]
Input [5]: [inv_item_sk#1, inv_warehouse_sk#2, inv_quantity_on_hand#3, inv_date_sk#4, i_item_sk#6]

(10) CometNativeScan parquet spark_catalog.default.warehouse
Output [2]: [w_warehouse_sk#7, w_warehouse_name#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/warehouse]
PushedFilters: [IsNotNull(w_warehouse_sk)]
ReadSchema: struct<w_warehouse_sk:int,w_warehouse_name:string>

(11) CometFilter
Input [2]: [w_warehouse_sk#7, w_warehouse_name#8]
Condition : isnotnull(w_warehouse_sk#7)

(12) CometColumnarToRow [codegen id : 2]
Input [2]: [w_warehouse_sk#7, w_warehouse_name#8]

(13) BroadcastExchange
Input [2]: [w_warehouse_sk#7, w_warehouse_name#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2]

(14) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [inv_warehouse_sk#2]
Right keys [1]: [w_warehouse_sk#7]
Join type: Inner
Join condition: None

(15) Project [codegen id : 4]
Output [5]: [inv_quantity_on_hand#3, inv_date_sk#4, i_item_sk#6, w_warehouse_sk#7, w_warehouse_name#8]
Input [6]: [inv_warehouse_sk#2, inv_quantity_on_hand#3, inv_date_sk#4, i_item_sk#6, w_warehouse_sk#7, w_warehouse_name#8]

(16) ReusedExchange [Reuses operator id: 50]
Output [2]: [d_date_sk#9, d_moy#10]

(17) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [inv_date_sk#4]
Right keys [1]: [d_date_sk#9]
Join type: Inner
Join condition: None

(18) Project [codegen id : 4]
Output [5]: [inv_quantity_on_hand#3, i_item_sk#6, w_warehouse_sk#7, w_warehouse_name#8, d_moy#10]
Input [7]: [inv_quantity_on_hand#3, inv_date_sk#4, i_item_sk#6, w_warehouse_sk#7, w_warehouse_name#8, d_date_sk#9, d_moy#10]

(19) HashAggregate [codegen id : 4]
Input [5]: [inv_quantity_on_hand#3, i_item_sk#6, w_warehouse_sk#7, w_warehouse_name#8, d_moy#10]
Keys [4]: [w_warehouse_name#8, w_warehouse_sk#7, i_item_sk#6, d_moy#10]
Functions [2]: [partial_stddev_samp(cast(inv_quantity_on_hand#3 as double)), partial_avg(inv_quantity_on_hand#3)]
Aggregate Attributes [5]: [n#11, avg#12, m2#13, sum#14, count#15]
Results [9]: [w_warehouse_name#8, w_warehouse_sk#7, i_item_sk#6, d_moy#10, n#16, avg#17, m2#18, sum#19, count#20]

(20) CometColumnarExchange
Input [9]: [w_warehouse_name#8, w_warehouse_sk#7, i_item_sk#6, d_moy#10, n#16, avg#17, m2#18, sum#19, count#20]
Arguments: hashpartitioning(w_warehouse_name#8, w_warehouse_sk#7, i_item_sk#6, d_moy#10, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=3]

(21) CometHashAggregate
Input [9]: [w_warehouse_name#8, w_warehouse_sk#7, i_item_sk#6, d_moy#10, n#16, avg#17, m2#18, sum#19, count#20]
Keys [4]: [w_warehouse_name#8, w_warehouse_sk#7, i_item_sk#6, d_moy#10]
Functions [2]: [stddev_samp(cast(inv_quantity_on_hand#3 as double)), avg(inv_quantity_on_hand#3)]

(22) CometFilter
Input [5]: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, stdev#21, mean#22]
Condition : (CASE WHEN (knownfloatingpointnormalized(normalizenanandzero(mean#22)) = 0.0) THEN false ELSE (knownfloatingpointnormalized(normalizenanandzero((stdev#21 / knownfloatingpointnormalized(normalizenanandzero(mean#22))))) > 1.0) END AND CASE WHEN (knownfloatingpointnormalized(normalizenanandzero(mean#22)) = 0.0) THEN false ELSE (knownfloatingpointnormalized(normalizenanandzero((stdev#21 / knownfloatingpointnormalized(normalizenanandzero(mean#22))))) > 1.5) END)

(23) CometProject
Input [5]: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, stdev#21, mean#22]
Arguments: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, mean#22, cov#23], [w_warehouse_sk#7, i_item_sk#6, d_moy#10, mean#22, CASE WHEN (knownfloatingpointnormalized(normalizenanandzero(mean#22)) = 0.0) THEN null ELSE (stdev#21 / knownfloatingpointnormalized(normalizenanandzero(mean#22))) END AS cov#23]

(24) Scan parquet spark_catalog.default.inventory
Output [4]: [inv_item_sk#24, inv_warehouse_sk#25, inv_quantity_on_hand#26, inv_date_sk#27]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(inv_date_sk#27), dynamicpruningexpression(inv_date_sk#27 IN dynamicpruning#28)]
PushedFilters: [IsNotNull(inv_item_sk), IsNotNull(inv_warehouse_sk)]
ReadSchema: struct<inv_item_sk:int,inv_warehouse_sk:int,inv_quantity_on_hand:int>

(25) ColumnarToRow [codegen id : 8]
Input [4]: [inv_item_sk#24, inv_warehouse_sk#25, inv_quantity_on_hand#26, inv_date_sk#27]

(26) Filter [codegen id : 8]
Input [4]: [inv_item_sk#24, inv_warehouse_sk#25, inv_quantity_on_hand#26, inv_date_sk#27]
Condition : (isnotnull(inv_item_sk#24) AND isnotnull(inv_warehouse_sk#25))

(27) ReusedExchange [Reuses operator id: 7]
Output [1]: [i_item_sk#29]

(28) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [inv_item_sk#24]
Right keys [1]: [i_item_sk#29]
Join type: Inner
Join condition: None

(29) Project [codegen id : 8]
Output [4]: [inv_warehouse_sk#25, inv_quantity_on_hand#26, inv_date_sk#27, i_item_sk#29]
Input [5]: [inv_item_sk#24, inv_warehouse_sk#25, inv_quantity_on_hand#26, inv_date_sk#27, i_item_sk#29]

(30) ReusedExchange [Reuses operator id: 13]
Output [2]: [w_warehouse_sk#30, w_warehouse_name#31]

(31) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [inv_warehouse_sk#25]
Right keys [1]: [w_warehouse_sk#30]
Join type: Inner
Join condition: None

(32) Project [codegen id : 8]
Output [5]: [inv_quantity_on_hand#26, inv_date_sk#27, i_item_sk#29, w_warehouse_sk#30, w_warehouse_name#31]
Input [6]: [inv_warehouse_sk#25, inv_quantity_on_hand#26, inv_date_sk#27, i_item_sk#29, w_warehouse_sk#30, w_warehouse_name#31]

(33) ReusedExchange [Reuses operator id: 55]
Output [2]: [d_date_sk#32, d_moy#33]

(34) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [inv_date_sk#27]
Right keys [1]: [d_date_sk#32]
Join type: Inner
Join condition: None

(35) Project [codegen id : 8]
Output [5]: [inv_quantity_on_hand#26, i_item_sk#29, w_warehouse_sk#30, w_warehouse_name#31, d_moy#33]
Input [7]: [inv_quantity_on_hand#26, inv_date_sk#27, i_item_sk#29, w_warehouse_sk#30, w_warehouse_name#31, d_date_sk#32, d_moy#33]

(36) HashAggregate [codegen id : 8]
Input [5]: [inv_quantity_on_hand#26, i_item_sk#29, w_warehouse_sk#30, w_warehouse_name#31, d_moy#33]
Keys [4]: [w_warehouse_name#31, w_warehouse_sk#30, i_item_sk#29, d_moy#33]
Functions [2]: [partial_stddev_samp(cast(inv_quantity_on_hand#26 as double)), partial_avg(inv_quantity_on_hand#26)]
Aggregate Attributes [5]: [n#34, avg#35, m2#36, sum#37, count#38]
Results [9]: [w_warehouse_name#31, w_warehouse_sk#30, i_item_sk#29, d_moy#33, n#39, avg#40, m2#41, sum#42, count#43]

(37) CometColumnarExchange
Input [9]: [w_warehouse_name#31, w_warehouse_sk#30, i_item_sk#29, d_moy#33, n#39, avg#40, m2#41, sum#42, count#43]
Arguments: hashpartitioning(w_warehouse_name#31, w_warehouse_sk#30, i_item_sk#29, d_moy#33, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=4]

(38) CometHashAggregate
Input [9]: [w_warehouse_name#31, w_warehouse_sk#30, i_item_sk#29, d_moy#33, n#39, avg#40, m2#41, sum#42, count#43]
Keys [4]: [w_warehouse_name#31, w_warehouse_sk#30, i_item_sk#29, d_moy#33]
Functions [2]: [stddev_samp(cast(inv_quantity_on_hand#26 as double)), avg(inv_quantity_on_hand#26)]

(39) CometFilter
Input [5]: [w_warehouse_sk#30, i_item_sk#29, d_moy#33, stdev#44, mean#45]
Condition : CASE WHEN (knownfloatingpointnormalized(normalizenanandzero(mean#45)) = 0.0) THEN false ELSE (knownfloatingpointnormalized(normalizenanandzero((stdev#44 / knownfloatingpointnormalized(normalizenanandzero(mean#45))))) > 1.0) END

(40) CometProject
Input [5]: [w_warehouse_sk#30, i_item_sk#29, d_moy#33, stdev#44, mean#45]
Arguments: [w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46], [w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, CASE WHEN (knownfloatingpointnormalized(normalizenanandzero(mean#45)) = 0.0) THEN null ELSE (stdev#44 / knownfloatingpointnormalized(normalizenanandzero(mean#45))) END AS cov#46]

(41) CometBroadcastExchange
Input [5]: [w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46]
Arguments: [w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46]

(42) CometBroadcastHashJoin
Left output [5]: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, mean#22, cov#23]
Right output [5]: [w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46]
Arguments: [i_item_sk#6, w_warehouse_sk#7], [i_item_sk#29, w_warehouse_sk#30], Inner, BuildRight

(43) CometExchange
Input [10]: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, mean#22, cov#23, w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46]
Arguments: rangepartitioning(w_warehouse_sk#7 ASC NULLS FIRST, i_item_sk#6 ASC NULLS FIRST, d_moy#10 ASC NULLS FIRST, mean#22 ASC NULLS FIRST, cov#23 ASC NULLS FIRST, d_moy#33 ASC NULLS FIRST, mean#45 ASC NULLS FIRST, cov#46 ASC NULLS FIRST, 5), ENSURE_REQUIREMENTS, CometNativeShuffle, [plan_id=5]

(44) CometSort
Input [10]: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, mean#22, cov#23, w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46]
Arguments: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, mean#22, cov#23, w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46], [w_warehouse_sk#7 ASC NULLS FIRST, i_item_sk#6 ASC NULLS FIRST, d_moy#10 ASC NULLS FIRST, mean#22 ASC NULLS FIRST, cov#23 ASC NULLS FIRST, d_moy#33 ASC NULLS FIRST, mean#45 ASC NULLS FIRST, cov#46 ASC NULLS FIRST]

(45) CometColumnarToRow [codegen id : 9]
Input [10]: [w_warehouse_sk#7, i_item_sk#6, d_moy#10, mean#22, cov#23, w_warehouse_sk#30, i_item_sk#29, d_moy#33, mean#45, cov#46]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = inv_date_sk#4 IN dynamicpruning#5
BroadcastExchange (50)
+- * CometColumnarToRow (49)
   +- CometProject (48)
      +- CometFilter (47)
         +- CometNativeScan parquet spark_catalog.default.date_dim (46)


(46) CometNativeScan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#9, d_year#47, d_moy#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2001), EqualTo(d_moy,1), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(47) CometFilter
Input [3]: [d_date_sk#9, d_year#47, d_moy#10]
Condition : ((((isnotnull(d_year#47) AND isnotnull(d_moy#10)) AND (d_year#47 = 2001)) AND (d_moy#10 = 1)) AND isnotnull(d_date_sk#9))

(48) CometProject
Input [3]: [d_date_sk#9, d_year#47, d_moy#10]
Arguments: [d_date_sk#9, d_moy#10], [d_date_sk#9, d_moy#10]

(49) CometColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#9, d_moy#10]

(50) BroadcastExchange
Input [2]: [d_date_sk#9, d_moy#10]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

Subquery:2 Hosting operator id = 24 Hosting Expression = inv_date_sk#27 IN dynamicpruning#28
BroadcastExchange (55)
+- * CometColumnarToRow (54)
   +- CometProject (53)
      +- CometFilter (52)
         +- CometNativeScan parquet spark_catalog.default.date_dim (51)


(51) CometNativeScan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#32, d_year#48, d_moy#33]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2001), EqualTo(d_moy,2), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(52) CometFilter
Input [3]: [d_date_sk#32, d_year#48, d_moy#33]
Condition : ((((isnotnull(d_year#48) AND isnotnull(d_moy#33)) AND (d_year#48 = 2001)) AND (d_moy#33 = 2)) AND isnotnull(d_date_sk#32))

(53) CometProject
Input [3]: [d_date_sk#32, d_year#48, d_moy#33]
Arguments: [d_date_sk#32, d_moy#33], [d_date_sk#32, d_moy#33]

(54) CometColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#32, d_moy#33]

(55) BroadcastExchange
Input [2]: [d_date_sk#32, d_moy#33]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=7]


