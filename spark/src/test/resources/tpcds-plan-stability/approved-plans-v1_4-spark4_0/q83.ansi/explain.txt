== Physical Plan ==
TakeOrderedAndProject (56)
+- * Project (55)
   +- * BroadcastHashJoin Inner BuildRight (54)
      :- * Project (38)
      :  +- * BroadcastHashJoin Inner BuildRight (37)
      :     :- * HashAggregate (21)
      :     :  +- * ColumnarToRow (20)
      :     :     +- CometColumnarExchange (19)
      :     :        +- RowToColumnar (18)
      :     :           +- * HashAggregate (17)
      :     :              +- * ColumnarToRow (16)
      :     :                 +- CometProject (15)
      :     :                    +- CometBroadcastHashJoin (14)
      :     :                       :- CometProject (7)
      :     :                       :  +- CometBroadcastHashJoin (6)
      :     :                       :     :- CometFilter (2)
      :     :                       :     :  +- CometScan parquet spark_catalog.default.store_returns (1)
      :     :                       :     +- CometBroadcastExchange (5)
      :     :                       :        +- CometFilter (4)
      :     :                       :           +- CometScan parquet spark_catalog.default.item (3)
      :     :                       +- CometBroadcastExchange (13)
      :     :                          +- CometProject (12)
      :     :                             +- CometBroadcastHashJoin (11)
      :     :                                :- CometFilter (9)
      :     :                                :  +- CometScan parquet spark_catalog.default.date_dim (8)
      :     :                                +- ReusedExchange (10)
      :     +- BroadcastExchange (36)
      :        +- * HashAggregate (35)
      :           +- * ColumnarToRow (34)
      :              +- CometColumnarExchange (33)
      :                 +- RowToColumnar (32)
      :                    +- * HashAggregate (31)
      :                       +- * ColumnarToRow (30)
      :                          +- CometProject (29)
      :                             +- CometBroadcastHashJoin (28)
      :                                :- CometProject (26)
      :                                :  +- CometBroadcastHashJoin (25)
      :                                :     :- CometFilter (23)
      :                                :     :  +- CometScan parquet spark_catalog.default.catalog_returns (22)
      :                                :     +- ReusedExchange (24)
      :                                +- ReusedExchange (27)
      +- BroadcastExchange (53)
         +- * HashAggregate (52)
            +- * ColumnarToRow (51)
               +- CometColumnarExchange (50)
                  +- RowToColumnar (49)
                     +- * HashAggregate (48)
                        +- * ColumnarToRow (47)
                           +- CometProject (46)
                              +- CometBroadcastHashJoin (45)
                                 :- CometProject (43)
                                 :  +- CometBroadcastHashJoin (42)
                                 :     :- CometFilter (40)
                                 :     :  +- CometScan parquet spark_catalog.default.web_returns (39)
                                 :     +- ReusedExchange (41)
                                 +- ReusedExchange (44)


(1) Scan parquet spark_catalog.default.store_returns
Output [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(sr_returned_date_sk#3), dynamicpruningexpression(sr_returned_date_sk#3 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(sr_item_sk)]
ReadSchema: struct<sr_item_sk:int,sr_return_quantity:int>

(2) CometFilter
Input [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Condition : isnotnull(sr_item_sk#1)

(3) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#5, i_item_id#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_item_id)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(4) CometFilter
Input [2]: [i_item_sk#5, i_item_id#6]
Condition : (isnotnull(i_item_sk#5) AND isnotnull(i_item_id#6))

(5) CometBroadcastExchange
Input [2]: [i_item_sk#5, i_item_id#6]
Arguments: [i_item_sk#5, i_item_id#6]

(6) CometBroadcastHashJoin
Left output [3]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3]
Right output [2]: [i_item_sk#5, i_item_id#6]
Arguments: [sr_item_sk#1], [i_item_sk#5], Inner, BuildRight

(7) CometProject
Input [5]: [sr_item_sk#1, sr_return_quantity#2, sr_returned_date_sk#3, i_item_sk#5, i_item_id#6]
Arguments: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6], [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6]

(8) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#7, d_date#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(9) CometFilter
Input [2]: [d_date_sk#7, d_date#8]
Condition : isnotnull(d_date_sk#7)

(10) ReusedExchange [Reuses operator id: 66]
Output [1]: [d_date#9]

(11) CometBroadcastHashJoin
Left output [2]: [d_date_sk#7, d_date#8]
Right output [1]: [d_date#9]
Arguments: [d_date#8], [d_date#9], LeftSemi, BuildRight

(12) CometProject
Input [2]: [d_date_sk#7, d_date#8]
Arguments: [d_date_sk#7], [d_date_sk#7]

(13) CometBroadcastExchange
Input [1]: [d_date_sk#7]
Arguments: [d_date_sk#7]

(14) CometBroadcastHashJoin
Left output [3]: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6]
Right output [1]: [d_date_sk#7]
Arguments: [sr_returned_date_sk#3], [d_date_sk#7], Inner, BuildRight

(15) CometProject
Input [4]: [sr_return_quantity#2, sr_returned_date_sk#3, i_item_id#6, d_date_sk#7]
Arguments: [sr_return_quantity#2, i_item_id#6], [sr_return_quantity#2, i_item_id#6]

(16) ColumnarToRow [codegen id : 1]
Input [2]: [sr_return_quantity#2, i_item_id#6]

(17) HashAggregate [codegen id : 1]
Input [2]: [sr_return_quantity#2, i_item_id#6]
Keys [1]: [i_item_id#6]
Functions [1]: [partial_sum(sr_return_quantity#2)]
Aggregate Attributes [1]: [sum#10]
Results [2]: [i_item_id#6, sum#11]

(18) RowToColumnar
Input [2]: [i_item_id#6, sum#11]

(19) CometColumnarExchange
Input [2]: [i_item_id#6, sum#11]
Arguments: hashpartitioning(i_item_id#6, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=1]

(20) ColumnarToRow [codegen id : 6]
Input [2]: [i_item_id#6, sum#11]

(21) HashAggregate [codegen id : 6]
Input [2]: [i_item_id#6, sum#11]
Keys [1]: [i_item_id#6]
Functions [1]: [sum(sr_return_quantity#2)]
Aggregate Attributes [1]: [sum(sr_return_quantity#2)#12]
Results [2]: [i_item_id#6 AS item_id#13, sum(sr_return_quantity#2)#12 AS sr_item_qty#14]

(22) Scan parquet spark_catalog.default.catalog_returns
Output [3]: [cr_item_sk#15, cr_return_quantity#16, cr_returned_date_sk#17]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cr_returned_date_sk#17), dynamicpruningexpression(cr_returned_date_sk#17 IN dynamicpruning#18)]
PushedFilters: [IsNotNull(cr_item_sk)]
ReadSchema: struct<cr_item_sk:int,cr_return_quantity:int>

(23) CometFilter
Input [3]: [cr_item_sk#15, cr_return_quantity#16, cr_returned_date_sk#17]
Condition : isnotnull(cr_item_sk#15)

(24) ReusedExchange [Reuses operator id: 5]
Output [2]: [i_item_sk#19, i_item_id#20]

(25) CometBroadcastHashJoin
Left output [3]: [cr_item_sk#15, cr_return_quantity#16, cr_returned_date_sk#17]
Right output [2]: [i_item_sk#19, i_item_id#20]
Arguments: [cr_item_sk#15], [i_item_sk#19], Inner, BuildRight

(26) CometProject
Input [5]: [cr_item_sk#15, cr_return_quantity#16, cr_returned_date_sk#17, i_item_sk#19, i_item_id#20]
Arguments: [cr_return_quantity#16, cr_returned_date_sk#17, i_item_id#20], [cr_return_quantity#16, cr_returned_date_sk#17, i_item_id#20]

(27) ReusedExchange [Reuses operator id: 13]
Output [1]: [d_date_sk#21]

(28) CometBroadcastHashJoin
Left output [3]: [cr_return_quantity#16, cr_returned_date_sk#17, i_item_id#20]
Right output [1]: [d_date_sk#21]
Arguments: [cr_returned_date_sk#17], [d_date_sk#21], Inner, BuildRight

(29) CometProject
Input [4]: [cr_return_quantity#16, cr_returned_date_sk#17, i_item_id#20, d_date_sk#21]
Arguments: [cr_return_quantity#16, i_item_id#20], [cr_return_quantity#16, i_item_id#20]

(30) ColumnarToRow [codegen id : 2]
Input [2]: [cr_return_quantity#16, i_item_id#20]

(31) HashAggregate [codegen id : 2]
Input [2]: [cr_return_quantity#16, i_item_id#20]
Keys [1]: [i_item_id#20]
Functions [1]: [partial_sum(cr_return_quantity#16)]
Aggregate Attributes [1]: [sum#22]
Results [2]: [i_item_id#20, sum#23]

(32) RowToColumnar
Input [2]: [i_item_id#20, sum#23]

(33) CometColumnarExchange
Input [2]: [i_item_id#20, sum#23]
Arguments: hashpartitioning(i_item_id#20, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=2]

(34) ColumnarToRow [codegen id : 3]
Input [2]: [i_item_id#20, sum#23]

(35) HashAggregate [codegen id : 3]
Input [2]: [i_item_id#20, sum#23]
Keys [1]: [i_item_id#20]
Functions [1]: [sum(cr_return_quantity#16)]
Aggregate Attributes [1]: [sum(cr_return_quantity#16)#24]
Results [2]: [i_item_id#20 AS item_id#25, sum(cr_return_quantity#16)#24 AS cr_item_qty#26]

(36) BroadcastExchange
Input [2]: [item_id#25, cr_item_qty#26]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=3]

(37) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [item_id#13]
Right keys [1]: [item_id#25]
Join type: Inner
Join condition: None

(38) Project [codegen id : 6]
Output [3]: [item_id#13, sr_item_qty#14, cr_item_qty#26]
Input [4]: [item_id#13, sr_item_qty#14, item_id#25, cr_item_qty#26]

(39) Scan parquet spark_catalog.default.web_returns
Output [3]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(wr_returned_date_sk#29), dynamicpruningexpression(wr_returned_date_sk#29 IN dynamicpruning#30)]
PushedFilters: [IsNotNull(wr_item_sk)]
ReadSchema: struct<wr_item_sk:int,wr_return_quantity:int>

(40) CometFilter
Input [3]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29]
Condition : isnotnull(wr_item_sk#27)

(41) ReusedExchange [Reuses operator id: 5]
Output [2]: [i_item_sk#31, i_item_id#32]

(42) CometBroadcastHashJoin
Left output [3]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29]
Right output [2]: [i_item_sk#31, i_item_id#32]
Arguments: [wr_item_sk#27], [i_item_sk#31], Inner, BuildRight

(43) CometProject
Input [5]: [wr_item_sk#27, wr_return_quantity#28, wr_returned_date_sk#29, i_item_sk#31, i_item_id#32]
Arguments: [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32], [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32]

(44) ReusedExchange [Reuses operator id: 13]
Output [1]: [d_date_sk#33]

(45) CometBroadcastHashJoin
Left output [3]: [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32]
Right output [1]: [d_date_sk#33]
Arguments: [wr_returned_date_sk#29], [d_date_sk#33], Inner, BuildRight

(46) CometProject
Input [4]: [wr_return_quantity#28, wr_returned_date_sk#29, i_item_id#32, d_date_sk#33]
Arguments: [wr_return_quantity#28, i_item_id#32], [wr_return_quantity#28, i_item_id#32]

(47) ColumnarToRow [codegen id : 4]
Input [2]: [wr_return_quantity#28, i_item_id#32]

(48) HashAggregate [codegen id : 4]
Input [2]: [wr_return_quantity#28, i_item_id#32]
Keys [1]: [i_item_id#32]
Functions [1]: [partial_sum(wr_return_quantity#28)]
Aggregate Attributes [1]: [sum#34]
Results [2]: [i_item_id#32, sum#35]

(49) RowToColumnar
Input [2]: [i_item_id#32, sum#35]

(50) CometColumnarExchange
Input [2]: [i_item_id#32, sum#35]
Arguments: hashpartitioning(i_item_id#32, 5), ENSURE_REQUIREMENTS, CometColumnarShuffle, [plan_id=4]

(51) ColumnarToRow [codegen id : 5]
Input [2]: [i_item_id#32, sum#35]

(52) HashAggregate [codegen id : 5]
Input [2]: [i_item_id#32, sum#35]
Keys [1]: [i_item_id#32]
Functions [1]: [sum(wr_return_quantity#28)]
Aggregate Attributes [1]: [sum(wr_return_quantity#28)#36]
Results [2]: [i_item_id#32 AS item_id#37, sum(wr_return_quantity#28)#36 AS wr_item_qty#38]

(53) BroadcastExchange
Input [2]: [item_id#37, wr_item_qty#38]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=5]

(54) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [item_id#13]
Right keys [1]: [item_id#37]
Join type: Inner
Join condition: None

(55) Project [codegen id : 6]
Output [8]: [item_id#13, sr_item_qty#14, (((cast(sr_item_qty#14 as double) / cast(((sr_item_qty#14 + cr_item_qty#26) + wr_item_qty#38) as double)) / 3.0) * 100.0) AS sr_dev#39, cr_item_qty#26, (((cast(cr_item_qty#26 as double) / cast(((sr_item_qty#14 + cr_item_qty#26) + wr_item_qty#38) as double)) / 3.0) * 100.0) AS cr_dev#40, wr_item_qty#38, (((cast(wr_item_qty#38 as double) / cast(((sr_item_qty#14 + cr_item_qty#26) + wr_item_qty#38) as double)) / 3.0) * 100.0) AS wr_dev#41, (cast(((sr_item_qty#14 + cr_item_qty#26) + wr_item_qty#38) as decimal(20,0)) / 3.0) AS average#42]
Input [5]: [item_id#13, sr_item_qty#14, cr_item_qty#26, item_id#37, wr_item_qty#38]

(56) TakeOrderedAndProject
Input [8]: [item_id#13, sr_item_qty#14, sr_dev#39, cr_item_qty#26, cr_dev#40, wr_item_qty#38, wr_dev#41, average#42]
Arguments: 100, [item_id#13 ASC NULLS FIRST, sr_item_qty#14 ASC NULLS FIRST], [item_id#13, sr_item_qty#14, sr_dev#39, cr_item_qty#26, cr_dev#40, wr_item_qty#38, wr_dev#41, average#42]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = sr_returned_date_sk#3 IN dynamicpruning#4
BroadcastExchange (70)
+- * ColumnarToRow (69)
   +- CometProject (68)
      +- CometBroadcastHashJoin (67)
         :- CometFilter (58)
         :  +- CometScan parquet spark_catalog.default.date_dim (57)
         +- CometBroadcastExchange (66)
            +- CometProject (65)
               +- CometBroadcastHashJoin (64)
                  :- CometScan parquet spark_catalog.default.date_dim (59)
                  +- CometBroadcastExchange (63)
                     +- CometProject (62)
                        +- CometFilter (61)
                           +- CometScan parquet spark_catalog.default.date_dim (60)


(57) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#7, d_date#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(58) CometFilter
Input [2]: [d_date_sk#7, d_date#8]
Condition : isnotnull(d_date_sk#7)

(59) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#9, d_week_seq#43]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
ReadSchema: struct<d_date:date,d_week_seq:int>

(60) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#44, d_week_seq#45]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_date, [2000-06-30,2000-09-27,2000-11-17])]
ReadSchema: struct<d_date:date,d_week_seq:int>

(61) CometFilter
Input [2]: [d_date#44, d_week_seq#45]
Condition : d_date#44 IN (2000-06-30,2000-09-27,2000-11-17)

(62) CometProject
Input [2]: [d_date#44, d_week_seq#45]
Arguments: [d_week_seq#45], [d_week_seq#45]

(63) CometBroadcastExchange
Input [1]: [d_week_seq#45]
Arguments: [d_week_seq#45]

(64) CometBroadcastHashJoin
Left output [2]: [d_date#9, d_week_seq#43]
Right output [1]: [d_week_seq#45]
Arguments: [d_week_seq#43], [d_week_seq#45], LeftSemi, BuildRight

(65) CometProject
Input [2]: [d_date#9, d_week_seq#43]
Arguments: [d_date#9], [d_date#9]

(66) CometBroadcastExchange
Input [1]: [d_date#9]
Arguments: [d_date#9]

(67) CometBroadcastHashJoin
Left output [2]: [d_date_sk#7, d_date#8]
Right output [1]: [d_date#9]
Arguments: [d_date#8], [d_date#9], LeftSemi, BuildRight

(68) CometProject
Input [2]: [d_date_sk#7, d_date#8]
Arguments: [d_date_sk#7], [d_date_sk#7]

(69) ColumnarToRow [codegen id : 1]
Input [1]: [d_date_sk#7]

(70) BroadcastExchange
Input [1]: [d_date_sk#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

Subquery:2 Hosting operator id = 22 Hosting Expression = cr_returned_date_sk#17 IN dynamicpruning#4

Subquery:3 Hosting operator id = 39 Hosting Expression = wr_returned_date_sk#29 IN dynamicpruning#4


