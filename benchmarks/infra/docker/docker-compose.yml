# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Spark standalone cluster for benchmarks.
#
# Usage:
#   docker compose -f benchmarks/infra/docker/docker-compose.yml up -d
#
# Override with constrained memory limits:
#   docker compose -f benchmarks/infra/docker/docker-compose.yml \
#                  -f benchmarks/infra/docker/docker-compose.constrained.yml up -d
#
# Environment variables (set in .env or export before running):
#   BENCH_IMAGE        - Docker image to use (default: comet-bench)
#   DATA_DIR           - Host path to TPC data (default: /tmp/tpc-data)
#   QUERIES_DIR        - Host path to query SQL files (default: /tmp/tpc-queries)
#   RESULTS_DIR        - Host path for results output (default: /tmp/bench-results)
#   ENGINE_JARS_DIR    - Host path containing engine JARs (default: /tmp/engine-jars)

services:
  spark-master:
    image: ${BENCH_IMAGE:-comet-bench}
    container_name: spark-master
    hostname: spark-master
    command: /opt/spark/sbin/start-master.sh --host spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ${DATA_DIR:-/tmp/tpc-data}:/data:ro
      - ${QUERIES_DIR:-/tmp/tpc-queries}:/queries:ro
      - ${RESULTS_DIR:-/tmp/bench-results}:/results
      - ${ENGINE_JARS_DIR:-/tmp/engine-jars}:/jars:ro
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_NO_DAEMONIZE=true

  spark-worker:
    image: ${BENCH_IMAGE:-comet-bench}
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    command: /opt/spark/sbin/start-worker.sh spark://spark-master:7077
    ports:
      - "8081:8081"
    volumes:
      - ${DATA_DIR:-/tmp/tpc-data}:/data:ro
      - ${QUERIES_DIR:-/tmp/tpc-queries}:/queries:ro
      - ${RESULTS_DIR:-/tmp/bench-results}:/results
      - ${ENGINE_JARS_DIR:-/tmp/engine-jars}:/jars:ro
    environment:
      - SPARK_WORKER_CORES=${WORKER_CORES:-8}
      - SPARK_WORKER_MEMORY=${WORKER_MEMORY:-16g}
      - SPARK_NO_DAEMONIZE=true

  bench:
    image: ${BENCH_IMAGE:-comet-bench}
    container_name: bench-runner
    depends_on:
      - spark-master
      - spark-worker
    # Override 'command' to run a specific benchmark, e.g.:
    #   docker compose run bench python /opt/benchmarks/run.py \
    #       --engine comet --profile docker -- tpc ...
    command: ["echo", "Use 'docker compose run bench python /opt/benchmarks/run.py ...' to run benchmarks"]
    volumes:
      - ${DATA_DIR:-/tmp/tpc-data}:/data:ro
      - ${QUERIES_DIR:-/tmp/tpc-queries}:/queries:ro
      - ${RESULTS_DIR:-/tmp/bench-results}:/results
      - ${ENGINE_JARS_DIR:-/tmp/engine-jars}:/jars:ro
    environment:
      - SPARK_HOME=/opt/spark
      - SPARK_MASTER=spark://spark-master:7077
      - COMET_JAR=/jars/comet.jar
      - PYTHONPATH=/opt
